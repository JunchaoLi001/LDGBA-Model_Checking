{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5f1fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<csrl.oaa.oaa at 0x221efe77a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: 0\n",
      "Transition function: [\n",
      "  {(): 0, ('a',): 1, ('b',): 0, ('c',): 2, ('a', 'b'): 0, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2},\n",
      "  {(): 1, ('a',): 1, ('b',): 0, ('c',): 2, ('a', 'b'): 0, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2},\n",
      "  {(): 2, ('a',): 2, ('b',): 2, ('c',): 2, ('a', 'b'): 2, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2}\n",
      "]\n",
      "Acceptance: [\n",
      "  {(): [None], ('a',): [True], ('b',): [True], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]},\n",
      "  {(): [None], ('a',): [True], ('b',): [True], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]},\n",
      "  {(): [None], ('a',): [None], ('b',): [None], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]}\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import manually defined automata\n",
    "%matplotlib inline\n",
    "from csrl.pomdp import GridPOMDP\n",
    "from csrl.oaa import oaa\n",
    "from csrl import ControlSynthesis\n",
    "import numpy as np \n",
    "\n",
    "oa=oaa()\n",
    "\n",
    "# LTL Specification\n",
    "#ltl = '(GFa & GFb) & G!c' ### goes to 'a', 'b' recurrently, gallobly ! c\n",
    "\n",
    "# Translate the LTL formula to an LDBA\n",
    "print('Number of Omega-automaton states (including the trap state):',oa.shape[1])\n",
    "display(oa)\n",
    "\n",
    "print('Initial state:',oa.q0)\n",
    "print('Transition function: ['),print(*['  '+str(t) for t in oa.delta],sep=',\\n'),print(']')\n",
    "print('Acceptance: ['),print(*['  '+str(t) for t in oa.acc],sep=',\\n'),print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e69f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNCHA~1\\AppData\\Local\\Temp/ipykernel_22728/3991470510.py:29: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ],dtype=np.object)\n"
     ]
    }
   ],
   "source": [
    "# POMDP Description\n",
    "shape = (10,10)\n",
    "# E: Empty, T: Trap, B: Obstacle\n",
    "structure = np.array([\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E']\n",
    "])\n",
    "\n",
    "# Labels of the states\n",
    "label = np.array([\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       ('c',),       ('c',),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       ('c',),       ('c',),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       ('c',),       ('c',),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       ('c',),       ('c',),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()]\n",
    "],dtype=np.object)\n",
    "\n",
    "grid_pomdp = GridPOMDP(shape=shape,structure=structure,label=label) \n",
    "\n",
    "# Construct the product POMDP\n",
    "csrl = ControlSynthesis(grid_pomdp,oa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33501f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]],\n",
       "\n",
       "        [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "        [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.belief_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c331dd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]],\n",
       "\n",
       "        [[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]],\n",
       "\n",
       "        [[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]]]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfafe01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc59fe3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.113630712032318\n",
      "episode: 1/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.034545958042144775\n",
      "episode: 2/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.2063665390014648\n",
      "episode: 3/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.019311487674713135\n",
      "episode: 5/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 6/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.50568550825119\n",
      "episode: 8/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 9/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 10/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.294707298278809\n",
      "episode: 11/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 12/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 13/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.50001323223114\n",
      "episode: 14/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 15/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 16/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 17/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 18/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 19/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 20/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 21/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 13.884765625\n",
      "episode: 22/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 23/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 24/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-07\n",
      "episode: 25/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 26/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984371185302734\n",
      "episode: 27/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 28/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 29/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 30/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.029991090297698975\n",
      "episode: 31/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.0675575137138367\n",
      "episode: 32/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.96093761920929\n",
      "episode: 33/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 34/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 35/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890703916549683\n",
      "episode: 36/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 37/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00021398067474365234\n",
      "episode: 38/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 39/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 27.954231560230255\n",
      "episode: 40/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 41/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 42/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 43/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.64892578125\n",
      "episode: 44/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 45/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 46/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 47/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.894371032714844e-06\n",
      "episode: 48/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 49/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 50/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 51/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 52/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 53/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 54/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 55/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 56/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 57/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 58/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0007655024528503418\n",
      "episode: 59/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 60/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 61/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 62/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 63/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015520334243774414\n",
      "episode: 64/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 65/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.15634649991989\n",
      "episode: 66/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 67/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 68/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 69/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.129852294921875\n",
      "episode: 70/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976564884185791\n",
      "episode: 71/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.01260143518447876\n",
      "episode: 72/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 73/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 74/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 75/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 76/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.98898321390152\n",
      "episode: 77/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0506628155708313\n",
      "episode: 78/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 79/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 80/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 81/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656399011612\n",
      "episode: 82/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.15764617919921875\n",
      "episode: 83/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 84/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568639278412\n",
      "episode: 85/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 86/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 87/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.732080459594727e-05\n",
      "episode: 88/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996849238872528\n",
      "episode: 89/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 90/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02303069829940796\n",
      "episode: 91/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.047902464866638\n",
      "episode: 92/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.04258066415786743\n",
      "episode: 93/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5086616277694702\n",
      "episode: 94/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.15764617919921875\n",
      "episode: 95/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.15888595581054688\n",
      "episode: 96/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9548006057739258\n",
      "episode: 97/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 98/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.8359375\n",
      "episode: 99/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 100/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.05902099609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 101/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 102/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 103/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.410891354084015\n",
      "episode: 104/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 105/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 106/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.21677017211914\n",
      "episode: 107/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 108/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 109/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 110/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.1285400390625\n",
      "episode: 111/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 112/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989158630371094\n",
      "episode: 113/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.09309762716293335\n",
      "episode: 114/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.027801573276519775\n",
      "episode: 115/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.991264343261719\n",
      "episode: 116/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988984763622284\n",
      "episode: 117/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.951778888702393\n",
      "episode: 118/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 119/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 120/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 121/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 122/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.009237051010132\n",
      "episode: 123/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 124/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.24968022108078\n",
      "episode: 125/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 126/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.453125357627869\n",
      "episode: 127/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 13.922657012939453\n",
      "episode: 128/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 129/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.109029352664948\n",
      "episode: 130/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 131/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.166987419128418\n",
      "episode: 132/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 133/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 134/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.949352204799652\n",
      "episode: 135/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0019197463989257812\n",
      "episode: 136/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 137/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 138/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 139/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 140/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 141/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.724220275878906\n",
      "episode: 142/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 143/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.01997220516204834\n",
      "episode: 144/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 145/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.489402294158936\n",
      "episode: 146/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0961567759513855\n",
      "episode: 147/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 148/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984435617923737\n",
      "episode: 149/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007025778293609619\n",
      "episode: 150/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.005339682102203\n",
      "episode: 151/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 152/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.968839168548584\n",
      "episode: 153/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 154/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 155/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 156/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 157/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0013471245765686035\n",
      "episode: 158/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0132789611816406e-06\n",
      "episode: 159/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02039361000061035\n",
      "episode: 160/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984546661376953\n",
      "episode: 161/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.12524628639221191\n",
      "episode: 162/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 163/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.001918792724609375\n",
      "episode: 164/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 165/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.979213535785675\n",
      "episode: 166/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 167/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 168/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 169/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 170/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 171/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012993991374969482\n",
      "episode: 172/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 173/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 174/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 175/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.32900261878967285\n",
      "episode: 176/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 177/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 178/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 179/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 180/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 181/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 182/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.450580596923828e-06\n",
      "episode: 183/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.945401787757874\n",
      "episode: 184/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02574324607849121\n",
      "episode: 185/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008179128170013428\n",
      "episode: 186/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.001456201076508\n",
      "episode: 187/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984272003173828\n",
      "episode: 188/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 189/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.504035353660583\n",
      "episode: 190/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 191/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 192/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 193/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0074697136878967285\n",
      "episode: 194/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.13165283203125\n",
      "episode: 195/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.999947905540466\n",
      "episode: 196/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 197/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 198/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.01143646240234375\n",
      "episode: 199/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992331266403198\n",
      "episode: 200/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 201/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 202/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992632925510406\n",
      "episode: 203/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 204/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 205/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 6.771087646484375e-05\n",
      "episode: 206/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.98899132013321\n",
      "episode: 207/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.8100587725639343\n",
      "episode: 208/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 209/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 210/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 211/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 212/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 213/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.1859105825424194\n",
      "episode: 214/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 6.377696990966797e-06\n",
      "episode: 215/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 216/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 217/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 218/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012320995330810547\n",
      "episode: 219/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 220/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 221/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 222/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 223/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.043053388595581\n",
      "episode: 224/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 225/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.049397587776184\n",
      "episode: 226/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 227/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.98909878730774\n",
      "episode: 228/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 229/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 230/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 231/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 232/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 233/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 234/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.014743983745574951\n",
      "episode: 235/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 236/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 237/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 238/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 239/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007793426513671875\n",
      "episode: 240/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 241/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 242/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989161491394043\n",
      "episode: 243/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 244/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.10932832956314\n",
      "episode: 245/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 246/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 247/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.304208397865295\n",
      "episode: 248/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 249/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02034860849380493\n",
      "episode: 250/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 251/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 252/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 253/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 254/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007951021194458008\n",
      "episode: 255/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 256/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 257/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00018924474716186523\n",
      "episode: 258/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.969132363796234\n",
      "episode: 259/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 20.092887580394745\n",
      "episode: 260/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.977389633655548\n",
      "episode: 261/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 262/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 263/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.0265579223632812e-06\n",
      "episode: 264/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 265/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 266/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996771812438965\n",
      "episode: 267/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0014702081680297852\n",
      "episode: 268/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 269/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 270/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 271/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.005762994289398193\n",
      "episode: 272/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976692497730255\n",
      "episode: 273/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 274/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 275/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 276/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 277/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.953128695487976\n",
      "episode: 278/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 279/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 280/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 281/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 282/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007701992988586426\n",
      "episode: 283/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.1056671142578125\n",
      "episode: 284/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.2355080246925354\n",
      "episode: 285/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 286/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.49655169248581\n",
      "episode: 287/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 288/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 289/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.465955674648285\n",
      "episode: 290/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 291/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 292/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 293/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.88033676147461\n",
      "episode: 294/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.327612161636353\n",
      "episode: 295/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.04905211925506592\n",
      "episode: 296/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 297/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 298/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 299/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 300/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 301/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 302/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 20.357598066329956\n",
      "episode: 303/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984484374523163\n",
      "episode: 304/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 305/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 306/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 307/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 308/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 309/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 310/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.225018799304962\n",
      "episode: 311/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976673305034637\n",
      "episode: 312/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 313/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.27685546875\n",
      "episode: 314/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 315/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 316/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 317/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008941411972045898\n",
      "episode: 318/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 319/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.21239811182022095\n",
      "episode: 320/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 321/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 322/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 323/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 324/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.895949602127075\n",
      "episode: 325/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 326/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.960942447185516\n",
      "episode: 327/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 328/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 15.219314873218536\n",
      "episode: 329/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976888179779053\n",
      "episode: 330/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 331/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.459064543247223\n",
      "episode: 332/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.49779582023620605\n",
      "episode: 333/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976671934127808\n",
      "episode: 334/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 335/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.031219482421875\n",
      "episode: 336/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.2464599609375\n",
      "episode: 337/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989001393318176\n",
      "episode: 338/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.002998232841492\n",
      "episode: 339/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.018118619918823\n",
      "episode: 340/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.496585845947266\n",
      "episode: 341/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 342/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 343/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 344/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 345/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.005098462104797\n",
      "episode: 346/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.51220703125\n",
      "episode: 347/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 18.747290432453156\n",
      "episode: 348/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 349/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 350/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0035396814346313477\n",
      "episode: 351/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 352/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.00147920846939\n",
      "episode: 353/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.276897430419922e-05\n",
      "episode: 354/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.740516662597656\n",
      "episode: 355/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00216752290725708\n",
      "episode: 356/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 357/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.89093291759491\n",
      "episode: 358/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 359/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 360/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 361/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 362/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 363/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 364/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 365/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0123291015625\n",
      "episode: 366/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 367/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 368/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 369/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.000006020069122\n",
      "episode: 370/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.5854835510253906e-05\n",
      "episode: 371/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 372/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 373/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 374/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.722487568855286\n",
      "episode: 375/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 376/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 377/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.3113021850585938e-06\n",
      "episode: 378/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 379/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 380/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 381/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 382/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 383/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 384/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 385/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.945699691772461\n",
      "episode: 386/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 387/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.4768053889274597\n",
      "episode: 388/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 389/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.0003662109375\n",
      "episode: 390/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 391/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 392/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 393/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 394/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 395/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984375059604645\n",
      "episode: 396/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 397/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539062e-07\n",
      "episode: 398/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 399/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00010836124420166016\n",
      "episode: 400/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 401/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 402/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 403/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 404/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.957256317138672\n",
      "episode: 405/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 406/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 407/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.196963846683502\n",
      "episode: 408/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 15.144320905208588\n",
      "episode: 409/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 410/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 411/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.007675170898438\n",
      "episode: 412/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 413/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 414/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 415/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 42.59039098024368\n",
      "episode: 416/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.013919174671173\n",
      "episode: 417/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 418/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.00805926322937\n",
      "episode: 419/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 420/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1146068572998047e-05\n",
      "episode: 421/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 422/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.843051970005035\n",
      "episode: 423/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 424/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02652597427368164\n",
      "episode: 425/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 426/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 427/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 428/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 429/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 430/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012776076793670654\n",
      "episode: 431/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.664520263671875\n",
      "episode: 432/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.828125\n",
      "episode: 433/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.4189453125\n",
      "episode: 434/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 435/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 436/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0961461067199707\n",
      "episode: 437/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 438/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 439/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 440/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 441/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 442/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656500339508\n",
      "episode: 443/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 444/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 445/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 446/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 447/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 448/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0001246333122253418\n",
      "episode: 449/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 450/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 451/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 452/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 453/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 454/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.28167724609375\n",
      "episode: 455/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 456/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 457/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 458/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 459/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.000154912471771\n",
      "episode: 460/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 461/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984524846076965\n",
      "episode: 462/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.7285346984863281e-06\n",
      "episode: 463/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 464/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0017529726028442383\n",
      "episode: 465/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 466/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.35595703125\n",
      "episode: 467/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.870709359645844\n",
      "episode: 468/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.86102294921875e-06\n",
      "episode: 469/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 470/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1025390625\n",
      "episode: 471/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 472/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 473/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 474/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 475/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 476/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 477/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 478/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00041604042053222656\n",
      "episode: 479/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 480/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.497633695602417\n",
      "episode: 481/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 482/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 483/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 484/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 485/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988885581493378\n",
      "episode: 486/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 487/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.473324060440063\n",
      "episode: 488/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 489/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 490/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.94471651315689\n",
      "episode: 491/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0472749471664429\n",
      "episode: 492/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 493/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 494/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007767021656036377\n",
      "episode: 495/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 496/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 497/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.594142019748688\n",
      "episode: 498/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.07021015882492\n",
      "episode: 499/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1324882507324219e-06\n",
      "episode: 500/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 501/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 502/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 503/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.3185681700706482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 504/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 505/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.070114016532898\n",
      "episode: 506/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00021904706954956055\n",
      "episode: 507/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 508/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 509/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 510/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 511/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.000377297401428\n",
      "episode: 512/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 513/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 514/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 515/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 516/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984471440315247\n",
      "episode: 517/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 518/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 519/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 520/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 521/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.005051374435425\n",
      "episode: 522/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.000001549720764\n",
      "episode: 523/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 524/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 525/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 526/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 527/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.973727643489838\n",
      "episode: 528/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-07\n",
      "episode: 529/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9777324199676514\n",
      "episode: 530/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.635565280914307\n",
      "episode: 531/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 532/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 533/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 534/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 535/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.344650268554688e-07\n",
      "episode: 536/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 537/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00044989585876464844\n",
      "episode: 538/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 539/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984270632266998\n",
      "episode: 540/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 541/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 542/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 543/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.134658813476562\n",
      "episode: 544/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 545/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.468994140625\n",
      "episode: 546/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5543315410614014\n",
      "episode: 547/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 548/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 549/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0013049840927124023\n",
      "episode: 550/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984545767307281\n",
      "episode: 551/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.185648560523987\n",
      "episode: 552/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.243322372436523e-05\n",
      "episode: 553/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 554/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.03376901149749756\n",
      "episode: 555/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 556/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 557/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00018799304962158203\n",
      "episode: 558/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988876521587372\n",
      "episode: 559/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.13671875\n",
      "episode: 560/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.381991147994995\n",
      "episode: 561/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.71875\n",
      "episode: 562/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 563/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 564/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 565/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 566/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 567/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 568/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 569/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 570/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.020407795906067\n",
      "episode: 571/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 572/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 573/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 574/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 575/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 576/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.05485290288925171\n",
      "episode: 577/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.5430299043655396\n",
      "episode: 578/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 579/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 580/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 581/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 582/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.95828902721405\n",
      "episode: 583/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02064371109008789\n",
      "episode: 584/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9784936904907227\n",
      "episode: 585/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.011108160018921\n",
      "episode: 586/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 178.27348709106445\n",
      "episode: 587/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 14.189799904823303\n",
      "episode: 588/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.997037887573242\n",
      "episode: 589/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 590/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 591/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 592/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.007810235023499\n",
      "episode: 593/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 594/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 595/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00202864408493042\n",
      "episode: 596/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9367116689682\n",
      "episode: 597/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0077307820320129395\n",
      "episode: 598/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 599/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.024794816970825195\n",
      "episode: 600/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 601/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0002716183662414551\n",
      "episode: 602/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 603/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 604/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008366823196411133\n",
      "episode: 605/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 606/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 607/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 608/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 609/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 610/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 611/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.013334035873413086\n",
      "episode: 612/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.3709068298339844e-06\n",
      "episode: 613/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 614/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.11762237548828125\n",
      "episode: 615/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 616/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 617/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 618/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 619/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 620/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 621/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 622/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.854294300079346\n",
      "episode: 623/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 624/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.14044451713562012\n",
      "episode: 625/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 626/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 627/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 628/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.0352703332901\n",
      "episode: 629/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 630/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988983154296875\n",
      "episode: 631/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 632/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.010316848754883\n",
      "episode: 633/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 634/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 635/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00011301040649414062\n",
      "episode: 636/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992525577545166\n",
      "episode: 637/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 638/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.12488937377929688\n",
      "episode: 639/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 640/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 641/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984269320964813\n",
      "episode: 642/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.148681640625\n",
      "episode: 643/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.00012469291687\n",
      "episode: 644/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 645/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.026169955730438232\n",
      "episode: 646/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 647/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 648/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 21.10563850402832\n",
      "episode: 649/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 650/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 651/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 652/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 653/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 654/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 655/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.004910469055175781\n",
      "episode: 656/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 657/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.112720489501953e-06\n",
      "episode: 658/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 659/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 660/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.164336204528809\n",
      "episode: 661/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 662/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 663/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 664/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 665/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.139513373374939\n",
      "episode: 666/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.78749930858612\n",
      "episode: 667/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.000107944011688\n",
      "episode: 668/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 669/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 670/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 671/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 672/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 673/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 674/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 675/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 676/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.089986324310303\n",
      "episode: 677/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 678/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.291534423828125e-06\n",
      "episode: 679/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0004932284355163574\n",
      "episode: 680/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 681/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012315332889556885\n",
      "episode: 682/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 683/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0011081695556640625\n",
      "episode: 684/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 685/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.33437305688858\n",
      "episode: 686/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 687/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 688/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0068206787109375\n",
      "episode: 689/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 690/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 691/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 692/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.029188394546509\n",
      "episode: 693/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.114269375801086\n",
      "episode: 694/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 695/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976454138755798\n",
      "episode: 696/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 697/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0024127960205078125\n",
      "episode: 698/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 699/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 700/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 701/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 702/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 703/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 704/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 20.00161510705948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 705/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 706/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 707/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 708/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 20.118408203125\n",
      "episode: 709/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.180908203125\n",
      "episode: 710/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.484380841255188\n",
      "episode: 711/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.998784065246582\n",
      "episode: 712/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.069105982780457\n",
      "episode: 713/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 714/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.10160207748413\n",
      "episode: 715/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 716/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 717/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984462261199951\n",
      "episode: 718/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 719/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00819408893585205\n",
      "episode: 720/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.771928191184998\n",
      "episode: 721/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 722/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 723/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.694595336914062\n",
      "episode: 724/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 725/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 726/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.998627781867981\n",
      "episode: 727/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007659852504730225\n",
      "episode: 728/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.519249975681305\n",
      "episode: 729/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00010979175567626953\n",
      "episode: 730/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 17.56597673892975\n",
      "episode: 731/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007521450519561768\n",
      "episode: 732/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 733/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 734/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.135859191417694\n",
      "episode: 735/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9111328125\n",
      "episode: 736/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0067958831787109375\n",
      "episode: 737/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.101592063903809\n",
      "episode: 738/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.004595160484313965\n",
      "episode: 739/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 740/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 741/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.88281399011612\n",
      "episode: 742/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.009781122207642\n",
      "episode: 743/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890629172325134\n",
      "episode: 744/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 745/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 746/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 747/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.496279120445251\n",
      "episode: 748/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 749/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 750/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 751/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 752/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 753/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.98454213142395\n",
      "episode: 754/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.14492130279541\n",
      "episode: 755/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 756/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.93237417936325\n",
      "episode: 757/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 758/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.005244195461273193\n",
      "episode: 759/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 760/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 761/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 762/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 763/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 764/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 765/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 766/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.15775173902511597\n",
      "episode: 767/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.289215207099915\n",
      "episode: 768/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 769/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 770/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 771/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.139404296875\n",
      "episode: 772/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 773/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 774/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 775/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.046395719051361084\n",
      "episode: 776/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 777/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 778/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 779/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 780/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 781/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 782/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.014803886413574219\n",
      "episode: 783/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 784/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 785/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 786/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.953261017799377\n",
      "episode: 787/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 788/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 789/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.468994140625\n",
      "episode: 790/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.0279159545898438e-05\n",
      "episode: 791/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 792/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.814697265625e-06\n",
      "episode: 793/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 794/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.016936480998993\n",
      "episode: 795/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 796/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 797/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 798/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 799/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 800/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984546661376953\n",
      "episode: 801/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 802/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015221774578094482\n",
      "episode: 803/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 804/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 805/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 806/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 807/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 808/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 809/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 810/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 811/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.04830390214920044\n",
      "episode: 812/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 813/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 814/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 815/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.782906532287598\n",
      "episode: 816/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.511614918708801\n",
      "episode: 817/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 818/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 819/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989115715026855\n",
      "episode: 820/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 821/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 822/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 823/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 824/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.144519925117493\n",
      "episode: 825/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976842403411865\n",
      "episode: 826/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 827/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.791071891784668\n",
      "episode: 828/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.017628788948059082\n",
      "episode: 829/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.016157031059265137\n",
      "episode: 830/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.198671817779541\n",
      "episode: 831/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 832/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 833/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007630884647369385\n",
      "episode: 834/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 835/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.997860848903656\n",
      "episode: 836/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.493013262748718\n",
      "episode: 837/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 20.807677090168\n",
      "episode: 838/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 839/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984548151493073\n",
      "episode: 840/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5543428659439087\n",
      "episode: 841/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.004014015197753906\n",
      "episode: 842/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 843/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 844/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0009479522705078125\n",
      "episode: 845/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 846/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.445415914058685\n",
      "episode: 847/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00012010335922241211\n",
      "episode: 848/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 849/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 850/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 851/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 852/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.004903793334961e-05\n",
      "episode: 853/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 854/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.981169164180756\n",
      "episode: 855/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.0625\n",
      "episode: 856/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.71875\n",
      "episode: 857/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02019345760345459\n",
      "episode: 858/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 97.92900174856186\n",
      "episode: 859/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.390625\n",
      "episode: 860/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.70550537109375\n",
      "episode: 861/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 862/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890625178813934\n",
      "episode: 863/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.3113021850585938e-06\n",
      "episode: 864/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 865/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 866/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 867/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 868/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.99609375\n",
      "episode: 869/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 870/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 871/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 872/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 873/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.344322144985199\n",
      "episode: 874/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25430417060852\n",
      "episode: 875/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 876/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 877/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.39844036102295\n",
      "episode: 878/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00031757354736328125\n",
      "episode: 879/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 880/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.35732269287109375\n",
      "episode: 881/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 882/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 883/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 884/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9794769287109375\n",
      "episode: 885/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.770653009414673\n",
      "episode: 886/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.032254040241241455\n",
      "episode: 887/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 888/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.006591141223907471\n",
      "episode: 889/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 890/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.1331863403320312\n",
      "episode: 891/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 892/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1622905731201172e-05\n",
      "episode: 893/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 894/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.83340835571289e-05\n",
      "episode: 895/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 896/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976677060127258\n",
      "episode: 897/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 898/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 899/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 900/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 901/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 902/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.148681640625\n",
      "episode: 903/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 904/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 905/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 906/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656625509262\n",
      "episode: 907/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.139404296875\n",
      "episode: 908/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 909/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 910/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 911/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 912/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 913/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 914/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 915/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 916/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 917/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 918/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 919/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 920/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 921/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 922/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 923/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 924/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00011086463928222656\n",
      "episode: 925/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 926/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 927/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 928/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 929/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984981536865234\n",
      "episode: 930/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984270453453064\n",
      "episode: 931/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 932/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 933/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 934/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.606053113937378\n",
      "episode: 935/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.128137767314911\n",
      "episode: 936/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 937/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 938/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 939/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00682830810546875\n",
      "episode: 940/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 941/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.099730849266052\n",
      "episode: 942/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.126226782798767\n",
      "episode: 943/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.16091418266296387\n",
      "episode: 944/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 945/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 946/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 947/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.003047943115234375\n",
      "episode: 948/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.001948058605194\n",
      "episode: 949/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.33251953125\n",
      "episode: 950/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.021879255771637\n",
      "episode: 951/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 952/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 953/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 954/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 955/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00789499282836914\n",
      "episode: 956/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 957/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 958/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 959/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.3984375\n",
      "episode: 960/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 961/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97704815864563\n",
      "episode: 962/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00010967254638671875\n",
      "episode: 963/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 964/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.295852184295654\n",
      "episode: 965/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 966/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 967/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 968/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 969/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 970/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 971/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 972/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.973808228969574\n",
      "episode: 973/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 974/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.195892333984375\n",
      "episode: 975/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 976/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 977/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 978/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 979/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.979775428771973\n",
      "episode: 980/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.3401300311088562\n",
      "episode: 981/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 982/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.7034095525741577\n",
      "episode: 983/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 984/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 985/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 986/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 987/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.874301910400391e-06\n",
      "episode: 988/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 989/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.875\n",
      "episode: 990/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 991/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 992/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 993/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00800102949142456\n",
      "episode: 994/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 995/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 996/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 997/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 40.85227084159851\n",
      "episode: 998/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00408095121383667\n",
      "episode: 999/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1000/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.927417755126953e-06\n",
      "episode: 1001/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1002/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1003/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1004/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1005/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996855735778809\n",
      "episode: 1006/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.009284019470215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1007/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1008/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1009/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1010/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984367370605469\n",
      "episode: 1011/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1012/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1013/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1014/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 1015/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.011422574520111084\n",
      "episode: 1016/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1017/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.945803463459015\n",
      "episode: 1018/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.322265803813934\n",
      "episode: 1019/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1020/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1021/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1022/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.945229649543762\n",
      "episode: 1023/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 1024/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.136563837528229\n",
      "episode: 1025/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1026/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1027/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.9343268275260925\n",
      "episode: 1028/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1029/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1030/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0340576171875\n",
      "episode: 1031/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 23.482233464717865\n",
      "episode: 1032/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1033/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1034/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1035/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.086036443710327\n",
      "episode: 1036/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1037/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1038/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1039/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 18.261512279510498\n",
      "episode: 1040/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.5033950805664062e-06\n",
      "episode: 1041/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 21.839691162109375\n",
      "episode: 1042/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.6443936228752136\n",
      "episode: 1043/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.27890282869339\n",
      "episode: 1044/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 18.637695372104645\n",
      "episode: 1045/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.319594979286194\n",
      "episode: 1046/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.8192996978759766e-05\n",
      "episode: 1047/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.03390312194824219\n",
      "episode: 1048/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.488096594810486\n",
      "episode: 1049/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1050/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008510172367095947\n",
      "episode: 1051/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.273827016353607\n",
      "episode: 1052/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1053/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984545707702637\n",
      "episode: 1054/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1055/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1056/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.12476617097854614\n",
      "episode: 1057/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1058/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1059/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1060/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1061/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1062/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1063/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1064/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1065/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1066/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.4824981689453125\n",
      "episode: 1067/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1068/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1069/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1070/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.4004327058792114\n",
      "episode: 1071/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1072/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00034606456756591797\n",
      "episode: 1073/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.0073477029800415\n",
      "episode: 1074/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1075/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.309355735778809\n",
      "episode: 1076/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976324677467346\n",
      "episode: 1077/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1078/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1079/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1080/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1081/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007816553115844727\n",
      "episode: 1082/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1083/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.5195942521095276\n",
      "episode: 1084/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.09750485420227051\n",
      "episode: 1085/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.059744417667389\n",
      "episode: 1086/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1087/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.11430048942566\n",
      "episode: 1088/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996746063232422\n",
      "episode: 1089/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1090/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.47927093505859375\n",
      "episode: 1091/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1092/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1093/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1094/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.734598934650421\n",
      "episode: 1095/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1096/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1097/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.981435775756836\n",
      "episode: 1098/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.3525848388671875\n",
      "episode: 1099/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1100/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1101/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1102/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1103/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.00968885421753\n",
      "episode: 1104/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1105/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992317199707031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1106/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 1107/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1108/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1109/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1110/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1111/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.867191314697266\n",
      "episode: 1112/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.06548982858657837\n",
      "episode: 1113/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.074422359466553\n",
      "episode: 1114/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015689611434936523\n",
      "episode: 1115/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1116/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.125441193580627\n",
      "episode: 1117/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1118/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.00360107421875\n",
      "episode: 1119/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0001251697540283203\n",
      "episode: 1120/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1121/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1122/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5416769981384277\n",
      "episode: 1123/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.009841978549957275\n",
      "episode: 1124/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1125/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976670980453491\n",
      "episode: 1126/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1127/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1128/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.095169186592102\n",
      "episode: 1129/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1130/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 18.235183715820312\n",
      "episode: 1131/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984299659729004\n",
      "episode: 1132/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1133/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1134/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1135/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1136/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1137/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1138/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1139/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008255720138549805\n",
      "episode: 1140/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.36572813987732\n",
      "episode: 1141/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00019598007202148438\n",
      "episode: 1142/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.160810947418213\n",
      "episode: 1143/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00580596923828125\n",
      "episode: 1144/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1145/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1146/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1147/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.832832336425781\n",
      "episode: 1148/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 1149/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1150/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1151/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1152/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.6570091247558594e-05\n",
      "episode: 1153/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.708251953125\n",
      "episode: 1154/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1155/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1156/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1157/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1158/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1159/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.33857125043869\n",
      "episode: 1160/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1161/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1162/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 6.079673767089844e-05\n",
      "episode: 1163/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1164/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976943135261536\n",
      "episode: 1165/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1166/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.97705078125\n",
      "episode: 1167/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1168/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97668206691742\n",
      "episode: 1169/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1170/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.484376072883606\n",
      "episode: 1171/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1172/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0004125237464904785\n",
      "episode: 1173/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.656562805175781\n",
      "episode: 1174/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.454353272914886\n",
      "episode: 1175/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1176/8000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1177/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1178/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1179/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984844148159027\n",
      "episode: 1180/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1181/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1182/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.010365843772888184\n",
      "episode: 1183/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 1184/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0513988733291626\n",
      "episode: 1185/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1186/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1187/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.44873046875\n",
      "episode: 1188/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1189/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1190/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1191/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.01918792724609375\n",
      "episode: 1192/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 1193/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.989026069641113\n",
      "episode: 1194/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1195/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.164883434772491\n",
      "episode: 1196/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.997404158115387\n",
      "episode: 1197/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1198/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1199/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1200/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.013124287128448486\n",
      "episode: 1201/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1202/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1203/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.51123046875\n",
      "episode: 1204/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.5596059560775757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1205/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1206/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.51124632358551\n",
      "episode: 1207/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.909952878952026\n",
      "episode: 1208/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1209/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1210/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976842403411865\n",
      "episode: 1211/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.890820860862732\n",
      "episode: 1212/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1213/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.297340393066406\n",
      "episode: 1214/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1215/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1216/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1217/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.027191162109375\n",
      "episode: 1218/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1219/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1220/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1221/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1222/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1223/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.014093041419983\n",
      "episode: 1224/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1225/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1226/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-07\n",
      "episode: 1227/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1228/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1229/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1230/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1231/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1232/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1233/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1234/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1235/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.151771545410156\n",
      "episode: 1236/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1237/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0052225589752197266\n",
      "episode: 1238/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.423246204853058\n",
      "episode: 1239/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1240/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1241/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1242/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1243/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 1244/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.454002618789673\n",
      "episode: 1245/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.496906280517578e-06\n",
      "episode: 1246/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1247/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 17.20141726732254\n",
      "episode: 1248/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 19.88091892004013\n",
      "episode: 1249/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.432484745979309\n",
      "episode: 1250/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1251/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 14.86088365316391\n",
      "episode: 1252/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1253/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1254/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1255/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1256/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1257/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.468994140625\n",
      "episode: 1258/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1259/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 1260/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1261/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1262/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007228851318359375\n",
      "episode: 1263/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1264/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.911231815814972\n",
      "episode: 1265/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.945536732673645\n",
      "episode: 1266/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.004204392433166504\n",
      "episode: 1267/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.987929344177246\n",
      "episode: 1268/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1269/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1270/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.977138042449951\n",
      "episode: 1271/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.989159345626831\n",
      "episode: 1272/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.1054019927978516e-05\n",
      "episode: 1273/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00024837255477905273\n",
      "episode: 1274/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.05855792760848999\n",
      "episode: 1275/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007756650447845459\n",
      "episode: 1276/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1277/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1278/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 1279/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1280/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.06868940591812134\n",
      "episode: 1281/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1282/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1283/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 12.233680725097656\n",
      "episode: 1284/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1285/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00011831521987915039\n",
      "episode: 1286/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.269010305404663\n",
      "episode: 1287/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.947182655334473\n",
      "episode: 1288/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.05311852693557739\n",
      "episode: 1289/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.28485107421875\n",
      "episode: 1290/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1291/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1292/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0002224445343017578\n",
      "episode: 1293/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1294/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1295/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.113399267196655\n",
      "episode: 1296/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.004912078380585\n",
      "episode: 1297/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.371044039726257\n",
      "episode: 1298/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.04520922899246216\n",
      "episode: 1299/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.04083132743835449\n",
      "episode: 1300/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.023928403854370117\n",
      "episode: 1301/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1302/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1303/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 1304/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1305/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.7857515811920166\n",
      "episode: 1306/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1307/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1308/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.981056451797485\n",
      "episode: 1309/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0002047419548034668\n",
      "episode: 1310/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00010091066360473633\n",
      "episode: 1311/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.459447145462036\n",
      "episode: 1312/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1313/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1314/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1315/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1316/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1317/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.121334373950958\n",
      "episode: 1318/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.499622344970703e-05\n",
      "episode: 1319/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1320/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1321/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1322/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 1323/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.3325978517532349\n",
      "episode: 1324/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1325/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1326/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1327/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.4741554260253906\n",
      "episode: 1328/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.001920163631439209\n",
      "episode: 1329/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1330/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984713613986969\n",
      "episode: 1331/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1332/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1333/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.179902076721191\n",
      "episode: 1334/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 17.85935539007187\n",
      "episode: 1335/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1336/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1337/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 1338/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1339/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.0018949508667\n",
      "episode: 1340/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1341/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.012021124362945557\n",
      "episode: 1342/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.012668430805206299\n",
      "episode: 1343/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1344/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1345/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1346/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 1347/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.133096098899841\n",
      "episode: 1348/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.4781951904296875e-05\n",
      "episode: 1349/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1350/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 1351/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.03780937194824219\n",
      "episode: 1352/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1353/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.994869232177734\n",
      "episode: 1354/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1355/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.66845703125\n",
      "episode: 1356/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1357/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.332540333271027\n",
      "episode: 1358/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.800355136394501\n",
      "episode: 1359/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 12.100556910037994\n",
      "episode: 1360/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007568359375\n",
      "episode: 1361/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1362/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1363/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1364/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1365/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1366/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1367/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1368/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1369/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1370/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1371/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1372/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97656512260437\n",
      "episode: 1373/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1374/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.13755416870117188\n",
      "episode: 1375/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1376/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976832389831543\n",
      "episode: 1377/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1378/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1379/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1380/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 1381/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1382/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97677880525589\n",
      "episode: 1383/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1384/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.006006062030792236\n",
      "episode: 1385/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1386/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1387/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 1388/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1389/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1390/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.0132789611816406e-06\n",
      "episode: 1391/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1392/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1393/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1394/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 1395/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 113.2424344420433\n",
      "episode: 1396/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1397/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1398/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1399/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.785369396209717\n",
      "episode: 1400/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.643560230731964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1401/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1402/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.4424324035644531e-05\n",
      "episode: 1403/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1404/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1405/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1406/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1407/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.834203839302063\n",
      "episode: 1408/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.006081998348236084\n",
      "episode: 1409/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.13015258312225342\n",
      "episode: 1410/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1411/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.0192190408706665\n",
      "episode: 1412/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 4.827976226806641e-06\n",
      "episode: 1413/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1414/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1415/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1416/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1417/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1418/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1419/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 1420/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.733482360839844\n",
      "episode: 1421/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1422/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.063445925712585\n",
      "episode: 1423/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 12.757877349853516\n",
      "episode: 1424/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.005633890628814697\n",
      "episode: 1425/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.3209114074707031\n",
      "episode: 1426/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.995773315429688\n",
      "episode: 1427/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1428/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1429/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 17.170841217041016\n",
      "episode: 1430/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1431/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1432/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.837828040122986\n",
      "episode: 1433/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1434/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0004680156707763672\n",
      "episode: 1435/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.627206802368164e-05\n",
      "episode: 1436/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1437/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.01569390296936035\n",
      "episode: 1438/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1439/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1440/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1441/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1442/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1443/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1444/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1445/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1446/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1447/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 1448/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.988878786563873\n",
      "episode: 1449/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.27685546875\n",
      "episode: 1450/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1451/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1452/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1453/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1454/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.3525848984718323\n",
      "episode: 1455/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1456/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.06192779541015625\n",
      "episode: 1457/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1458/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1459/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1460/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.995773315429688\n",
      "episode: 1461/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.028191804885864258\n",
      "episode: 1462/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1463/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1464/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.008026957511901855\n",
      "episode: 1465/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.5326377749443054\n",
      "episode: 1466/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.98927116394043\n",
      "episode: 1467/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1468/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.7930896878242493\n",
      "episode: 1469/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1470/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1471/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.992801547050476\n",
      "episode: 1472/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1473/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1474/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.14461874961853\n",
      "episode: 1475/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1476/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.34748733043670654\n",
      "episode: 1477/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1478/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1479/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.531260132789612\n",
      "episode: 1480/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1481/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976840078830719\n",
      "episode: 1482/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1483/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1484/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.965617716312408\n",
      "episode: 1485/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 14.92839652299881\n",
      "episode: 1486/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1487/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1488/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.01263350248336792\n",
      "episode: 1489/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 1490/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1491/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1492/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984314382076263\n",
      "episode: 1493/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1494/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.018328130245209\n",
      "episode: 1495/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.7298927307128906e-05\n",
      "episode: 1496/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1497/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.134731888771057\n",
      "episode: 1498/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1499/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1500/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 14.5341796875\n",
      "episode: 1501/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.012321114540100098\n",
      "episode: 1502/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1503/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.981517791748047\n",
      "episode: 1504/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.726749241352081\n",
      "episode: 1505/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.007183909416199\n",
      "episode: 1506/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1507/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1508/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1509/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1510/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1511/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1512/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.019444465637207\n",
      "episode: 1513/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976681590080261\n",
      "episode: 1514/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1515/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.164811134338379\n",
      "episode: 1516/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.467562913894653\n",
      "episode: 1517/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.16996175050735474\n",
      "episode: 1518/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1519/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1520/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1521/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1522/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1523/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1524/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1525/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.1063376665115356\n",
      "episode: 1526/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1527/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1528/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1529/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1530/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1531/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1532/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1533/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.331371307373047e-05\n",
      "episode: 1534/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1535/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.5260715484619141\n",
      "episode: 1536/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1537/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1538/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.008025288581848145\n",
      "episode: 1539/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 1540/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.139404296875\n",
      "episode: 1541/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.22079050540924072\n",
      "episode: 1542/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.986697673797607\n",
      "episode: 1543/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1544/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1545/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.994212031364441\n",
      "episode: 1546/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1547/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1548/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.153085708618164e-05\n",
      "episode: 1549/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1550/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1551/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1552/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1553/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1554/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.011069536209106\n",
      "episode: 1555/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1556/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97656399011612\n",
      "episode: 1557/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1558/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.3666212558746338\n",
      "episode: 1559/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1560/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1561/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.863871812820435\n",
      "episode: 1562/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1563/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.184534549713135\n",
      "episode: 1564/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1565/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1566/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1567/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1568/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1569/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.996973633766174\n",
      "episode: 1570/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 1571/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1572/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.8275334239006042\n",
      "episode: 1573/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976652204990387\n",
      "episode: 1574/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1575/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.00462257862091\n",
      "episode: 1576/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1577/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1578/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1579/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1580/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1581/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1582/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1583/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.7859345078468323\n",
      "episode: 1584/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976421356201172\n",
      "episode: 1585/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 106.26917457580566\n",
      "episode: 1586/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1587/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.899653494358063\n",
      "episode: 1588/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00010728836059570312\n",
      "episode: 1589/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.581710815429688e-05\n",
      "episode: 1590/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.008887648582458496\n",
      "episode: 1591/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1592/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1593/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.488090515136719\n",
      "episode: 1594/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 1595/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.843751609325409\n",
      "episode: 1596/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.016137301921844482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1597/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 1598/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.174569070339203\n",
      "episode: 1599/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1600/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1601/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 19.62484782934189\n",
      "episode: 1602/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1603/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.026180267333984375\n",
      "episode: 1604/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1605/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.996926665306091\n",
      "episode: 1606/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1607/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.996750056743622\n",
      "episode: 1608/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 23.324474453926086\n",
      "episode: 1609/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1610/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1611/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1612/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.929688155651093\n",
      "episode: 1613/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1614/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1167939901351929\n",
      "episode: 1615/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1616/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.6355056762695312\n",
      "episode: 1617/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1618/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.0994415283203125e-06\n",
      "episode: 1619/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.045150935649872\n",
      "episode: 1620/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1621/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.011711299419403076\n",
      "episode: 1622/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1623/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0009475350379943848\n",
      "episode: 1624/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.289215087890625\n",
      "episode: 1625/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1626/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0006911754608154297\n",
      "episode: 1627/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1628/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1629/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976669490337372\n",
      "episode: 1630/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.515716552734375\n",
      "episode: 1631/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.9778127670288086\n",
      "episode: 1632/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1633/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.581932067871094\n",
      "episode: 1634/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1635/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 1636/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1637/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1638/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976600170135498\n",
      "episode: 1639/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 1640/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1641/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.66845703125\n",
      "episode: 1642/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97693157196045\n",
      "episode: 1643/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1644/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.003764927387237549\n",
      "episode: 1645/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1646/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1647/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1648/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1649/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1650/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1651/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1652/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1653/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1654/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.92198133468628\n",
      "episode: 1655/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.297127664089203\n",
      "episode: 1656/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.9775390625\n",
      "episode: 1657/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.628036499023438e-05\n",
      "episode: 1658/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1659/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.025977671146393\n",
      "episode: 1660/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.779764175415039e-05\n",
      "episode: 1661/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1662/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007924318313598633\n",
      "episode: 1663/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1664/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1665/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1666/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1667/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.172135472297668\n",
      "episode: 1668/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1669/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 22.88980269432068\n",
      "episode: 1670/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.986856341362\n",
      "episode: 1671/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1672/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1673/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1674/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.028002262115479\n",
      "episode: 1675/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00013518333435058594\n",
      "episode: 1676/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1677/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1678/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1679/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.98046875\n",
      "episode: 1680/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976658999919891\n",
      "episode: 1681/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1682/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1683/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976673364639282\n",
      "episode: 1684/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1685/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1686/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.466688334941864\n",
      "episode: 1687/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1688/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1689/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1690/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.494033217430115\n",
      "episode: 1691/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1692/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1693/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.813254654407501\n",
      "episode: 1694/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0019907355308532715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1695/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1696/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1697/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0030670166015625\n",
      "episode: 1698/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 1699/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.945585370063782\n",
      "episode: 1700/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.980411291122437\n",
      "episode: 1701/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1702/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976564347743988\n",
      "episode: 1703/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1704/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1705/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1706/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1707/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1708/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1709/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 1710/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1711/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.6689300537109375e-06\n",
      "episode: 1712/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1713/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.997456789016724\n",
      "episode: 1714/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1715/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007991254329681396\n",
      "episode: 1716/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1717/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1718/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1719/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1720/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1324882507324219e-06\n",
      "episode: 1721/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1722/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.301299154758453\n",
      "episode: 1723/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1724/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1725/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.981315672397614\n",
      "episode: 1726/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984595656394958\n",
      "episode: 1727/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1728/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 1729/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1730/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1731/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1732/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.010942459106445\n",
      "episode: 1733/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1734/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.198883056640625e-06\n",
      "episode: 1735/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00027173757553100586\n",
      "episode: 1736/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1737/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.032296657562256\n",
      "episode: 1738/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.068983316421509\n",
      "episode: 1739/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1740/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1741/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0001208186149597168\n",
      "episode: 1742/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1743/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.418703019618988\n",
      "episode: 1744/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1745/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1746/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1747/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1748/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.83868408203125\n",
      "episode: 1749/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1750/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1751/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.4066696166992188e-05\n",
      "episode: 1752/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.03478527069091797\n",
      "episode: 1753/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.008905053138733\n",
      "episode: 1754/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1755/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1756/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1757/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1758/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1759/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1760/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.640631258487701\n",
      "episode: 1761/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1762/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 14.258760631084442\n",
      "episode: 1763/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1764/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1765/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1766/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1767/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1768/8000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1769/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1770/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.984270453453064\n",
      "episode: 1771/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1772/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 23.998108506202698\n",
      "episode: 1773/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.265738427639008\n",
      "episode: 1774/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1775/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.2972953915596\n",
      "episode: 1776/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1777/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.344650268554688e-06\n",
      "episode: 1778/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 12.574823796749115\n",
      "episode: 1779/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1780/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1781/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1782/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1783/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1784/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1785/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.4390750527381897\n",
      "episode: 1786/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1787/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.485449135303497\n",
      "episode: 1788/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.001918792724609375\n",
      "episode: 1789/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.015002131462097168\n",
      "episode: 1790/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00019621849060058594\n",
      "episode: 1791/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 14.277619421482086\n",
      "episode: 1792/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1793/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1794/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1795/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1796/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1797/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1798/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1799/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1800/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1801/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1802/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1803/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1804/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1805/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1806/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1807/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.987219095230103\n",
      "episode: 1808/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1809/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976978540420532\n",
      "episode: 1810/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1811/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1812/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.043125152587890625\n",
      "episode: 1813/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1814/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 1815/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1816/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.013903617858886719\n",
      "episode: 1817/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.668439984321594\n",
      "episode: 1818/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 1819/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00010687112808227539\n",
      "episode: 1820/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976669490337372\n",
      "episode: 1821/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.00195038318634\n",
      "episode: 1822/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 1823/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.008998513221740723\n",
      "episode: 1824/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.01579815149307251\n",
      "episode: 1825/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1826/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1827/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.93752658367157\n",
      "episode: 1828/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1829/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1830/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1831/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1832/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1833/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 1834/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1835/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 12.011948823928833\n",
      "episode: 1836/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1837/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1838/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1839/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1840/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1841/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.025918006896973\n",
      "episode: 1842/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1843/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.9498770236969\n",
      "episode: 1844/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.026641368865966797\n",
      "episode: 1845/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976842403411865\n",
      "episode: 1846/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1847/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1848/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1849/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.1397509574890137\n",
      "episode: 1850/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1851/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.1254138946533203\n",
      "episode: 1852/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1853/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0254518985748291\n",
      "episode: 1854/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1855/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.988633632659912\n",
      "episode: 1856/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1857/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1858/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.940696716308594e-07\n",
      "episode: 1859/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1860/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1861/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.50781261920929\n",
      "episode: 1862/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.007712006568908691\n",
      "episode: 1863/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1864/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00010704994201660156\n",
      "episode: 1865/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1866/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1867/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1868/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976674318313599\n",
      "episode: 1869/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1870/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1871/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.98482871055603\n",
      "episode: 1872/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1873/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976595640182495\n",
      "episode: 1874/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.984375\n",
      "episode: 1875/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1876/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.9802322387695312e-06\n",
      "episode: 1877/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1878/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1879/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1880/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1881/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1882/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1883/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1884/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.334186851978302\n",
      "episode: 1885/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1886/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1887/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1888/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.002208709716797\n",
      "episode: 1889/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.814453125\n",
      "episode: 1890/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.140625\n",
      "episode: 1891/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.034490406513214\n",
      "episode: 1892/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1893/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1894/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.073106467723846\n",
      "episode: 1895/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1896/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1897/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1898/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1899/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0006769895553588867\n",
      "episode: 1900/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.5139579772949219e-05\n",
      "episode: 1901/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1902/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1903/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.09607821702957153\n",
      "episode: 1904/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.750384092330933\n",
      "episode: 1905/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1906/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1907/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1908/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.945361733436584\n",
      "episode: 1909/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 1910/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00018799304962158203\n",
      "episode: 1911/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.02480459213256836\n",
      "episode: 1912/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1913/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1914/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1915/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 1916/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1917/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.539143323898315\n",
      "episode: 1918/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 7.23786473274231\n",
      "episode: 1919/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.007883429527282715\n",
      "episode: 1920/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00040334463119506836\n",
      "episode: 1921/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.083534240722656\n",
      "episode: 1922/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.101318418979645\n",
      "episode: 1923/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.004659235477448\n",
      "episode: 1924/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1925/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.2759714126586914\n",
      "episode: 1926/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.93896484375\n",
      "episode: 1927/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1928/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1929/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1930/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.134033203125\n",
      "episode: 1931/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.012737512588500977\n",
      "episode: 1932/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.429824769496918\n",
      "episode: 1933/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1934/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.33180558681488037\n",
      "episode: 1935/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1936/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1937/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1938/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1939/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 4.661083221435547e-05\n",
      "episode: 1940/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.20605307817459106\n",
      "episode: 1941/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1942/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.907707214355469\n",
      "episode: 1943/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.02002197504043579\n",
      "episode: 1944/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1945/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1946/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 1947/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1948/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.996587753295898\n",
      "episode: 1949/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.97700834274292\n",
      "episode: 1950/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.001996159553527832\n",
      "episode: 1951/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1952/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.491957664489746\n",
      "episode: 1953/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 1954/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.9375\n",
      "episode: 1955/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 11.856726586818695\n",
      "episode: 1956/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1957/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1958/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1959/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1960/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1961/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 12.785511374473572\n",
      "episode: 1962/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1963/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1964/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.5497207641601562e-06\n",
      "episode: 1965/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.929907262325287\n",
      "episode: 1966/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00010859966278076172\n",
      "episode: 1967/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1968/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1969/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 1970/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.062219083309174\n",
      "episode: 1971/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.984270453453064\n",
      "episode: 1972/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.01033318042755127\n",
      "episode: 1973/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.017452716827393\n",
      "episode: 1974/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976757049560547\n",
      "episode: 1975/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.993511199951172e-06\n",
      "episode: 1976/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 1977/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1978/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1979/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.307764649391174\n",
      "episode: 1980/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.007323324680328369\n",
      "episode: 1981/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.8477439880371094e-06\n",
      "episode: 1982/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.5669564008712769\n",
      "episode: 1983/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.29485273361206\n",
      "episode: 1984/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1985/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1986/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1987/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1988/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.022054493427277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1989/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1990/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1991/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.96093761920929\n",
      "episode: 1992/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1993/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1994/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 1995/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1996/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1997/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.991958618164062\n",
      "episode: 1998/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1999/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2000/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2001/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2002/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2003/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.183349609375\n",
      "episode: 2004/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2005/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2006/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.968751668930054\n",
      "episode: 2007/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.129852294921875\n",
      "episode: 2008/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.038902342319488525\n",
      "episode: 2009/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2010/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2011/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2012/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2013/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0002722740173339844\n",
      "episode: 2014/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 11.841064453125\n",
      "episode: 2015/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2016/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2017/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2018/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2019/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0048100948333740234\n",
      "episode: 2020/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.017411172389984\n",
      "episode: 2021/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 2022/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.265716552734375\n",
      "episode: 2023/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.0297356247901917\n",
      "episode: 2024/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2025/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2026/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.0831297636032104\n",
      "episode: 2027/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976568639278412\n",
      "episode: 2028/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2029/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2030/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2031/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2032/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2033/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2034/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2035/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.015379548072814941\n",
      "episode: 2036/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 13.453774094581604\n",
      "episode: 2037/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.309208571910858\n",
      "episode: 2038/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2039/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2040/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2041/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.008331120014190674\n",
      "episode: 2042/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2043/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2044/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.007427334785461426\n",
      "episode: 2045/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2046/8000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00019782781600952148\n",
      "episode: 2047/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2048/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.41441410779953\n",
      "episode: 2049/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.022472620010376\n",
      "episode: 2050/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2051/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2052/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.014449536800385\n",
      "episode: 2053/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 4.76837158203125e-07\n",
      "episode: 2054/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2055/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.976569175720215\n",
      "episode: 2056/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.989651501178741\n",
      "episode: 2057/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2058/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.487508535385132\n",
      "episode: 2059/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2060/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2061/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2062/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2063/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.01418614387512207\n",
      "episode: 2064/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2065/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2066/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2067/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 4.291534423828125e-06\n",
      "episode: 2068/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.088302612304688\n",
      "episode: 2069/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 2070/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 8.332796573638916\n",
      "episode: 2071/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2072/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 19.777421534061432\n",
      "episode: 2073/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2074/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2075/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2076/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2077/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00770193338394165\n",
      "episode: 2078/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2079/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.03170371055603\n",
      "episode: 2080/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2081/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 7.910271108150482\n",
      "episode: 2082/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 2083/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2084/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2085/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2086/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2087/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2088/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2089/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2090/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2091/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2092/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2093/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2094/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 7.164627432823181\n",
      "episode: 2095/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2096/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2097/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2098/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2099/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2100/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2101/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.002815186977386\n",
      "episode: 2102/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2103/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2104/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2105/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.953284204006195\n",
      "episode: 2106/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2107/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.5431199669837952\n",
      "episode: 2108/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2109/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2110/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.01447063684463501\n",
      "episode: 2111/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.078369140625\n",
      "episode: 2112/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2113/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2114/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.253923416137695\n",
      "episode: 2115/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 2116/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 4.649162292480469e-06\n",
      "episode: 2117/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2118/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.131603419780731\n",
      "episode: 2119/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.934751749038696\n",
      "episode: 2120/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2121/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2122/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2123/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2124/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2125/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2126/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2127/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.9306640625\n",
      "episode: 2128/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2129/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 2130/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2131/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.828458786010742\n",
      "episode: 2132/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 8.007983207702637\n",
      "episode: 2133/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.228358209133148\n",
      "episode: 2134/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 49.41712373495102\n",
      "episode: 2135/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.984435617923737\n",
      "episode: 2136/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.97656524181366\n",
      "episode: 2137/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2138/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2139/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2140/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.976569652557373\n",
      "episode: 2141/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2142/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 19.859715580940247\n",
      "episode: 2143/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 2144/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2145/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2146/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2147/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.001457333564758\n",
      "episode: 2148/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2149/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2150/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.71875\n",
      "episode: 2151/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2152/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 4.64990234375\n",
      "episode: 2153/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2154/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.02466130256652832\n",
      "episode: 2155/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2156/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2157/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2158/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2159/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2160/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 11.970306396484375\n",
      "episode: 2161/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2162/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2163/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 11.095039367675781\n",
      "episode: 2164/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.989150047302246\n",
      "episode: 2165/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2166/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.985102951526642\n",
      "episode: 2167/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.06323349475860596\n",
      "episode: 2168/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2169/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 13.841842114925385\n",
      "episode: 2170/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.9493408203125\n",
      "episode: 2171/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.8431415557861328e-05\n",
      "episode: 2172/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.820582151412964\n",
      "episode: 2173/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2174/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.3768672943115234e-05\n",
      "episode: 2175/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2176/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.901388168334961e-05\n",
      "episode: 2177/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2178/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.266246259212494\n",
      "episode: 2179/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 12.052297055721283\n",
      "episode: 2180/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.495960474014282\n",
      "episode: 2181/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.86482435464859\n",
      "episode: 2182/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.01451689004898\n",
      "episode: 2183/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2184/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.240158438682556\n",
      "episode: 2185/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2186/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 5.0008296966552734e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2187/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.036648690700531006\n",
      "episode: 2188/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2189/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2190/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2191/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 2192/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2193/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2194/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.177595674991608\n",
      "episode: 2195/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2196/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2197/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.15764617919921875\n",
      "episode: 2198/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2199/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2200/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2201/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2202/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2203/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 23.384811401367188\n",
      "episode: 2204/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 2205/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.004444301128387\n",
      "episode: 2206/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.313894510269165\n",
      "episode: 2207/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.009347379207611\n",
      "episode: 2208/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2209/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 8.79348087310791\n",
      "episode: 2210/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2211/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2212/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2213/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.5374870300292969\n",
      "episode: 2214/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2215/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.997078537940979\n",
      "episode: 2216/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2217/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0201876163482666\n",
      "episode: 2218/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2219/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2220/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.03360879421234131\n",
      "episode: 2221/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2222/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2223/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 7.159810721874237\n",
      "episode: 2224/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.79558789730072\n",
      "episode: 2225/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2226/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2227/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.012244462966918945\n",
      "episode: 2228/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2229/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2230/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.667588710784912\n",
      "episode: 2231/8000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2232/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.989163160324097\n",
      "episode: 2233/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2234/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 7.167387843132019\n",
      "episode: 2235/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2236/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 2237/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.834766387939453e-06\n",
      "episode: 2238/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.484635353088379\n",
      "episode: 2239/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2240/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.984270513057709\n",
      "episode: 2241/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2242/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 7.645672559738159\n",
      "episode: 2243/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2244/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2245/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.023091256618499756\n",
      "episode: 2246/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2247/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0002340078353881836\n",
      "episode: 2248/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.07024002075195312\n",
      "episode: 2249/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2250/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.94539088010788\n",
      "episode: 2251/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2252/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 2253/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2254/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2255/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2256/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2257/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2258/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2259/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.023769795894622803\n",
      "episode: 2260/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.996776103973389\n",
      "episode: 2261/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2262/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2263/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.03691917657852173\n",
      "episode: 2264/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.22739553451538\n",
      "episode: 2265/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 2266/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2267/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2268/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2269/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2270/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2271/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 11.034416198730469\n",
      "episode: 2272/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 2273/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0003935694694519043\n",
      "episode: 2274/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2275/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00020372867584228516\n",
      "episode: 2276/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2277/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.984545707702637\n",
      "episode: 2278/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.996833801269531\n",
      "episode: 2279/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2280/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.989027380943298\n",
      "episode: 2281/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2282/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2283/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 2284/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0464591383934021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2285/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2286/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2287/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2288/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2289/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.07034933567047119\n",
      "episode: 2290/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 2291/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.08120346069336\n",
      "episode: 2292/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2293/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 11.216102600097656\n",
      "episode: 2294/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2295/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2296/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2297/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.011446356773376\n",
      "episode: 2298/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0068206787109375\n",
      "episode: 2299/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2300/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 8.96875\n",
      "episode: 2301/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2302/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2303/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2304/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2305/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.989300012588501\n",
      "episode: 2306/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2307/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2308/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2309/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 11.761990547180176\n",
      "episode: 2310/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 2311/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2312/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.9453125\n",
      "episode: 2313/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2314/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00010162591934204102\n",
      "episode: 2315/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2316/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.6580148935318\n",
      "episode: 2317/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2318/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 6.079673767089844e-06\n",
      "episode: 2319/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 1.430511474609375e-06\n",
      "episode: 2320/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2321/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 2.082770526409149\n",
      "episode: 2322/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.324539184570312\n",
      "episode: 2323/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2324/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976949334144592\n",
      "episode: 2325/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2326/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2327/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 2328/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2329/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2330/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2331/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 5.900859832763672e-06\n",
      "episode: 2332/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.98443979024887\n",
      "episode: 2333/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.03555101156234741\n",
      "episode: 2334/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2335/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.65087890625\n",
      "episode: 2336/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 7.1210938692092896\n",
      "episode: 2337/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2338/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 5.364418029785156e-07\n",
      "episode: 2339/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2340/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2341/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2342/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2343/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 8.323524475097656\n",
      "episode: 2344/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.4670889377594\n",
      "episode: 2345/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.904938280582428\n",
      "episode: 2346/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2347/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 2348/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 11.736404061317444\n",
      "episode: 2349/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2350/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 2.4318695068359375e-05\n",
      "episode: 2351/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2352/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2353/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.03328025341034\n",
      "episode: 2354/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2355/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2356/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2357/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2358/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.357929229736328e-06\n",
      "episode: 2359/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2360/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2361/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2362/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2363/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.98883056640625\n",
      "episode: 2364/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2365/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2366/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2367/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2368/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2369/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2370/8000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2371/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 14.841796875\n",
      "episode: 2372/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.549753189086914\n",
      "episode: 2373/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.221580266952515\n",
      "episode: 2374/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.12807846069335938\n",
      "episode: 2375/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2376/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2377/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2378/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.97684532403946\n",
      "episode: 2379/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.110684394836426\n",
      "episode: 2380/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.007884740829467773\n",
      "episode: 2381/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2382/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2383/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.176666855812073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2384/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.136146545410156\n",
      "episode: 2385/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 6.079673767089844e-06\n",
      "episode: 2386/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 7.632816433906555\n",
      "episode: 2387/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.976782739162445\n",
      "episode: 2388/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2389/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2390/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2391/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.3325424790382385\n",
      "episode: 2392/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 7.5674285888671875\n",
      "episode: 2393/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2394/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 11.974456787109375\n",
      "episode: 2395/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.33841705322265625\n",
      "episode: 2396/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.976673245429993\n",
      "episode: 2397/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2398/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2399/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.032896518707275\n",
      "episode: 2400/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2401/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2402/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2403/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.010092198848724365\n",
      "episode: 2404/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.07011604309082\n",
      "episode: 2405/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.00027370452880859375\n",
      "episode: 2406/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 7.152557373046875e-07\n",
      "episode: 2407/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 11.330078125\n",
      "episode: 2408/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2409/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2410/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2411/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2412/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2413/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2414/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.976842403411865\n",
      "episode: 2415/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.001865804195404\n",
      "episode: 2416/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2417/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.066911697387695\n",
      "episode: 2418/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2419/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2420/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.4458327293396\n",
      "episode: 2421/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2422/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2423/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2424/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2425/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2426/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2427/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 18.854079008102417\n",
      "episode: 2428/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2429/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0478363037109375\n",
      "episode: 2430/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2431/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2432/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 11.95529180765152\n",
      "episode: 2433/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2434/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2435/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2436/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2437/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 6.556510925292969e-07\n",
      "episode: 2438/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2439/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2440/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 2441/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.993837296962738\n",
      "episode: 2442/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2443/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2444/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2445/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 1.3709068298339844e-06\n",
      "episode: 2446/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2447/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.011926293373108\n",
      "episode: 2448/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.04285442829132\n",
      "episode: 2449/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2450/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2451/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2452/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2453/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.03517341613769531\n",
      "episode: 2454/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2455/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2456/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2457/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2458/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 2459/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2460/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2461/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2462/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 12.76995724439621\n",
      "episode: 2463/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 2464/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.6790450811386108\n",
      "episode: 2465/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.4626162052154541\n",
      "episode: 2466/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2467/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 12.247881352901459\n",
      "episode: 2468/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.976682603359222\n",
      "episode: 2469/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2470/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.032888352870941\n",
      "episode: 2471/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2472/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2473/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2474/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 1.430511474609375e-06\n",
      "episode: 2475/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.990320205688477\n",
      "episode: 2476/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.016517519950867\n",
      "episode: 2477/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 4.91796875\n",
      "episode: 2478/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2479/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.97778034210205\n",
      "episode: 2480/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 2481/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.026749730110168457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2482/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0673828125\n",
      "episode: 2483/8000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2484/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2485/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.476825952529907\n",
      "episode: 2486/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.976577341556549\n",
      "episode: 2487/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2488/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2489/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2490/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2491/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2492/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.002992570400238037\n",
      "episode: 2493/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 1.5497207641601562e-06\n",
      "episode: 2494/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2495/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2496/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.961476862430573\n",
      "episode: 2497/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2498/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2499/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.03148227930069\n",
      "episode: 2500/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2501/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2502/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.95077133178711\n",
      "episode: 2503/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2504/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2505/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2506/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2507/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2508/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.011514663696289062\n",
      "episode: 2509/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2510/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2511/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2512/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.02179872989654541\n",
      "episode: 2513/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 7.805073499679565\n",
      "episode: 2514/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.007345020771026611\n",
      "episode: 2515/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.418684422969818\n",
      "episode: 2516/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2517/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 2518/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2519/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2520/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.659332811832428\n",
      "episode: 2521/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2522/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 12.002549827098846\n",
      "episode: 2523/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.907988429069519\n",
      "episode: 2524/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.000276327133179\n",
      "episode: 2525/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2526/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2527/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.976563572883606\n",
      "episode: 2528/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2529/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 94.92367792129517\n",
      "episode: 2530/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 19.72010177373886\n",
      "episode: 2531/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2532/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.894989013671875\n",
      "episode: 2533/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2534/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.05006766319274902\n",
      "episode: 2535/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0010330677032470703\n",
      "episode: 2536/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.490524291992188\n",
      "episode: 2537/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.02022552490234375\n",
      "episode: 2538/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.649991989135742e-05\n",
      "episode: 2539/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2540/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 14.896255135536194\n",
      "episode: 2541/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2542/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 6.198883056640625e-06\n",
      "episode: 2543/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.004080832004547\n",
      "episode: 2544/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2545/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.989684343338013\n",
      "episode: 2546/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 18.81034767627716\n",
      "episode: 2547/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2548/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2549/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2550/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2551/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 2552/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 2.0155786871910095\n",
      "episode: 2553/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.937516987323761\n",
      "episode: 2554/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2555/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.156494140625\n",
      "episode: 2556/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.81258475780487\n",
      "episode: 2557/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2558/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.525295495986938\n",
      "episode: 2559/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 2.8058741092681885\n",
      "episode: 2560/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 17.32966858148575\n",
      "episode: 2561/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2562/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2563/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 7.890731990337372\n",
      "episode: 2564/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.6328125\n",
      "episode: 2565/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2566/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2567/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.485725283622742\n",
      "episode: 2568/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 1.3770899176597595\n",
      "episode: 2569/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2570/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2571/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2572/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.015842676162719727\n",
      "episode: 2573/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.00018799304962158203\n",
      "episode: 2574/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2575/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2576/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2577/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2578/8000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2579/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2580/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.989176392555237\n",
      "episode: 2581/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.991264343261719\n",
      "episode: 2582/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0128326416015625\n",
      "episode: 2583/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.01540440320968628\n",
      "episode: 2584/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2585/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2586/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 3.715331196784973\n",
      "episode: 2587/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2588/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2589/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2590/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.97697389125824\n",
      "episode: 2591/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.01975947618484497\n",
      "episode: 2592/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 7.9803314208984375\n",
      "episode: 2593/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2594/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2595/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 3.083121418952942\n",
      "episode: 2596/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.29637622833252\n",
      "episode: 2597/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.938336849212646\n",
      "episode: 2598/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.976669788360596\n",
      "episode: 2599/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 20.3429217338562\n",
      "episode: 2600/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 1.85986328125\n",
      "episode: 2601/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2602/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2603/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 4.9377763867378235\n",
      "episode: 2604/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2605/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2606/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2607/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2608/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.97657060623169\n",
      "episode: 2609/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2610/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.976569890975952\n",
      "episode: 2611/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2612/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2613/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 8.074031174182892\n",
      "episode: 2614/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2615/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2616/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 2617/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 20.62487953901291\n",
      "episode: 2618/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2619/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 13.669889509677887\n",
      "episode: 2620/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2621/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 12.657278835773468\n",
      "episode: 2622/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2623/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 8.059108257293701\n",
      "episode: 2624/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.029009640216827393\n",
      "episode: 2625/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2626/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2627/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0067244768142700195\n",
      "episode: 2628/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2629/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.976671516895294\n",
      "episode: 2630/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2631/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2632/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2633/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.001918315887451\n",
      "episode: 2634/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 11.969650268554688\n",
      "episode: 2635/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2636/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2637/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2638/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.032958269119262695\n",
      "episode: 2639/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.009696900844573975\n",
      "episode: 2640/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2641/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 2642/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2643/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.028090596199035645\n",
      "episode: 2644/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.03945732116699219\n",
      "episode: 2645/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.801153421401978\n",
      "episode: 2646/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2647/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.025285720825195312\n",
      "episode: 2648/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 6.079673767089844e-06\n",
      "episode: 2649/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2650/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2651/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2652/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.078369140625\n",
      "episode: 2653/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 18.703123152256012\n",
      "episode: 2654/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2655/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 12.759873807430267\n",
      "episode: 2656/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2657/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2658/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2659/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2660/8000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2661/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.3984375\n",
      "episode: 2662/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 12.3538219332695\n",
      "episode: 2663/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2664/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 2665/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2666/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 7.1445313692092896\n",
      "episode: 2667/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2668/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00020003318786621094\n",
      "episode: 2669/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.9775390625\n",
      "episode: 2670/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2671/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2672/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 2673/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2674/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2675/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2676/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2677/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.9506607055664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2678/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2679/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2680/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2681/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.004765093326569\n",
      "episode: 2682/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2683/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2684/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0002224445343017578\n",
      "episode: 2685/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.97703742980957\n",
      "episode: 2686/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2687/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 8.32918119430542\n",
      "episode: 2688/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.017482161521912\n",
      "episode: 2689/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2690/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.984927117824554\n",
      "episode: 2691/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.007983207702636719\n",
      "episode: 2692/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00019681453704833984\n",
      "episode: 2693/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2694/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.614115476608276\n",
      "episode: 2695/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00041604042053222656\n",
      "episode: 2696/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2697/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.028831481933594\n",
      "episode: 2698/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.977047741413116\n",
      "episode: 2699/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2700/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2701/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.9857701063156128\n",
      "episode: 2702/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2703/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2704/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2705/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.329147338867188\n",
      "episode: 2706/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 8.58306884765625e-05\n",
      "episode: 2707/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2708/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.506032943725586\n",
      "episode: 2709/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 12.059490978717804\n",
      "episode: 2710/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.001989424228668213\n",
      "episode: 2711/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 2712/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.156257688999176\n",
      "episode: 2713/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2714/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2715/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 2.4000930786132812\n",
      "episode: 2716/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2717/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2718/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.127920866012573\n",
      "episode: 2719/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.007811129093170166\n",
      "episode: 2720/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2721/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2722/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2723/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2724/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00011086463928222656\n",
      "episode: 2725/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.006851375102996826\n",
      "episode: 2726/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.430038630962372\n",
      "episode: 2727/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 18.9375\n",
      "episode: 2728/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.984928846359253\n",
      "episode: 2729/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.04346954822540283\n",
      "episode: 2730/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2731/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00770336389541626\n",
      "episode: 2732/8000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.1300157904624939\n",
      "episode: 2733/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2734/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.607127010822296\n",
      "episode: 2735/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.98451852798462\n",
      "episode: 2736/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 11.977935791015625\n",
      "episode: 2737/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 1.7285346984863281e-06\n",
      "episode: 2738/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2739/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2740/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 2741/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.27685546875\n",
      "episode: 2742/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.991929948329926\n",
      "episode: 2743/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2744/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.01759284734725952\n",
      "episode: 2745/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.075174152851105\n",
      "episode: 2746/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2747/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2748/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2749/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.00022649765014648438\n",
      "episode: 2750/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 12.807310402393341\n",
      "episode: 2751/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.311874389648438\n",
      "episode: 2752/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.02874290943145752\n",
      "episode: 2753/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2754/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2755/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.976697444915771\n",
      "episode: 2756/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 3.814697265625e-06\n",
      "episode: 2757/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.976675510406494\n",
      "episode: 2758/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.001574277877808\n",
      "episode: 2759/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2760/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2761/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2762/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2763/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2764/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.12487196922302246\n",
      "episode: 2765/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2766/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 2767/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2768/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2769/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 3.814697265625e-06\n",
      "episode: 2770/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.01569342613220215\n",
      "episode: 2771/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0020076632499694824\n",
      "episode: 2772/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2773/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2774/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.482776403427124\n",
      "episode: 2775/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2776/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2777/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 7.171876609325409\n",
      "episode: 2778/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2779/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2780/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2781/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 12.797639548778534\n",
      "episode: 2782/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2783/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.098824918270111\n",
      "episode: 2784/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2785/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2786/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.552598714828491\n",
      "episode: 2787/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.026597142219543\n",
      "episode: 2788/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 15.052563905715942\n",
      "episode: 2789/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2790/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2791/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2792/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.978482365608215\n",
      "episode: 2793/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2794/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.014442205429077\n",
      "episode: 2795/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2796/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2797/8000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.929968178272247\n",
      "episode: 2798/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.487957835197449\n",
      "episode: 2799/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.24306362867355347\n",
      "episode: 2800/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2801/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2802/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2803/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2804/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 2805/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2806/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 10.945068359375\n",
      "episode: 2807/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2808/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2809/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 6.842613220214844e-05\n",
      "episode: 2810/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 2811/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2812/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.008269071578979492\n",
      "episode: 2813/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 2.6702880859375e-05\n",
      "episode: 2814/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2815/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 8.940696716308594e-07\n",
      "episode: 2816/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0002512931823730469\n",
      "episode: 2817/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 11.0556640625\n",
      "episode: 2818/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.00010699033737182617\n",
      "episode: 2819/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2820/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.4689983129501343\n",
      "episode: 2821/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.543220579624176\n",
      "episode: 2822/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2823/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2824/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2825/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.720024585723877\n",
      "episode: 2826/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2827/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 1.4781951904296875e-05\n",
      "episode: 2828/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2829/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976671814918518\n",
      "episode: 2830/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-06\n",
      "episode: 2831/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2832/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 10.045464217662811\n",
      "episode: 2833/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2834/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 12.836109519004822\n",
      "episode: 2835/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 2.0528883934020996\n",
      "episode: 2836/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 10.134183764457703\n",
      "episode: 2837/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2838/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.984648942947388\n",
      "episode: 2839/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 2840/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2841/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 2.1496676206588745\n",
      "episode: 2842/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 7.207798004150391\n",
      "episode: 2843/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2844/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2845/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2846/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2847/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0032052993774414062\n",
      "episode: 2848/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 8.083381414413452\n",
      "episode: 2849/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.024529337882995605\n",
      "episode: 2850/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.914746701717377\n",
      "episode: 2851/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2852/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 19.773009300231934\n",
      "episode: 2853/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2854/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2855/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2856/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 2.7836352586746216\n",
      "episode: 2857/8000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 21.674498915672302\n",
      "episode: 2858/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.01139098405838\n",
      "episode: 2859/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2860/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.101451873779297\n",
      "episode: 2861/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.00728607177734375\n",
      "episode: 2862/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2863/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 13.208160161972046\n",
      "episode: 2864/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2865/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2866/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2867/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2868/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 2.035614013671875\n",
      "episode: 2869/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0008101463317871094\n",
      "episode: 2870/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2871/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2872/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2873/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.00010985136032104492\n",
      "episode: 2874/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2875/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2876/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2877/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 7.0552204847335815\n",
      "episode: 2878/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.945622742176056\n",
      "episode: 2879/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 8.534183502197266\n",
      "episode: 2880/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2881/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.01662302017212\n",
      "episode: 2882/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2883/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 1.2516975402832031e-06\n",
      "episode: 2884/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.016565680503845\n",
      "episode: 2885/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 2886/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2887/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.001277923583984375\n",
      "episode: 2888/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2889/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2890/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2891/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 12.907219111919403\n",
      "episode: 2892/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 2893/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.945398330688477\n",
      "episode: 2894/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 2895/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2896/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.976563572883606\n",
      "episode: 2897/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.64062511920929\n",
      "episode: 2898/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.978488147258759\n",
      "episode: 2899/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.922197818756104\n",
      "episode: 2900/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.08841723203659\n",
      "episode: 2901/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2902/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.547331809997559\n",
      "episode: 2903/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.50775396823883\n",
      "episode: 2904/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2905/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2906/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.934755861759186\n",
      "episode: 2907/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2908/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.110870361328125\n",
      "episode: 2909/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2910/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.032632291316986084\n",
      "episode: 2911/8000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2912/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.026428818702698\n",
      "episode: 2913/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2914/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.12488937377929688\n",
      "episode: 2915/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2916/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2917/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 5.960464477539062e-07\n",
      "episode: 2918/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 11.988768935203552\n",
      "episode: 2919/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.34055042266845703\n",
      "episode: 2920/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.890826284885406\n",
      "episode: 2921/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2922/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2923/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 17.81451904773712\n",
      "episode: 2924/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2925/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2926/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2927/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 6.794929504394531e-06\n",
      "episode: 2928/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.99424397945404\n",
      "episode: 2929/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2930/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2931/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2932/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2933/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 7.654484033584595\n",
      "episode: 2934/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2935/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2936/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.491812348365784\n",
      "episode: 2937/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2938/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 2.8481580018997192\n",
      "episode: 2939/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2940/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 5.732035934925079\n",
      "episode: 2941/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 17.988739848136902\n",
      "episode: 2942/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-06\n",
      "episode: 2943/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.04443526268005371\n",
      "episode: 2944/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2945/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.141542375087738\n",
      "episode: 2946/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.00175279378891\n",
      "episode: 2947/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2948/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 11.997955322265625\n",
      "episode: 2949/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 11.902183532714844\n",
      "episode: 2950/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 2.783525288105011\n",
      "episode: 2951/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2952/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.040849268436431885\n",
      "episode: 2953/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2954/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.5022889375686646\n",
      "episode: 2955/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 7.179654359817505\n",
      "episode: 2956/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2957/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.007779479026794434\n",
      "episode: 2958/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2959/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.000676810741425\n",
      "episode: 2960/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.084716796875\n",
      "episode: 2961/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2962/8000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 2963/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2964/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.17334818840026855\n",
      "episode: 2965/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.14478451013565\n",
      "episode: 2966/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2967/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.026336610317230225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2968/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2969/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 1.9775662422180176\n",
      "episode: 2970/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2971/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.97656625509262\n",
      "episode: 2972/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.04286813735961914\n",
      "episode: 2973/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2974/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 1.813856303691864\n",
      "episode: 2975/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.988977134227753\n",
      "episode: 2976/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.984776318073273\n",
      "episode: 2977/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.918749511241913\n",
      "episode: 2978/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2979/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2980/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2981/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2982/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.010301291942596\n",
      "episode: 2983/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.718855619430542\n",
      "episode: 2984/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2985/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.019952237606048584\n",
      "episode: 2986/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.004883766174316\n",
      "episode: 2987/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2988/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2989/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2990/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.978552281856537\n",
      "episode: 2991/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.017980098724365\n",
      "episode: 2992/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2993/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2994/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2995/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.97667247056961\n",
      "episode: 2996/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2997/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0024129748344421387\n",
      "episode: 2998/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2999/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 3000/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.021310508251190186\n",
      "episode: 3001/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.977035284042358\n",
      "episode: 3002/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3003/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.46177327632904\n",
      "episode: 3004/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.021151363849639893\n",
      "episode: 3005/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3006/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 12.009812593460083\n",
      "episode: 3007/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.977232873439789\n",
      "episode: 3008/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3009/8000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3010/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0077056884765625\n",
      "episode: 3011/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3012/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.985208630561829\n",
      "episode: 3013/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.966825246810913\n",
      "episode: 3014/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.985137939453125\n",
      "episode: 3015/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 3016/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3017/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.00012421607971191406\n",
      "episode: 3018/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.337150812149048\n",
      "episode: 3019/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.854964315891266\n",
      "episode: 3020/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.349381804466248\n",
      "episode: 3021/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3022/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3023/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.479873657226562\n",
      "episode: 3024/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.195404529571533\n",
      "episode: 3025/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 8.040160953998566\n",
      "episode: 3026/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3027/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.036443114280700684\n",
      "episode: 3028/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3029/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 6.425903558731079\n",
      "episode: 3030/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3031/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3032/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3033/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3034/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3035/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 6.29722273349762\n",
      "episode: 3036/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 20.315133571624756\n",
      "episode: 3037/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3038/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3039/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3040/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3041/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3042/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3043/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0024770498275756836\n",
      "episode: 3044/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.945594131946564\n",
      "episode: 3045/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.78920829296112\n",
      "episode: 3046/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.927292823791504\n",
      "episode: 3047/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3048/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3049/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3050/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.253695011138916\n",
      "episode: 3051/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 4.1365623474121094e-05\n",
      "episode: 3052/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.000275075435638\n",
      "episode: 3053/8000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 14.036245346069336\n",
      "episode: 3054/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3055/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3056/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3057/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.914068520069122\n",
      "episode: 3058/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 3059/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.484640121459961\n",
      "episode: 3060/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3061/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.456972122192383\n",
      "episode: 3062/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3063/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3064/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3065/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 8.132818579673767\n",
      "episode: 3066/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 7.156846821308136\n",
      "episode: 3067/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 10.008424639701843\n",
      "episode: 3068/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.882816851139069\n",
      "episode: 3069/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3070/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.445100128650665\n",
      "episode: 3071/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 8.293473839759827\n",
      "episode: 3072/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 2.181529998779297e-05\n",
      "episode: 3073/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3074/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3075/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3076/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3077/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.15764617919921875\n",
      "episode: 3078/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.727111339569092\n",
      "episode: 3079/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3080/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3081/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3082/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 10.000006198883057\n",
      "episode: 3083/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3084/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3085/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 11.669464111328125\n",
      "episode: 3086/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3087/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.988887071609497\n",
      "episode: 3088/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3089/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 12.832632541656494\n",
      "episode: 3090/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.06056618690490723\n",
      "episode: 3091/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 10.0106201171875\n",
      "episode: 3092/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3093/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3094/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.349927127361298\n",
      "episode: 3095/8000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.989329814910889\n",
      "episode: 3096/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 2.79296875\n",
      "episode: 3097/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3098/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.00010699033737182617\n",
      "episode: 3099/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3100/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 3101/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3102/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3103/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3104/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3105/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3106/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.010294079780578613\n",
      "episode: 3107/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3108/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3109/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3110/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3111/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.000246524810791\n",
      "episode: 3112/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 13.506737768650055\n",
      "episode: 3113/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 12.774706840515137\n",
      "episode: 3114/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.496531009674072\n",
      "episode: 3115/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 3116/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 20.825094163417816\n",
      "episode: 3117/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 3118/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3119/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.126565337181091\n",
      "episode: 3120/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 2.801125645637512\n",
      "episode: 3121/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3122/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.84386146068573\n",
      "episode: 3123/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3124/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3125/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.445321440696716\n",
      "episode: 3126/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3127/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.00038039684295654297\n",
      "episode: 3128/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.284246683120728\n",
      "episode: 3129/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 18.052713096141815\n",
      "episode: 3130/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3131/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.984550416469574\n",
      "episode: 3132/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 3133/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.563150882720947\n",
      "episode: 3134/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 4.618408203125\n",
      "episode: 3135/8000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.984272003173828\n",
      "episode: 3136/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3137/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3138/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.832283020019531\n",
      "episode: 3139/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3140/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3141/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.942476511001587\n",
      "episode: 3142/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 3143/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.164078414440155\n",
      "episode: 3144/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976670682430267\n",
      "episode: 3145/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.020191192626953125\n",
      "episode: 3146/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3147/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976569294929504\n",
      "episode: 3148/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3149/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3150/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 2.1627960205078125\n",
      "episode: 3151/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3152/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 20.050559043884277\n",
      "episode: 3153/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.504172563552856\n",
      "episode: 3154/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3155/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3156/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3157/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.135518908500671\n",
      "episode: 3158/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 215.67628169059753\n",
      "episode: 3159/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3160/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3161/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3162/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3163/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 1.9785089492797852\n",
      "episode: 3164/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.353209614753723\n",
      "episode: 3165/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 3166/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3167/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 3168/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.476666390895844\n",
      "episode: 3169/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.273905515670776\n",
      "episode: 3170/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 7.170794785022736\n",
      "episode: 3171/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976571202278137\n",
      "episode: 3172/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3173/8000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3174/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 3175/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3176/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 1.22406005859375\n",
      "episode: 3177/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 3.814697265625e-06\n",
      "episode: 3178/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3179/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3180/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.491858005523682\n",
      "episode: 3181/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.013160407543182373\n",
      "episode: 3182/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3183/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 3184/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3185/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3186/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 3187/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 2.0886608362197876\n",
      "episode: 3188/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3189/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 5.01852285861969\n",
      "episode: 3190/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 3191/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3192/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3193/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3194/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.976842641830444\n",
      "episode: 3195/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.99756246805191\n",
      "episode: 3196/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0022707581520080566\n",
      "episode: 3197/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3198/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.531336009502411\n",
      "episode: 3199/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 5.245208740234375e-06\n",
      "episode: 3200/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.84375\n",
      "episode: 3201/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0012483596801757812\n",
      "episode: 3202/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3203/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.976564109325409\n",
      "episode: 3204/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3205/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 38.99284762144089\n",
      "episode: 3206/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3207/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0004519820213317871\n",
      "episode: 3208/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3209/8000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 8.000234007835388\n",
      "episode: 3210/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3211/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.984267175197601\n",
      "episode: 3212/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0017514824867248535\n",
      "episode: 3213/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3214/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3215/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 17.129176139831543\n",
      "episode: 3216/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3217/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 7.17742395401001\n",
      "episode: 3218/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3219/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.984595477581024\n",
      "episode: 3220/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 19.632899165153503\n",
      "episode: 3221/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3222/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.00043851137161254883\n",
      "episode: 3223/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3224/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.976670980453491\n",
      "episode: 3225/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3226/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.945312559604645\n",
      "episode: 3227/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.984270513057709\n",
      "episode: 3228/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 2.859374463558197\n",
      "episode: 3229/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 7.6210949420928955\n",
      "episode: 3230/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.99675989151001\n",
      "episode: 3231/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.1510772705078125\n",
      "episode: 3232/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 13.105267524719238\n",
      "episode: 3233/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 10.139404296875\n",
      "episode: 3234/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 12.951312780380249\n",
      "episode: 3235/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3236/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.976569056510925\n",
      "episode: 3237/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3238/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 3239/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3240/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.988980948925018\n",
      "episode: 3241/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.98643010854721\n",
      "episode: 3242/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 15.769287109375\n",
      "episode: 3243/8000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3244/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.726249694824219\n",
      "episode: 3245/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3246/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.687501668930054\n",
      "episode: 3247/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.06569713354110718\n",
      "episode: 3248/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.92979645729065\n",
      "episode: 3249/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3250/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3251/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3252/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.985333621501923\n",
      "episode: 3253/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3254/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3255/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.991546154022217\n",
      "episode: 3256/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3257/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 19.922432363033295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3258/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3259/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3260/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 8.020625591278076\n",
      "episode: 3261/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.5503196716308594\n",
      "episode: 3262/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.491964638233185\n",
      "episode: 3263/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.976874709129333\n",
      "episode: 3264/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 10.013281404972076\n",
      "episode: 3265/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 2.1278858184814453e-05\n",
      "episode: 3266/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3267/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3268/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3269/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3270/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3271/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 10.5556640625\n",
      "episode: 3272/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.968750059604645\n",
      "episode: 3273/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.00036346912384033203\n",
      "episode: 3274/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.001918792724609375\n",
      "episode: 3275/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 19.95351207256317\n",
      "episode: 3276/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 8.0056272149086\n",
      "episode: 3277/8000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 11.969936192035675\n",
      "episode: 3278/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.976835250854492\n",
      "episode: 3279/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.012422859668732\n",
      "episode: 3280/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 1.866515576839447\n",
      "episode: 3281/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.85189700126648\n",
      "episode: 3282/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.99653935432434\n",
      "episode: 3283/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3284/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.673374891281128\n",
      "episode: 3285/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.914168894290924\n",
      "episode: 3286/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3287/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.5367431640625e-07\n",
      "episode: 3288/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3289/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3290/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.321087837219238\n",
      "episode: 3291/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.020304858684539795\n",
      "episode: 3292/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3293/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 3294/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 1.430511474609375e-06\n",
      "episode: 3295/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3296/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.01880031824112\n",
      "episode: 3297/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 20.012772738933563\n",
      "episode: 3298/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 11.849647521972656\n",
      "episode: 3299/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.3016357421875\n",
      "episode: 3300/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.445344984531403\n",
      "episode: 3301/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 19.664071023464203\n",
      "episode: 3302/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.030355393886566162\n",
      "episode: 3303/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3304/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 3305/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.989392757415771\n",
      "episode: 3306/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.452739298343658\n",
      "episode: 3307/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3308/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.99686586856842\n",
      "episode: 3309/8000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.3462834358215332\n",
      "episode: 3310/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 1.878079354763031\n",
      "episode: 3311/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.8984375\n",
      "episode: 3312/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3313/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 10.023339867591858\n",
      "episode: 3314/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3315/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3316/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.150357246398926\n",
      "episode: 3317/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3318/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 10.309212386608124\n",
      "episode: 3319/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3320/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 2.000515103340149\n",
      "episode: 3321/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3322/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3323/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.015280723571777344\n",
      "episode: 3324/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.48001939058303833\n",
      "episode: 3325/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.99221396446228\n",
      "episode: 3326/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3327/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 10.488533616065979\n",
      "episode: 3328/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 4.923904001712799\n",
      "episode: 3329/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 3330/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3331/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3332/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3333/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3334/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3335/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.976619124412537\n",
      "episode: 3336/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 1.1188673973083496\n",
      "episode: 3337/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3338/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.08320152759552002\n",
      "episode: 3339/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3340/8000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.32554394006729126\n",
      "episode: 3341/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0015660524368286133\n",
      "episode: 3342/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 11.051769375801086\n",
      "episode: 3343/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.030066967010498\n",
      "episode: 3344/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.92969125509262\n",
      "episode: 3345/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.3984375\n",
      "episode: 3346/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.009399950504302979\n",
      "episode: 3347/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3348/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.978466033935547\n",
      "episode: 3349/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3350/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3351/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.00031697750091552734\n",
      "episode: 3352/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3353/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3354/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 3355/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3356/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3357/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3358/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 3359/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3360/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3361/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.312016248703003\n",
      "episode: 3362/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.993793487548828\n",
      "episode: 3363/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 24.0703125\n",
      "episode: 3364/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0019197463989257812\n",
      "episode: 3365/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 57.058954894542694\n",
      "episode: 3366/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3367/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.976669490337372\n",
      "episode: 3368/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3369/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 2.0315160155296326\n",
      "episode: 3370/8000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.017285823822021484\n",
      "episode: 3371/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.4453125\n",
      "episode: 3372/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 1.2099742889404297e-05\n",
      "episode: 3373/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3374/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.001967906951904\n",
      "episode: 3375/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3376/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.30982106924057\n",
      "episode: 3377/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3378/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.986365735530853\n",
      "episode: 3379/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3380/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.945651292800903\n",
      "episode: 3381/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3382/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.013115644454956\n",
      "episode: 3383/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.86367416381836\n",
      "episode: 3384/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3385/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3386/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3387/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.984344482421875\n",
      "episode: 3388/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3389/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3390/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.01300048828125\n",
      "episode: 3391/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3392/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3393/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3394/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 17.348657846450806\n",
      "episode: 3395/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3396/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3397/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3398/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.976562678813934\n",
      "episode: 3399/8000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.0013108253479\n",
      "episode: 3400/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.882813513278961\n",
      "episode: 3401/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 7.1885058879852295\n",
      "episode: 3402/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.988838195800781\n",
      "episode: 3403/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.992424249649048\n",
      "episode: 3404/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3405/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.002029418945312\n",
      "episode: 3406/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3407/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.968750238418579\n",
      "episode: 3408/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3409/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3410/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3411/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 1.708558201789856\n",
      "episode: 3412/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 3413/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3414/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 1.9775390625\n",
      "episode: 3415/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 3416/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 12.76017451286316\n",
      "episode: 3417/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.97678530216217\n",
      "episode: 3418/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.976569294929504\n",
      "episode: 3419/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.976880073547363\n",
      "episode: 3420/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.007699489593505859\n",
      "episode: 3421/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.000402688980103\n",
      "episode: 3422/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3423/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3424/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.976862907409668\n",
      "episode: 3425/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 6.556510925292969e-07\n",
      "episode: 3426/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.976672530174255\n",
      "episode: 3427/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.881500244140625\n",
      "episode: 3428/8000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 1.6510486602783203e-05\n",
      "episode: 3429/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.026948928833008\n",
      "episode: 3430/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3431/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.43750011920929\n",
      "episode: 3432/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3433/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.360595703125\n",
      "episode: 3434/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.010589599609375\n",
      "episode: 3435/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3436/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 8.738945126533508\n",
      "episode: 3437/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.311874389648438\n",
      "episode: 3438/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3439/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.203166604042053\n",
      "episode: 3440/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.009348332881927\n",
      "episode: 3441/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.87649941444397\n",
      "episode: 3442/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 17.973039865493774\n",
      "episode: 3443/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.955078125\n",
      "episode: 3444/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3445/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.345683217048645\n",
      "episode: 3446/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.011379718780518\n",
      "episode: 3447/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 12.310906052589417\n",
      "episode: 3448/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.044921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3449/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3450/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3451/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.734026670455933\n",
      "episode: 3452/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3453/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.026956260204315\n",
      "episode: 3454/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3455/8000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3456/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.984375\n",
      "episode: 3457/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 3458/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.977779865264893\n",
      "episode: 3459/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.992692589759827\n",
      "episode: 3460/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.976564943790436\n",
      "episode: 3461/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 17.65669310092926\n",
      "episode: 3462/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 19.64575558900833\n",
      "episode: 3463/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 10.196884870529175\n",
      "episode: 3464/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 8.345055222511292\n",
      "episode: 3465/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 3466/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3467/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.990078508853912\n",
      "episode: 3468/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 18.359749794006348\n",
      "episode: 3469/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 2.7871742248535156\n",
      "episode: 3470/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.984713077545166\n",
      "episode: 3471/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3472/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3473/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3474/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.929960012435913\n",
      "episode: 3475/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.979599177837372\n",
      "episode: 3476/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 8.535385131835938e-05\n",
      "episode: 3477/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.992525935173035\n",
      "episode: 3478/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.984111309051514\n",
      "episode: 3479/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.02284640073776245\n",
      "episode: 3480/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3481/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 7.179749548435211\n",
      "episode: 3482/8000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3483/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 3484/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3485/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.672099888324738\n",
      "episode: 3486/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3487/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3488/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.976645171642303\n",
      "episode: 3489/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3490/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3491/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3492/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3493/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 11.954514622688293\n",
      "episode: 3494/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.026482105255126953\n",
      "episode: 3495/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3496/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3497/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3498/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.997026264667511\n",
      "episode: 3499/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3500/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3501/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3502/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3503/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 19.965720415115356\n",
      "episode: 3504/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 12.304582476615906\n",
      "episode: 3505/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 33.671927869319916\n",
      "episode: 3506/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3507/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 15.428623795509338\n",
      "episode: 3508/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3509/8000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 2.2292137145996094e-05\n",
      "episode: 3510/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3511/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3512/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3513/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.692420423030853\n",
      "episode: 3514/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.00037086009979248047\n",
      "episode: 3515/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.126508951187134\n",
      "episode: 3516/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 8.466361343860626\n",
      "episode: 3517/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.97658920288086\n",
      "episode: 3518/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.995779991149902\n",
      "episode: 3519/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3520/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 3521/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.996757507324219\n",
      "episode: 3522/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0004055500030517578\n",
      "episode: 3523/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.994869232177734\n",
      "episode: 3524/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 1.965395212173462\n",
      "episode: 3525/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3526/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 16.252443253993988\n",
      "episode: 3527/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3528/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.335582852363586\n",
      "episode: 3529/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3530/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.98577880859375\n",
      "episode: 3531/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3532/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.000519037246704\n",
      "episode: 3533/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 3534/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.988989293575287\n",
      "episode: 3535/8000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 7.226326823234558\n",
      "episode: 3536/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3537/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.47509765625\n",
      "episode: 3538/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 20.282654762268066\n",
      "episode: 3539/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3540/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3541/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.976725339889526\n",
      "episode: 3542/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3543/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3544/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.984364688396454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3545/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.06890654563903809\n",
      "episode: 3546/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3547/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3548/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3549/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.104968070983887\n",
      "episode: 3550/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0006254315376281738\n",
      "episode: 3551/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3552/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3553/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3554/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.976840019226074\n",
      "episode: 3555/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.012760281562805\n",
      "episode: 3556/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3557/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.006794929504395\n",
      "episode: 3558/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 17.25157141685486\n",
      "episode: 3559/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.988847076892853\n",
      "episode: 3560/8000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.906521797180176\n",
      "episode: 3561/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3562/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 3563/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.976672768592834\n",
      "episode: 3564/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.437165141105652\n",
      "episode: 3565/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.97679477930069\n",
      "episode: 3566/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.992348790168762\n",
      "episode: 3567/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3568/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.959106504917145\n",
      "episode: 3569/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0024183988571166992\n",
      "episode: 3570/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.890822052955627\n",
      "episode: 3571/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3572/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 10.000289916992188\n",
      "episode: 3573/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.578125298023224\n",
      "episode: 3574/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.9296875\n",
      "episode: 3575/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3576/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.976650655269623\n",
      "episode: 3577/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.054091572761535645\n",
      "episode: 3578/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 3579/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.75996321439743\n",
      "episode: 3580/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3581/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 10.009482026100159\n",
      "episode: 3582/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 10.03919380903244\n",
      "episode: 3583/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.946239054203033\n",
      "episode: 3584/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.007340490818023682\n",
      "episode: 3585/8000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3586/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3587/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.953232169151306\n",
      "episode: 3588/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0011883378028869629\n",
      "episode: 3589/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 3590/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.976663410663605\n",
      "episode: 3591/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 10.284633874893188\n",
      "episode: 3592/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 13.300272107124329\n",
      "episode: 3593/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.977184116840363\n",
      "episode: 3594/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3595/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 3596/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 19.645377695560455\n",
      "episode: 3597/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.164068579673767\n",
      "episode: 3598/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.00019103288650512695\n",
      "episode: 3599/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3600/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 8.96875\n",
      "episode: 3601/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 10.054579317569733\n",
      "episode: 3602/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 17.125000059604645\n",
      "episode: 3603/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.976562678813934\n",
      "episode: 3604/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.00048172473907470703\n",
      "episode: 3605/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 17.684724509716034\n",
      "episode: 3606/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 3607/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.00010901689529418945\n",
      "episode: 3608/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.004612565040588379\n",
      "episode: 3609/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 10.420041501522064\n",
      "episode: 3610/8000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3611/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.984376549720764\n",
      "episode: 3612/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.953136444091797\n",
      "episode: 3613/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3614/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 5.4836273193359375e-06\n",
      "episode: 3615/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 10.1459681391716\n",
      "episode: 3616/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.984264433383942\n",
      "episode: 3617/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 10.007956385612488\n",
      "episode: 3618/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3619/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3620/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3621/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 22.53375244140625\n",
      "episode: 3622/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 7.240657806396484\n",
      "episode: 3623/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3624/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.007703423500061035\n",
      "episode: 3625/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.20800751447677612\n",
      "episode: 3626/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.976948022842407\n",
      "episode: 3627/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.984274923801422\n",
      "episode: 3628/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3629/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.492193281650543\n",
      "episode: 3630/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.984260559082031\n",
      "episode: 3631/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.988882422447205\n",
      "episode: 3632/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.976567804813385\n",
      "episode: 3633/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 10.551660358905792\n",
      "episode: 3634/8000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3635/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 21.94357717037201\n",
      "episode: 3636/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3637/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 3.0994415283203125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3638/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.976675152778625\n",
      "episode: 3639/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3640/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.992248058319092\n",
      "episode: 3641/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.67995309829712\n",
      "episode: 3642/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 1.807861328125\n",
      "episode: 3643/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.985055208206177\n",
      "episode: 3644/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.988984405994415\n",
      "episode: 3645/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3646/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 1.9780882000923157\n",
      "episode: 3647/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.981369197368622\n",
      "episode: 3648/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3649/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.008143007755279541\n",
      "episode: 3650/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.992387413978577\n",
      "episode: 3651/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 3652/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3653/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 3654/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3655/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.984823882579803\n",
      "episode: 3656/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.977027177810669\n",
      "episode: 3657/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 12.202811479568481\n",
      "episode: 3658/8000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.976674199104309\n",
      "episode: 3659/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 11.942842483520508\n",
      "episode: 3660/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 16.6796875\n",
      "episode: 3661/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.33568811416625977\n",
      "episode: 3662/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.986366212368011\n",
      "episode: 3663/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 3664/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3665/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 10.171180725097656\n",
      "episode: 3666/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 10.042779922485352\n",
      "episode: 3667/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 11.42226791381836\n",
      "episode: 3668/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3669/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3670/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 3671/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.976568281650543\n",
      "episode: 3672/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.2637733817100525\n",
      "episode: 3673/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.978423118591309\n",
      "episode: 3674/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 7.0976563692092896\n",
      "episode: 3675/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.837141335010529\n",
      "episode: 3676/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 12.901070952415466\n",
      "episode: 3677/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3678/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.976448476314545\n",
      "episode: 3679/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 16.975516140460968\n",
      "episode: 3680/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 10.00784170627594\n",
      "episode: 3681/8000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.525360941886902\n",
      "episode: 3682/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.311874389648438\n",
      "episode: 3683/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.030948042869568\n",
      "episode: 3684/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 2.8014183044433594e-06\n",
      "episode: 3685/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.488521814346313\n",
      "episode: 3686/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.476563930511475\n",
      "episode: 3687/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 2.772721827030182\n",
      "episode: 3688/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.004722595214844\n",
      "episode: 3689/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3690/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3691/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.68414956331253\n",
      "episode: 3692/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.538713812828064\n",
      "episode: 3693/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.161775946617126\n",
      "episode: 3694/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 3695/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3696/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3697/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 3698/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.976568639278412\n",
      "episode: 3699/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 3700/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 10.015945494174957\n",
      "episode: 3701/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.444949924945831\n",
      "episode: 3702/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.00010699033737182617\n",
      "episode: 3703/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 3704/8000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3705/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 12.349959671497345\n",
      "episode: 3706/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.978553712368011\n",
      "episode: 3707/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.984272062778473\n",
      "episode: 3708/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.976562857627869\n",
      "episode: 3709/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3710/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.976701855659485\n",
      "episode: 3711/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3712/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.968856871128082\n",
      "episode: 3713/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3714/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 10.324634671211243\n",
      "episode: 3715/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.00029653310775756836\n",
      "episode: 3716/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 3717/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 29.01672798395157\n",
      "episode: 3718/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 8.009803235530853\n",
      "episode: 3719/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.976572275161743\n",
      "episode: 3720/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3721/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3722/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 10.109192967414856\n",
      "episode: 3723/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3724/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3725/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.00030612945556640625\n",
      "episode: 3726/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 22.00039780139923\n",
      "episode: 3727/8000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 3728/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 12.742653846740723\n",
      "episode: 3729/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3730/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.48363733291626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3731/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3732/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 10.505384087562561\n",
      "episode: 3733/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.11892282962799072\n",
      "episode: 3734/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.546875\n",
      "episode: 3735/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 10.01797366142273\n",
      "episode: 3736/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3737/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 3738/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3739/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3740/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.48403775691986\n",
      "episode: 3741/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.5942011475563049\n",
      "episode: 3742/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3743/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.97722041606903\n",
      "episode: 3744/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3745/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3746/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3747/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 2.248046875\n",
      "episode: 3748/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 3.314018249511719e-05\n",
      "episode: 3749/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3750/8000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 10.118418037891388\n",
      "episode: 3751/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 3752/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3753/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3754/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 10.000474691390991\n",
      "episode: 3755/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 22.80462658405304\n",
      "episode: 3756/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 8.96875\n",
      "episode: 3757/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3758/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 10.268967747688293\n",
      "episode: 3759/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.990190029144287\n",
      "episode: 3760/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.1642826795578\n",
      "episode: 3761/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3762/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3763/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.984266877174377\n",
      "episode: 3764/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3765/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.98883068561554\n",
      "episode: 3766/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3767/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3768/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.976878821849823\n",
      "episode: 3769/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 10.479873657226562\n",
      "episode: 3770/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 12.773484706878662\n",
      "episode: 3771/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3772/8000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 10.223767518997192\n",
      "episode: 3773/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 3774/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 12.767473816871643\n",
      "episode: 3775/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.6328125\n",
      "episode: 3776/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 2.0805739760398865\n",
      "episode: 3777/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 3.551788330078125\n",
      "episode: 3778/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.085174083709717\n",
      "episode: 3779/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3780/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3781/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.017629146575928\n",
      "episode: 3782/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.01879769563675\n",
      "episode: 3783/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3784/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.98427426815033\n",
      "episode: 3785/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3786/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.976566195487976\n",
      "episode: 3787/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.017476081848145\n",
      "episode: 3788/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.823452889919281\n",
      "episode: 3789/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.976949393749237\n",
      "episode: 3790/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.004746079444885\n",
      "episode: 3791/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3792/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.984270513057709\n",
      "episode: 3793/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3794/8000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3795/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3796/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 3797/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.6328125\n",
      "episode: 3798/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.976861834526062\n",
      "episode: 3799/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.890654921531677\n",
      "episode: 3800/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 7.987022399902344e-06\n",
      "episode: 3801/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.976840019226074\n",
      "episode: 3802/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.4453125\n",
      "episode: 3803/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3804/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.968859314918518\n",
      "episode: 3805/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 7.144639730453491\n",
      "episode: 3806/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3807/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.984265923500061\n",
      "episode: 3808/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.476562559604645\n",
      "episode: 3809/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 11.065143346786499\n",
      "episode: 3810/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3811/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 10.019303679466248\n",
      "episode: 3812/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.71875149011612\n",
      "episode: 3813/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.968869864940643\n",
      "episode: 3814/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3815/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 12.007895231246948\n",
      "episode: 3816/8000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3817/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.97684234380722\n",
      "episode: 3818/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3819/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3820/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 5.3515625\n",
      "episode: 3821/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3822/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3823/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.981057703495026\n",
      "episode: 3824/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3825/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.00010883808135986328\n",
      "episode: 3826/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3827/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3828/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3829/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.996856808662415\n",
      "episode: 3830/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3831/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 1.9419309496879578\n",
      "episode: 3832/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 10.000436782836914\n",
      "episode: 3833/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 10.000699520111084\n",
      "episode: 3834/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.890931606292725\n",
      "episode: 3835/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.010229289531707764\n",
      "episode: 3836/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 7.648773670196533\n",
      "episode: 3837/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3838/8000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3839/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 2.7832459807395935\n",
      "episode: 3840/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3841/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3842/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 9.690017342567444\n",
      "episode: 3843/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.199325561523438\n",
      "episode: 3844/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.009346008300781\n",
      "episode: 3845/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 8.967470169067383\n",
      "episode: 3846/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3847/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 3.425984740257263\n",
      "episode: 3848/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 9.976944744586945\n",
      "episode: 3849/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 7.161490082740784\n",
      "episode: 3850/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3851/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3852/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.336263179779053\n",
      "episode: 3853/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.494283199310303\n",
      "episode: 3854/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3855/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 103.84722542762756\n",
      "episode: 3856/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.055631875991821\n",
      "episode: 3857/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 8.0078125\n",
      "episode: 3858/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 9.976840496063232\n",
      "episode: 3859/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 9.996903419494629\n",
      "episode: 3860/8000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.113578796386719\n",
      "episode: 3861/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3862/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 12.496833086013794\n",
      "episode: 3863/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.88303542137146\n",
      "episode: 3864/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3865/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.989313244819641\n",
      "episode: 3866/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3867/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 19.867197394371033\n",
      "episode: 3868/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 19.875022888183594\n",
      "episode: 3869/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.976762890815735\n",
      "episode: 3870/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 12.558743476867676\n",
      "episode: 3871/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3872/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 10.004838466644287\n",
      "episode: 3873/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 10.630554437637329\n",
      "episode: 3874/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.484375059604645\n",
      "episode: 3875/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3876/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3877/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.914104163646698\n",
      "episode: 3878/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3879/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3880/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 3881/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3882/8000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3883/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.17773962020874\n",
      "episode: 3884/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.1830769181251526\n",
      "episode: 3885/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 10.020033478736877\n",
      "episode: 3886/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.976835489273071\n",
      "episode: 3887/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.945405423641205\n",
      "episode: 3888/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 20.16549688577652\n",
      "episode: 3889/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.883083581924438\n",
      "episode: 3890/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.989161491394043\n",
      "episode: 3891/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 14.579345703125\n",
      "episode: 3892/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 27.07149350643158\n",
      "episode: 3893/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.011003494262695312\n",
      "episode: 3894/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3895/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 3896/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 12.762107133865356\n",
      "episode: 3897/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.991419792175293\n",
      "episode: 3898/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.984270513057709\n",
      "episode: 3899/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 10.008635520935059\n",
      "episode: 3900/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.976669430732727\n",
      "episode: 3901/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 10.305469989776611\n",
      "episode: 3902/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 20.284324645996094\n",
      "episode: 3903/8000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 11.909717500209808\n",
      "episode: 3904/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.012240827083588\n",
      "episode: 3905/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3906/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.006695210933685303\n",
      "episode: 3907/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.984650135040283\n",
      "episode: 3908/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.329147338867188\n",
      "episode: 3909/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3910/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.976873457431793\n",
      "episode: 3911/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 24.951640963554382\n",
      "episode: 3912/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.898828864097595\n",
      "episode: 3913/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 12.668067634105682\n",
      "episode: 3914/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.01574993133544922\n",
      "episode: 3915/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.976563215255737\n",
      "episode: 3916/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.978592932224274\n",
      "episode: 3917/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.4460580348968506\n",
      "episode: 3918/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.98426479101181\n",
      "episode: 3919/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.98886889219284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3920/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 4.023576259613037\n",
      "episode: 3921/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.52622675895691\n",
      "episode: 3922/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 3923/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.006229400634766\n",
      "episode: 3924/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3925/8000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 8.710542261600494\n",
      "episode: 3926/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3927/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3928/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3929/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 24.97695940732956\n",
      "episode: 3930/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3931/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 12.057417869567871\n",
      "episode: 3932/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.992248058319092\n",
      "episode: 3933/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 10.070428013801575\n",
      "episode: 3934/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 14.7470703125\n",
      "episode: 3935/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 10.747478723526001\n",
      "episode: 3936/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.92972081899643\n",
      "episode: 3937/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 10.186311483383179\n",
      "episode: 3938/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.978471517562866\n",
      "episode: 3939/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 8.731673419475555\n",
      "episode: 3940/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.96112596988678\n",
      "episode: 3941/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 10.027881026268005\n",
      "episode: 3942/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.976797819137573\n",
      "episode: 3943/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3944/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3945/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 8.420237183570862\n",
      "episode: 3946/8000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 17.19021701812744\n",
      "episode: 3947/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 3948/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.04299861192703247\n",
      "episode: 3949/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.31816720962524414\n",
      "episode: 3950/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.093236088752747\n",
      "episode: 3951/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3952/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.025843501091003\n",
      "episode: 3953/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.487784445285797\n",
      "episode: 3954/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.988477230072021\n",
      "episode: 3955/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 11.09152364730835\n",
      "episode: 3956/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.976574003696442\n",
      "episode: 3957/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.149128794670105\n",
      "episode: 3958/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3959/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3960/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 12.011678457260132\n",
      "episode: 3961/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3962/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3963/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.087599992752075\n",
      "episode: 3964/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.488732039928436\n",
      "episode: 3965/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.97683572769165\n",
      "episode: 3966/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 3967/8000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.027237892150878906\n",
      "episode: 3968/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3969/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3970/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3971/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 3972/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 1.0779632925987244\n",
      "episode: 3973/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3974/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 12.822427988052368\n",
      "episode: 3975/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 10.107435584068298\n",
      "episode: 3976/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.992251813411713\n",
      "episode: 3977/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3978/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3979/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3980/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 29.152156710624695\n",
      "episode: 3981/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.496071219444275\n",
      "episode: 3982/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.945556581020355\n",
      "episode: 3983/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3984/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 20.23053526878357\n",
      "episode: 3985/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.98898333311081\n",
      "episode: 3986/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.859488189220428\n",
      "episode: 3987/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.02319502830505371\n",
      "episode: 3988/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.984285295009613\n",
      "episode: 3989/8000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 10.070945739746094\n",
      "episode: 3990/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3991/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 5.062678277492523\n",
      "episode: 3992/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.984367370605469\n",
      "episode: 3993/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 10.253691673278809\n",
      "episode: 3994/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3995/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 27.916642248630524\n",
      "episode: 3996/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.00027358531951904297\n",
      "episode: 3997/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3998/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3999/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4000/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4001/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.98630279302597\n",
      "episode: 4002/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 11.06089472770691\n",
      "episode: 4003/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4004/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 7.1448073387146\n",
      "episode: 4005/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4006/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 4007/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4008/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 16.33344316482544\n",
      "episode: 4009/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.455732345581055\n",
      "episode: 4010/8000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.964659690856934\n",
      "episode: 4011/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4012/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 25.169404089450836\n",
      "episode: 4013/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.992217063903809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4014/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.03340017795562744\n",
      "episode: 4015/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.98426902294159\n",
      "episode: 4016/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4017/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 4018/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.997188031673431\n",
      "episode: 4019/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 4020/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.992103576660156\n",
      "episode: 4021/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 4022/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 7.17958676815033\n",
      "episode: 4023/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.984375\n",
      "episode: 4024/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.013828396797180176\n",
      "episode: 4025/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4026/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.984484374523163\n",
      "episode: 4027/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4028/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.9891676902771\n",
      "episode: 4029/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 4030/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 8.96875\n",
      "episode: 4031/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.3569422960281372\n",
      "episode: 4032/8000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4033/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4034/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.994950592517853\n",
      "episode: 4035/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 10.06134033203125\n",
      "episode: 4036/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4037/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 18.39549344778061\n",
      "episode: 4038/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4039/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 12.812409818172455\n",
      "episode: 4040/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4041/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.992586135864258\n",
      "episode: 4042/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.984444737434387\n",
      "episode: 4043/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 10.06072998046875\n",
      "episode: 4044/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.976688265800476\n",
      "episode: 4045/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 19.979345738887787\n",
      "episode: 4046/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 10.049965918064117\n",
      "episode: 4047/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 22.32003688812256\n",
      "episode: 4048/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.976565182209015\n",
      "episode: 4049/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 12.81239116191864\n",
      "episode: 4050/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 30.074324786663055\n",
      "episode: 4051/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.985109686851501\n",
      "episode: 4052/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 19.598043739795685\n",
      "episode: 4053/8000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 19.125382006168365\n",
      "episode: 4054/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 21.58316695690155\n",
      "episode: 4055/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.071477830410004\n",
      "episode: 4056/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 12.818306744098663\n",
      "episode: 4057/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 12.907034277915955\n",
      "episode: 4058/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.0486781001091\n",
      "episode: 4059/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 19.947570204734802\n",
      "episode: 4060/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 31.66550087928772\n",
      "episode: 4061/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.306749999523163\n",
      "episode: 4062/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 11.981771469116211\n",
      "episode: 4063/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.477303445339203\n",
      "episode: 4064/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.97657036781311\n",
      "episode: 4065/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.976842045783997\n",
      "episode: 4066/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.001258373260498\n",
      "episode: 4067/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.992462873458862\n",
      "episode: 4068/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.373153448104858\n",
      "episode: 4069/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.715557098388672e-06\n",
      "episode: 4070/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 4071/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 39.889165699481964\n",
      "episode: 4072/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 37.58700281381607\n",
      "episode: 4073/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.009452819824219\n",
      "episode: 4074/8000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.008091628551483154\n",
      "episode: 4075/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 20.268300890922546\n",
      "episode: 4076/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4077/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.976448059082031\n",
      "episode: 4078/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4079/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.007779181003570557\n",
      "episode: 4080/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.468750178813934\n",
      "episode: 4081/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 19.95782834291458\n",
      "episode: 4082/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 12.792858123779297\n",
      "episode: 4083/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.97694182395935\n",
      "episode: 4084/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.992565095424652\n",
      "episode: 4085/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4086/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4087/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4088/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.498785376548767\n",
      "episode: 4089/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 23.13393944501877\n",
      "episode: 4090/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 4091/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4092/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 1.9641592502593994\n",
      "episode: 4093/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4094/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.985074996948242\n",
      "episode: 4095/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.71875\n",
      "episode: 4096/8000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.988897740840912\n",
      "episode: 4097/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 10.311874389648438\n",
      "episode: 4098/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 1.5735626220703125e-05\n",
      "episode: 4099/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 10.05446982383728\n",
      "episode: 4100/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 23.054794311523438\n",
      "episode: 4101/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4102/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 7.987022399902344e-06\n",
      "episode: 4103/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.988876342773438\n",
      "episode: 4104/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.98440271615982\n",
      "episode: 4105/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.984376549720764\n",
      "episode: 4106/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 19.96542066335678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4107/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.5090016722679138\n",
      "episode: 4108/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.484375\n",
      "episode: 4109/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 33.62196218967438\n",
      "episode: 4110/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4111/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 37.10023444890976\n",
      "episode: 4112/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 4113/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.988815307617188\n",
      "episode: 4114/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.945598363876343\n",
      "episode: 4115/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4116/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 10.00467073917389\n",
      "episode: 4117/8000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 12.855665802955627\n",
      "episode: 4118/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.9803466796875\n",
      "episode: 4119/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 10.36883544921875\n",
      "episode: 4120/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 7.152243614196777\n",
      "episode: 4121/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 8.06616586446762\n",
      "episode: 4122/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 12.19729208946228\n",
      "episode: 4123/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.4953892230987549\n",
      "episode: 4124/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 23.195959091186523\n",
      "episode: 4125/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 5.125999450683594e-06\n",
      "episode: 4126/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.016357243061065674\n",
      "episode: 4127/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 10.067413330078125\n",
      "episode: 4128/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 27.1497762799263\n",
      "episode: 4129/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 11.976787090301514\n",
      "episode: 4130/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 20.00228214263916\n",
      "episode: 4131/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.997063219547272\n",
      "episode: 4132/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 29.966211318969727\n",
      "episode: 4133/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.906355619430542\n",
      "episode: 4134/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4135/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4136/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.000880122184753418\n",
      "episode: 4137/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4138/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 18.312501072883606\n",
      "episode: 4139/8000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4140/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 11.9407057762146\n",
      "episode: 4141/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.972160339355469\n",
      "episode: 4142/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 4143/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 4144/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 19.939976930618286\n",
      "episode: 4145/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 17.170536935329437\n",
      "episode: 4146/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4147/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.509347438812256\n",
      "episode: 4148/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.976653337478638\n",
      "episode: 4149/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.99640941619873\n",
      "episode: 4150/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.976570725440979\n",
      "episode: 4151/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.92968761920929\n",
      "episode: 4152/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 12.759771823883057\n",
      "episode: 4153/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 4154/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 10.300787448883057\n",
      "episode: 4155/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.984525859355927\n",
      "episode: 4156/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.718755900859833\n",
      "episode: 4157/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 4158/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4159/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.989163875579834\n",
      "episode: 4160/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4161/8000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 10.322844684123993\n",
      "episode: 4162/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 22.86981350183487\n",
      "episode: 4163/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 21.945884704589844\n",
      "episode: 4164/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4165/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4166/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 22.43381631374359\n",
      "episode: 4167/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 20.31701683998108\n",
      "episode: 4168/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 17.115837156772614\n",
      "episode: 4169/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 27.140544533729553\n",
      "episode: 4170/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 8.041750013828278\n",
      "episode: 4171/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 9.999008178710938\n",
      "episode: 4172/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4173/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 9.976877927780151\n",
      "episode: 4174/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 4175/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 9.211203813552856\n",
      "episode: 4176/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 20.285712480545044\n",
      "episode: 4177/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4178/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 19.984055399894714\n",
      "episode: 4179/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 75.45714277029037\n",
      "episode: 4180/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 64.88026118278503\n",
      "episode: 4181/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 19.971360325813293\n",
      "episode: 4182/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 68.66891223192215\n",
      "episode: 4183/8000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.023495078086853027\n",
      "episode: 4184/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.671875059604645\n",
      "episode: 4185/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 30.309722661972046\n",
      "episode: 4186/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 18.001936316490173\n",
      "episode: 4187/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.999094724655151\n",
      "episode: 4188/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.97694319486618\n",
      "episode: 4189/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 19.930838108062744\n",
      "episode: 4190/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 19.953131079673767\n",
      "episode: 4191/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 19.97185516357422\n",
      "episode: 4192/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.007951617240906\n",
      "episode: 4193/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 12.749831557273865\n",
      "episode: 4194/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4195/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 22.048053443431854\n",
      "episode: 4196/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 4197/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 16.42195028066635\n",
      "episode: 4198/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 20.028905510902405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4199/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.988781094551086\n",
      "episode: 4200/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 4201/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.976965188980103\n",
      "episode: 4202/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 19.174817740917206\n",
      "episode: 4203/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4204/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 24.63473552465439\n",
      "episode: 4205/8000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4206/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 8.74755859375\n",
      "episode: 4207/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4208/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 39.92177331447601\n",
      "episode: 4209/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4210/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 6.765127182006836e-05\n",
      "episode: 4211/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-06\n",
      "episode: 4212/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 17.128981173038483\n",
      "episode: 4213/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 19.984124183654785\n",
      "episode: 4214/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 19.954481661319733\n",
      "episode: 4215/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 1.2921759486198425\n",
      "episode: 4216/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 21.763153076171875\n",
      "episode: 4217/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 19.972259521484375\n",
      "episode: 4218/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 1.9775390625\n",
      "episode: 4219/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 23.547007083892822\n",
      "episode: 4220/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 39.583772003650665\n",
      "episode: 4221/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4222/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.718857765197754\n",
      "episode: 4223/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4224/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4225/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 4226/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4227/8000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 21.62894606590271\n",
      "episode: 4228/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.735756874084473\n",
      "episode: 4229/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 11.983385980129242\n",
      "episode: 4230/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.976563394069672\n",
      "episode: 4231/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 19.914999067783356\n",
      "episode: 4232/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 11.98900032043457\n",
      "episode: 4233/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.491858124732971\n",
      "episode: 4234/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4235/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 4236/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 10.261439800262451\n",
      "episode: 4237/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 12.828498125076294\n",
      "episode: 4238/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.00010663270950317383\n",
      "episode: 4239/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4240/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 2.644645929336548\n",
      "episode: 4241/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4242/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.882812798023224\n",
      "episode: 4243/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 2.7772140502929688\n",
      "episode: 4244/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.00010710954666137695\n",
      "episode: 4245/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4246/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4247/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 11.740478515625\n",
      "episode: 4248/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.976574957370758\n",
      "episode: 4249/8000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 41.88038694858551\n",
      "episode: 4250/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 32.70508551597595\n",
      "episode: 4251/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4252/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.97656512260437\n",
      "episode: 4253/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 10.507597923278809\n",
      "episode: 4254/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 19.96752506494522\n",
      "episode: 4255/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 4256/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4257/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.97253692150116\n",
      "episode: 4258/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 3.962369740009308\n",
      "episode: 4259/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 19.953488051891327\n",
      "episode: 4260/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4261/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 19.978019893169403\n",
      "episode: 4262/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 8.000001549720764\n",
      "episode: 4263/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 21.081435799598694\n",
      "episode: 4264/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 19.960998117923737\n",
      "episode: 4265/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 73.05857443809509\n",
      "episode: 4266/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4267/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 22.057651042938232\n",
      "episode: 4268/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 29.906588971614838\n",
      "episode: 4269/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 25.52157175540924\n",
      "episode: 4270/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 24.36278396844864\n",
      "episode: 4271/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0851125717163086\n",
      "episode: 4272/8000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 18.9609375\n",
      "episode: 4273/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 10.491882681846619\n",
      "episode: 4274/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 4275/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 19.95312511920929\n",
      "episode: 4276/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 1274.4569376707077\n",
      "episode: 4277/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 37.108370304107666\n",
      "episode: 4278/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 34.095346093177795\n",
      "episode: 4279/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 19.02012997865677\n",
      "episode: 4280/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4281/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.996170043945312\n",
      "episode: 4282/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.976600170135498\n",
      "episode: 4283/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.492289245128632\n",
      "episode: 4284/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0010044574737548828\n",
      "episode: 4285/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 32.72130048274994\n",
      "episode: 4286/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4287/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4288/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 1.0251998901367188e-05\n",
      "episode: 4289/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 4290/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.989908218383789\n",
      "episode: 4291/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 58.235576927661896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4292/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4293/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 1.8997759819030762\n",
      "episode: 4294/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 20.697469472885132\n",
      "episode: 4295/8000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.990710735321045\n",
      "episode: 4296/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4297/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 10.0589599609375\n",
      "episode: 4298/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 19.953159391880035\n",
      "episode: 4299/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 19.91809904575348\n",
      "episode: 4300/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 30.42021906375885\n",
      "episode: 4301/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4302/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 42.63993418216705\n",
      "episode: 4303/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 1.4662742614746094e-05\n",
      "episode: 4304/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 49.25155174732208\n",
      "episode: 4305/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 29.67469197511673\n",
      "episode: 4306/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4307/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 9.976835012435913\n",
      "episode: 4308/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.1327972412109375\n",
      "episode: 4309/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4310/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 9.987617492675781\n",
      "episode: 4311/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 19.994595289230347\n",
      "episode: 4312/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 2.78125\n",
      "episode: 4313/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.34180599451065063\n",
      "episode: 4314/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 41.42390513420105\n",
      "episode: 4315/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 9.984784066677094\n",
      "episode: 4316/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 121.22890782356262\n",
      "episode: 4317/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0070032477378845215\n",
      "episode: 4318/8000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 11.953236043453217\n",
      "episode: 4319/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4320/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 69.27953881025314\n",
      "episode: 4321/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 2.783310055732727\n",
      "episode: 4322/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.44533920288086\n",
      "episode: 4323/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 69.87064129114151\n",
      "episode: 4324/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 1.9638671875\n",
      "episode: 4325/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 17.985134840011597\n",
      "episode: 4326/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 23.515625\n",
      "episode: 4327/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4328/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 57.3511301279068\n",
      "episode: 4329/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 89.53059202432632\n",
      "episode: 4330/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 32.836821377277374\n",
      "episode: 4331/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 92.86815977096558\n",
      "episode: 4332/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.98994904756546\n",
      "episode: 4333/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 37.14715766906738\n",
      "episode: 4334/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.6328125\n",
      "episode: 4335/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4336/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.986630320549011\n",
      "episode: 4337/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 8.96094298362732\n",
      "episode: 4338/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 13.118105173110962\n",
      "episode: 4339/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 19.664070069789886\n",
      "episode: 4340/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 16.334638357162476\n",
      "episode: 4341/8000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 29.99071455001831\n",
      "episode: 4342/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 25.576643586158752\n",
      "episode: 4343/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 10.038283348083496\n",
      "episode: 4344/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 110.60694354772568\n",
      "episode: 4345/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 12.856796383857727\n",
      "episode: 4346/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4347/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.976842641830444\n",
      "episode: 4348/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 32.485455095767975\n",
      "episode: 4349/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 57.206385016441345\n",
      "episode: 4350/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.978561758995056\n",
      "episode: 4351/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 19.953235864639282\n",
      "episode: 4352/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 42.80187302827835\n",
      "episode: 4353/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 50.02882343530655\n",
      "episode: 4354/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 10.050873100757599\n",
      "episode: 4355/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 82.36384111642838\n",
      "episode: 4356/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.9699222445487976\n",
      "episode: 4357/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 19.4140625\n",
      "episode: 4358/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.95509260892868\n",
      "episode: 4359/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4360/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 29.122257947921753\n",
      "episode: 4361/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 12.90926843881607\n",
      "episode: 4362/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 7.157118797302246\n",
      "episode: 4363/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 10.122143745422363\n",
      "episode: 4364/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 61.549025654792786\n",
      "episode: 4365/8000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4366/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 15.647509932518005\n",
      "episode: 4367/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.984506368637085\n",
      "episode: 4368/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 62.358617544174194\n",
      "episode: 4369/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4370/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 64.59983628988266\n",
      "episode: 4371/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 39.68715417385101\n",
      "episode: 4372/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 19.968637108802795\n",
      "episode: 4373/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.976835489273071\n",
      "episode: 4374/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 4375/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4376/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 59.58504354953766\n",
      "episode: 4377/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 5.132815599441528\n",
      "episode: 4378/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 91.42189037799835\n",
      "episode: 4379/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 82.78619480133057\n",
      "episode: 4380/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 66.52598625421524\n",
      "episode: 4381/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 49.9227015376091\n",
      "episode: 4382/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 54.63573729991913\n",
      "episode: 4383/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 31.165965914726257\n",
      "episode: 4384/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.96566116809845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4385/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 38.35832226276398\n",
      "episode: 4386/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 19.961689889431\n",
      "episode: 4387/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 4388/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 76.89861488342285\n",
      "episode: 4389/8000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.98440170288086\n",
      "episode: 4390/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 119.72870099544525\n",
      "episode: 4391/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 18.779884934425354\n",
      "episode: 4392/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4393/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 23.0811767578125\n",
      "episode: 4394/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 72.13231945037842\n",
      "episode: 4395/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.001918792724609375\n",
      "episode: 4396/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 4397/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4398/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 4399/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 19.44499969482422\n",
      "episode: 4400/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 29.94046300649643\n",
      "episode: 4401/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 12.01678466796875\n",
      "episode: 4402/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 10.009346008300781\n",
      "episode: 4403/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 29.921101093292236\n",
      "episode: 4404/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.007910728454589844\n",
      "episode: 4405/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.625\n",
      "episode: 4406/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 60.816811323165894\n",
      "episode: 4407/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 98.74091565608978\n",
      "episode: 4408/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 57.76927638053894\n",
      "episode: 4409/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0002834200859069824\n",
      "episode: 4410/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4411/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 4412/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.67962658405304\n",
      "episode: 4413/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 30.334390342235565\n",
      "episode: 4414/8000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 61.414166867733\n",
      "episode: 4415/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 68.01855492591858\n",
      "episode: 4416/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4417/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4418/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 79.01212733983994\n",
      "episode: 4419/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.5244140625\n",
      "episode: 4420/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 39.93960678577423\n",
      "episode: 4421/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 57.804472744464874\n",
      "episode: 4422/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 8.06781005859375\n",
      "episode: 4423/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 20.08942186832428\n",
      "episode: 4424/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 10.898770213127136\n",
      "episode: 4425/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 20.264787316322327\n",
      "episode: 4426/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.00020247697830200195\n",
      "episode: 4427/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 19.95590627193451\n",
      "episode: 4428/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4429/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4430/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 32.204761266708374\n",
      "episode: 4431/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 27.60454171895981\n",
      "episode: 4432/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 2.555090546607971\n",
      "episode: 4433/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 75.6663653254509\n",
      "episode: 4434/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 64.4243238568306\n",
      "episode: 4435/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 43.34345865249634\n",
      "episode: 4436/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 22.00338649749756\n",
      "episode: 4437/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4438/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 24.71409773826599\n",
      "episode: 4439/8000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.989200353622437\n",
      "episode: 4440/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 85.73288547992706\n",
      "episode: 4441/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 72.23301178216934\n",
      "episode: 4442/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 44.66855072975159\n",
      "episode: 4443/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 35.764054358005524\n",
      "episode: 4444/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 95.34116226434708\n",
      "episode: 4445/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 20.503847181797028\n",
      "episode: 4446/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 10.04059624671936\n",
      "episode: 4447/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.79174816608429\n",
      "episode: 4448/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 42.264255464076996\n",
      "episode: 4449/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 50.63961440324783\n",
      "episode: 4450/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 96.85441499948502\n",
      "episode: 4451/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 66.80497395992279\n",
      "episode: 4452/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 29.98157274723053\n",
      "episode: 4453/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4454/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.989190340042114\n",
      "episode: 4455/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 18.277657985687256\n",
      "episode: 4456/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 28.650445580482483\n",
      "episode: 4457/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 15.40062552690506\n",
      "episode: 4458/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 30.709575474262238\n",
      "episode: 4459/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 137.75136363506317\n",
      "episode: 4460/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 60.255072593688965\n",
      "episode: 4461/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 136.4009349346161\n",
      "episode: 4462/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 89.21785253286362\n",
      "episode: 4463/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 152.58432638645172\n",
      "episode: 4464/8000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 109.81115287542343\n",
      "episode: 4465/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 39.95932483673096\n",
      "episode: 4466/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 24.122614681720734\n",
      "episode: 4467/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 4468/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 115.2696173787117\n",
      "episode: 4469/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 7.7578125\n",
      "episode: 4470/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 28.4453125\n",
      "episode: 4471/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 162.53892344236374\n",
      "episode: 4472/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 22.84699249267578\n",
      "episode: 4473/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 19.03573614358902\n",
      "episode: 4474/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.328125\n",
      "episode: 4475/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4476/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4477/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 49.868738651275635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4478/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 75.491808116436\n",
      "episode: 4479/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 38.07812964916229\n",
      "episode: 4480/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 19.953615307807922\n",
      "episode: 4481/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 92.68349552154541\n",
      "episode: 4482/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 28.320260286331177\n",
      "episode: 4483/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 75.03587979078293\n",
      "episode: 4484/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 27.72140336036682\n",
      "episode: 4485/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 165.18497508764267\n",
      "episode: 4486/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 31.98391169309616\n",
      "episode: 4487/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 18.68760985136032\n",
      "episode: 4488/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 98.04308342933655\n",
      "episode: 4489/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 50.11728721857071\n",
      "episode: 4490/8000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 49.79704427719116\n",
      "episode: 4491/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.976836681365967\n",
      "episode: 4492/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 39.79411709308624\n",
      "episode: 4493/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 91.89573001861572\n",
      "episode: 4494/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 69.50499165058136\n",
      "episode: 4495/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 136.74827367067337\n",
      "episode: 4496/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 49.922811448574066\n",
      "episode: 4497/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 45.801067531108856\n",
      "episode: 4498/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 30.211565494537354\n",
      "episode: 4499/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 29.98339492082596\n",
      "episode: 4500/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 98.46501606702805\n",
      "episode: 4501/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 39.78933084011078\n",
      "episode: 4502/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 11.392814636230469\n",
      "episode: 4503/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 59.954903066158295\n",
      "episode: 4504/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4505/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 62.45480638742447\n",
      "episode: 4506/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 17.79478907585144\n",
      "episode: 4507/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 30.138480007648468\n",
      "episode: 4508/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4509/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 102.31549847126007\n",
      "episode: 4510/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4511/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.983396768569946\n",
      "episode: 4512/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4513/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 22.516802310943604\n",
      "episode: 4514/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 59.943930208683014\n",
      "episode: 4515/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 39.367924213409424\n",
      "episode: 4516/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 29.93083345890045\n",
      "episode: 4517/8000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 26.33955818414688\n",
      "episode: 4518/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 19.531355500221252\n",
      "episode: 4519/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 53.14246428012848\n",
      "episode: 4520/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 72.8684960603714\n",
      "episode: 4521/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 19.961762189865112\n",
      "episode: 4522/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 33.06691241264343\n",
      "episode: 4523/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 99.80354636907578\n",
      "episode: 4524/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4525/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 32.62654101848602\n",
      "episode: 4526/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4527/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0025683045387268066\n",
      "episode: 4528/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4529/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.989770889282227\n",
      "episode: 4530/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 10.156728744506836\n",
      "episode: 4531/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 51.304265677928925\n",
      "episode: 4532/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 93.72134739160538\n",
      "episode: 4533/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 137.67078763246536\n",
      "episode: 4534/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 40.25683677196503\n",
      "episode: 4535/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 1843.381768167019\n",
      "episode: 4536/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 34.63359248638153\n",
      "episode: 4537/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 119.80240839719772\n",
      "episode: 4538/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4539/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 101.96184754371643\n",
      "episode: 4540/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 39.894020080566406\n",
      "episode: 4541/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4542/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 49.34616333246231\n",
      "episode: 4543/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 11.766601920127869\n",
      "episode: 4544/8000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.015968382358551025\n",
      "episode: 4545/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 39.86186361312866\n",
      "episode: 4546/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 29.90663033723831\n",
      "episode: 4547/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4548/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 82.60407269001007\n",
      "episode: 4549/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 10.467086791992188\n",
      "episode: 4550/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 91.7972640991211\n",
      "episode: 4551/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 21.05559802055359\n",
      "episode: 4552/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 39.78595149517059\n",
      "episode: 4553/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 39.92371600866318\n",
      "episode: 4554/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 38.8984375\n",
      "episode: 4555/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 62.67404240369797\n",
      "episode: 4556/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 29.938445389270782\n",
      "episode: 4557/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 74.47183287143707\n",
      "episode: 4558/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 2646.685237109661\n",
      "episode: 4559/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 183.48549795150757\n",
      "episode: 4560/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 21.961459279060364\n",
      "episode: 4561/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 121.62756425142288\n",
      "episode: 4562/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 32.74790745973587\n",
      "episode: 4563/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 29.938302993774414\n",
      "episode: 4564/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 124.60885727405548\n",
      "episode: 4565/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4566/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 150.9018583893776\n",
      "episode: 4567/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4568/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 51.83902382850647\n",
      "episode: 4569/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 154.07640928030014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4570/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 31.05588734149933\n",
      "episode: 4571/8000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 28.47660356760025\n",
      "episode: 4572/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 69.81114453077316\n",
      "episode: 4573/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 130.97745525836945\n",
      "episode: 4574/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 19.449493408203125\n",
      "episode: 4575/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 71.14690774679184\n",
      "episode: 4576/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 65.91297245025635\n",
      "episode: 4577/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 32.79777693748474\n",
      "episode: 4578/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 83.15377163887024\n",
      "episode: 4579/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 16.58609902858734\n",
      "episode: 4580/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 80.10508632659912\n",
      "episode: 4581/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 70.20889180898666\n",
      "episode: 4582/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 42.45540928840637\n",
      "episode: 4583/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 29.929795920848846\n",
      "episode: 4584/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 20.072489738464355\n",
      "episode: 4585/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 19.993818879127502\n",
      "episode: 4586/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 50.36629003286362\n",
      "episode: 4587/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.976637721061707\n",
      "episode: 4588/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 58.55531269311905\n",
      "episode: 4589/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 67.11072421073914\n",
      "episode: 4590/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 69.84368520975113\n",
      "episode: 4591/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 42.77465742826462\n",
      "episode: 4592/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 48.93754881620407\n",
      "episode: 4593/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 125.5997906923294\n",
      "episode: 4594/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 136.7555506825447\n",
      "episode: 4595/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 53.2392857670784\n",
      "episode: 4596/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 78.46308243274689\n",
      "episode: 4597/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 75.57042759656906\n",
      "episode: 4598/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 32.84067964553833\n",
      "episode: 4599/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 38.73847717046738\n",
      "episode: 4600/8000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.978489875793457\n",
      "episode: 4601/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 45.69735813140869\n",
      "episode: 4602/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4603/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 18.14062511920929\n",
      "episode: 4604/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 127.74609363079071\n",
      "episode: 4605/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 65.7461279630661\n",
      "episode: 4606/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 52.7400438785553\n",
      "episode: 4607/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 78.83211153745651\n",
      "episode: 4608/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 107.54647308588028\n",
      "episode: 4609/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.976608276367188\n",
      "episode: 4610/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 54.57974851131439\n",
      "episode: 4611/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 27.871201276779175\n",
      "episode: 4612/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 19.76488369703293\n",
      "episode: 4613/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4614/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 59.581564247608185\n",
      "episode: 4615/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 19.952606201171875\n",
      "episode: 4616/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 7.200301647186279\n",
      "episode: 4617/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 67.41906636953354\n",
      "episode: 4618/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 11.94238656759262\n",
      "episode: 4619/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4620/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 20.251092851161957\n",
      "episode: 4621/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 39.34255462884903\n",
      "episode: 4622/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 53.056381583213806\n",
      "episode: 4623/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 70.27665144205093\n",
      "episode: 4624/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 114.7936459183693\n",
      "episode: 4625/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4626/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.171875\n",
      "episode: 4627/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 19.617080688476562\n",
      "episode: 4628/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 59.93313580751419\n",
      "episode: 4629/8000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 62.331304252147675\n",
      "episode: 4630/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 29.934272348880768\n",
      "episode: 4631/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 8.4765625\n",
      "episode: 4632/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 92.58080530166626\n",
      "episode: 4633/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 73.12552988529205\n",
      "episode: 4634/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 114.53458321094513\n",
      "episode: 4635/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 4636/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 74.52701872587204\n",
      "episode: 4637/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 19.97329616546631\n",
      "episode: 4638/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 84.84115481376648\n",
      "episode: 4639/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 10.259115159511566\n",
      "episode: 4640/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 19.961114764213562\n",
      "episode: 4641/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 123.8576300740242\n",
      "episode: 4642/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 102.02903455495834\n",
      "episode: 4643/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 106.09873735904694\n",
      "episode: 4644/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-06\n",
      "episode: 4645/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 92.18506479263306\n",
      "episode: 4646/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 256.11289924383163\n",
      "episode: 4647/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 69.7672108411789\n",
      "episode: 4648/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4649/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 93.54833960533142\n",
      "episode: 4650/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 81.78516656160355\n",
      "episode: 4651/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 57.40979468822479\n",
      "episode: 4652/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4653/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 37.16271585226059\n",
      "episode: 4654/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 106.99098521471024\n",
      "episode: 4655/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 171.50750052928925\n",
      "episode: 4656/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4657/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 70.98323231935501\n",
      "episode: 4658/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.72656363248825\n",
      "episode: 4659/8000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 163.6727774143219\n",
      "episode: 4660/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4661/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 31.985230565071106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4662/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 171.16350507736206\n",
      "episode: 4663/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 89.67570704221725\n",
      "episode: 4664/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4665/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 12.75977349281311\n",
      "episode: 4666/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 2.6352899074554443\n",
      "episode: 4667/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 42.04672312736511\n",
      "episode: 4668/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 4669/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 72.8924201130867\n",
      "episode: 4670/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 112.8468120098114\n",
      "episode: 4671/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 49.551650166511536\n",
      "episode: 4672/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 32.05498963594437\n",
      "episode: 4673/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 140.08702129125595\n",
      "episode: 4674/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 2.568960189819336e-05\n",
      "episode: 4675/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4676/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 4677/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 144.73946672677994\n",
      "episode: 4678/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 31.98798018693924\n",
      "episode: 4679/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 64.52047473192215\n",
      "episode: 4680/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 20.12206220626831\n",
      "episode: 4681/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 179.77526795864105\n",
      "episode: 4682/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 54.72986674308777\n",
      "episode: 4683/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 66.72131443023682\n",
      "episode: 4684/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 75.9153099656105\n",
      "episode: 4685/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 69.00974667072296\n",
      "episode: 4686/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 91.8560129404068\n",
      "episode: 4687/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 32.51662850379944\n",
      "episode: 4688/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 4689/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 179.3593977689743\n",
      "episode: 4690/8000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 137.21792674064636\n",
      "episode: 4691/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 100.9475861787796\n",
      "episode: 4692/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 106.55107206106186\n",
      "episode: 4693/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 59.84826648235321\n",
      "episode: 4694/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 72.45950758457184\n",
      "episode: 4695/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 54.92105531692505\n",
      "episode: 4696/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 32.0459303855896\n",
      "episode: 4697/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 30.11962902545929\n",
      "episode: 4698/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 32.713371992111206\n",
      "episode: 4699/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 49.90318977832794\n",
      "episode: 4700/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 84.9828183054924\n",
      "episode: 4701/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 31.87438213825226\n",
      "episode: 4702/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 1551.6477533578873\n",
      "episode: 4703/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 267.51969343423843\n",
      "episode: 4704/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 72.08048248291016\n",
      "episode: 4705/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 79.02667963504791\n",
      "episode: 4706/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 170.85199296474457\n",
      "episode: 4707/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 127.37071704864502\n",
      "episode: 4708/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 152.506551861763\n",
      "episode: 4709/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 82.65660411119461\n",
      "episode: 4710/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4711/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 163.21818763017654\n",
      "episode: 4712/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 43.29540795087814\n",
      "episode: 4713/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 112.68965792655945\n",
      "episode: 4714/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 172.49485176801682\n",
      "episode: 4715/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4716/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 30.31104850769043\n",
      "episode: 4717/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 19.963382482528687\n",
      "episode: 4718/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4719/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4720/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.976943254470825\n",
      "episode: 4721/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 39.90815109014511\n",
      "episode: 4722/8000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 134.83123153448105\n",
      "episode: 4723/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 72.41654294729233\n",
      "episode: 4724/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4725/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 20.028980493545532\n",
      "episode: 4726/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 172.16590178012848\n",
      "episode: 4727/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 59.418059945106506\n",
      "episode: 4728/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 49.35076665878296\n",
      "episode: 4729/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 19.955117166042328\n",
      "episode: 4730/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 62.64749664068222\n",
      "episode: 4731/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.976796507835388\n",
      "episode: 4732/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 113.51803213357925\n",
      "episode: 4733/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4734/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 88.10151946544647\n",
      "episode: 4735/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 30.067825317382812\n",
      "episode: 4736/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 72.60668087005615\n",
      "episode: 4737/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 60.83868855237961\n",
      "episode: 4738/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 2.7861156463623047\n",
      "episode: 4739/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 42.686785876750946\n",
      "episode: 4740/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 79.77768397331238\n",
      "episode: 4741/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 4742/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 29.936508178710938\n",
      "episode: 4743/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 39.90652108192444\n",
      "episode: 4744/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 74.74710100889206\n",
      "episode: 4745/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4746/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4747/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 112.30173295736313\n",
      "episode: 4748/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4749/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4750/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 2.810546875\n",
      "episode: 4751/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 80.09610563516617\n",
      "episode: 4752/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 52.91000473499298\n",
      "episode: 4753/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 40.170166015625\n",
      "episode: 4754/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4755/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 21.63974767923355\n",
      "episode: 4756/8000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 99.32095402479172\n",
      "episode: 4757/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 2.5480422973632812\n",
      "episode: 4758/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 4759/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 53.049395978450775\n",
      "episode: 4760/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 52.36748057603836\n",
      "episode: 4761/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 49.46570682525635\n",
      "episode: 4762/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 133.092180788517\n",
      "episode: 4763/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 19.959945678710938\n",
      "episode: 4764/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 143.32761496305466\n",
      "episode: 4765/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 121.45358544588089\n",
      "episode: 4766/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 15.632814526557922\n",
      "episode: 4767/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 59.89826023578644\n",
      "episode: 4768/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 52.79246544837952\n",
      "episode: 4769/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 56.85948985815048\n",
      "episode: 4770/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 29.220650672912598\n",
      "episode: 4771/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 29.117224395275116\n",
      "episode: 4772/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 11.4112046957016\n",
      "episode: 4773/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 5.04296875\n",
      "episode: 4774/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 25.855650663375854\n",
      "episode: 4775/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 6.377696990966797e-06\n",
      "episode: 4776/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 25.563404321670532\n",
      "episode: 4777/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 80.0230398774147\n",
      "episode: 4778/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 115.05065125226974\n",
      "episode: 4779/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 150.96419662237167\n",
      "episode: 4780/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 43.90278434753418\n",
      "episode: 4781/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 12.850045800209045\n",
      "episode: 4782/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 70.86511814594269\n",
      "episode: 4783/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4784/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4785/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 42.865254044532776\n",
      "episode: 4786/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4787/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 110.81600141525269\n",
      "episode: 4788/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 60.22332864999771\n",
      "episode: 4789/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4790/8000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 59.906003177165985\n",
      "episode: 4791/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 32.302449345588684\n",
      "episode: 4792/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 22.047780632972717\n",
      "episode: 4793/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4794/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 167.3072646856308\n",
      "episode: 4795/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.5367431640625e-07\n",
      "episode: 4796/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 92.22778505086899\n",
      "episode: 4797/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 105.76799839735031\n",
      "episode: 4798/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 45.065139293670654\n",
      "episode: 4799/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4800/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 19.95312649011612\n",
      "episode: 4801/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4802/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 117.61000746488571\n",
      "episode: 4803/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 120.88936376571655\n",
      "episode: 4804/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 25.393742740154266\n",
      "episode: 4805/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 182.0030578970909\n",
      "episode: 4806/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 139.8051648736\n",
      "episode: 4807/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 18.63281762599945\n",
      "episode: 4808/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4809/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 98.11554890871048\n",
      "episode: 4810/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 123.65096634626389\n",
      "episode: 4811/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 29.937699675559998\n",
      "episode: 4812/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 59.89173358678818\n",
      "episode: 4813/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 56.89895784854889\n",
      "episode: 4814/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 54.1991149187088\n",
      "episode: 4815/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 182.30050402879715\n",
      "episode: 4816/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 168.74272572994232\n",
      "episode: 4817/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 7.110834121704102e-05\n",
      "episode: 4818/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 6.509770333766937\n",
      "episode: 4819/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 80.00396758317947\n",
      "episode: 4820/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 147.09970903396606\n",
      "episode: 4821/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 168.8562971353531\n",
      "episode: 4822/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 49.91891437768936\n",
      "episode: 4823/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 68.81313574314117\n",
      "episode: 4824/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 89.87900644540787\n",
      "episode: 4825/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 88.8890865445137\n",
      "episode: 4826/8000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 63.8530278801918\n",
      "episode: 4827/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 123.70222795009613\n",
      "episode: 4828/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4829/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 19.12527370452881\n",
      "episode: 4830/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 136.46360313892365\n",
      "episode: 4831/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 18.964648008346558\n",
      "episode: 4832/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4833/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 158.0741609930992\n",
      "episode: 4834/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 20.22998046875\n",
      "episode: 4835/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 123.12999498844147\n",
      "episode: 4836/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 148.7787206172943\n",
      "episode: 4837/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 177.3105298280716\n",
      "episode: 4838/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 174.40481996536255\n",
      "episode: 4839/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 19.960227489471436\n",
      "episode: 4840/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 196.71877920627594\n",
      "episode: 4841/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4842/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 203.01963871717453\n",
      "episode: 4843/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 141.8497085571289\n",
      "episode: 4844/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 75.14513057470322\n",
      "episode: 4845/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 184.79438316822052\n",
      "episode: 4846/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 10.002838134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4847/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 87.39175713062286\n",
      "episode: 4848/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 18.962483525276184\n",
      "episode: 4849/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 44.77337408065796\n",
      "episode: 4850/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 112.11462253332138\n",
      "episode: 4851/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 55.73124796152115\n",
      "episode: 4852/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 111.79934448003769\n",
      "episode: 4853/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 100.00562173128128\n",
      "episode: 4854/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4855/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 129.44738978147507\n",
      "episode: 4856/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 185.21404641866684\n",
      "episode: 4857/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 172.84268736839294\n",
      "episode: 4858/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4859/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 40.44556313753128\n",
      "episode: 4860/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.976796507835388\n",
      "episode: 4861/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 179.25991868972778\n",
      "episode: 4862/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 111.20030480623245\n",
      "episode: 4863/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 193.47325885295868\n",
      "episode: 4864/8000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 39.90257865190506\n",
      "episode: 4865/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 113.09315776824951\n",
      "episode: 4866/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 52.66728067398071\n",
      "episode: 4867/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4868/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 59.92439252138138\n",
      "episode: 4869/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 165.34935051202774\n",
      "episode: 4870/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 89.16785830259323\n",
      "episode: 4871/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 58.71292835474014\n",
      "episode: 4872/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4873/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4874/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 40.375675082206726\n",
      "episode: 4875/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 123.84018564224243\n",
      "episode: 4876/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 20.04808807373047\n",
      "episode: 4877/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 121.06955897808075\n",
      "episode: 4878/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 149.1254996061325\n",
      "episode: 4879/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 165.7304019331932\n",
      "episode: 4880/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 29.937395453453064\n",
      "episode: 4881/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 110.29487812519073\n",
      "episode: 4882/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.020381569862365723\n",
      "episode: 4883/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 90.62164616584778\n",
      "episode: 4884/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 79.80682337284088\n",
      "episode: 4885/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 69.86149883270264\n",
      "episode: 4886/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4887/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 52.702070355415344\n",
      "episode: 4888/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 50.072060227394104\n",
      "episode: 4889/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 59.87952649593353\n",
      "episode: 4890/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 62.642685532569885\n",
      "episode: 4891/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 167.77383774518967\n",
      "episode: 4892/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 161.6291457414627\n",
      "episode: 4893/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 176.61993896961212\n",
      "episode: 4894/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4895/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 19.125\n",
      "episode: 4896/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 4897/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 4898/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 109.93510645627975\n",
      "episode: 4899/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 12.759765625\n",
      "episode: 4900/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 29.94532072544098\n",
      "episode: 4901/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 43.99917250871658\n",
      "episode: 4902/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 32.815311908721924\n",
      "episode: 4903/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 62.09179776906967\n",
      "episode: 4904/8000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 57.00861597061157\n",
      "episode: 4905/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 52.68230211734772\n",
      "episode: 4906/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 69.87295085191727\n",
      "episode: 4907/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 142.3769644498825\n",
      "episode: 4908/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4909/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 144.0649139881134\n",
      "episode: 4910/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 110.68278706073761\n",
      "episode: 4911/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 4912/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 40.45792245864868\n",
      "episode: 4913/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 74.64671099185944\n",
      "episode: 4914/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 64.85334867238998\n",
      "episode: 4915/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 104.5799331665039\n",
      "episode: 4916/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 11.953827023506165\n",
      "episode: 4917/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 4918/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 27.988204956054688\n",
      "episode: 4919/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 39.80327099561691\n",
      "episode: 4920/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4921/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 40.29795861244202\n",
      "episode: 4922/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 76.65084332227707\n",
      "episode: 4923/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 11.298752188682556\n",
      "episode: 4924/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 39.21541053056717\n",
      "episode: 4925/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 29.92969024181366\n",
      "episode: 4926/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 53.26742887496948\n",
      "episode: 4927/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 129.23762369155884\n",
      "episode: 4928/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4929/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 67.31020927429199\n",
      "episode: 4930/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 151.0521382689476\n",
      "episode: 4931/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 18.937954306602478\n",
      "episode: 4932/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 186.65171247720718\n",
      "episode: 4933/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 174.3552982211113\n",
      "episode: 4934/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 43.81998908519745\n",
      "episode: 4935/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 12.71875\n",
      "episode: 4936/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 125.30768102407455\n",
      "episode: 4937/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 122.88342624902725\n",
      "episode: 4938/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 2.83541339635849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4939/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 50.7195121049881\n",
      "episode: 4940/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 10.000000059604645\n",
      "episode: 4941/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 128.84861093759537\n",
      "episode: 4942/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 48.84022521972656\n",
      "episode: 4943/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 61.33199179172516\n",
      "episode: 4944/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 69.17190873622894\n",
      "episode: 4945/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 69.66040068864822\n",
      "episode: 4946/8000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 150.19495582580566\n",
      "episode: 4947/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 4948/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.42461359500885\n",
      "episode: 4949/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 47.535143315792084\n",
      "episode: 4950/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 1.9853973388671875\n",
      "episode: 4951/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 19.95313262939453\n",
      "episode: 4952/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 30.264472484588623\n",
      "episode: 4953/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 86.72912222146988\n",
      "episode: 4954/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 85.4222571849823\n",
      "episode: 4955/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0002066493034362793\n",
      "episode: 4956/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 38.8828125\n",
      "episode: 4957/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 36.06889057159424\n",
      "episode: 4958/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 32.49630934000015\n",
      "episode: 4959/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 132.36317420005798\n",
      "episode: 4960/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4961/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 19.961421966552734\n",
      "episode: 4962/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 55.76168465614319\n",
      "episode: 4963/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 19.964611053466797\n",
      "episode: 4964/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 20.22998046875\n",
      "episode: 4965/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 104.0052427649498\n",
      "episode: 4966/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 144.92128783464432\n",
      "episode: 4967/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 5.930652976036072\n",
      "episode: 4968/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 149.49550676345825\n",
      "episode: 4969/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 74.29318779706955\n",
      "episode: 4970/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 37.916206657886505\n",
      "episode: 4971/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 39.53125\n",
      "episode: 4972/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 175.26655119657516\n",
      "episode: 4973/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 163.26404094696045\n",
      "episode: 4974/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 89.80036687850952\n",
      "episode: 4975/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 32.79632872343063\n",
      "episode: 4976/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4977/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 99.51068311929703\n",
      "episode: 4978/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 110.03654909133911\n",
      "episode: 4979/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 122.30410170555115\n",
      "episode: 4980/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 212.64580261707306\n",
      "episode: 4981/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 62.3667927980423\n",
      "episode: 4982/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 83.90160286426544\n",
      "episode: 4983/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 219.26117676496506\n",
      "episode: 4984/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 5.6079829931259155\n",
      "episode: 4985/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 57.56429588794708\n",
      "episode: 4986/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4987/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.05143845081329346\n",
      "episode: 4988/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 18.984375\n",
      "episode: 4989/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 29.81278395652771\n",
      "episode: 4990/8000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 17.07839846611023\n",
      "episode: 4991/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 37.914193987846375\n",
      "episode: 4992/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 109.98934006690979\n",
      "episode: 4993/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 52.7555016875267\n",
      "episode: 4994/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 166.58130878210068\n",
      "episode: 4995/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 175.57391560077667\n",
      "episode: 4996/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 137.28638565540314\n",
      "episode: 4997/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 69.82026875019073\n",
      "episode: 4998/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 92.57639026641846\n",
      "episode: 4999/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 29.962988257408142\n",
      "episode: 5000/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 41.56864982843399\n",
      "episode: 5001/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 69.07291442155838\n",
      "episode: 5002/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 186.80677354335785\n",
      "episode: 5003/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 163.47667837142944\n",
      "episode: 5004/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 29.976059317588806\n",
      "episode: 5005/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 49.89965158700943\n",
      "episode: 5006/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 210.9793679714203\n",
      "episode: 5007/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 167.91820579767227\n",
      "episode: 5008/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 101.08317041397095\n",
      "episode: 5009/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5010/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 161.27713358402252\n",
      "episode: 5011/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 142.55377489328384\n",
      "episode: 5012/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 10.87649405002594\n",
      "episode: 5013/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 53.473868787288666\n",
      "episode: 5014/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 67.1797303557396\n",
      "episode: 5015/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 19.4375\n",
      "episode: 5016/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 162.86495262384415\n",
      "episode: 5017/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 19.42187511920929\n",
      "episode: 5018/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.9536794424057\n",
      "episode: 5019/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 214.78751307725906\n",
      "episode: 5020/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5021/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 59.53134161233902\n",
      "episode: 5022/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 19.95339870452881\n",
      "episode: 5023/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5024/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 107.66919881105423\n",
      "episode: 5025/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 214.50050151348114\n",
      "episode: 5026/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 107.43637657165527\n",
      "episode: 5027/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 22.736329317092896\n",
      "episode: 5028/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 19.965438842773438\n",
      "episode: 5029/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 123.10748475790024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5030/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 129.16922277212143\n",
      "episode: 5031/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 202.25496262311935\n",
      "episode: 5032/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 96.12969261407852\n",
      "episode: 5033/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 92.06325376033783\n",
      "episode: 5034/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 30.426789164543152\n",
      "episode: 5035/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 99.87730312347412\n",
      "episode: 5036/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 99.57227897644043\n",
      "episode: 5037/8000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 6.678070425987244\n",
      "episode: 5038/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 40.61088854074478\n",
      "episode: 5039/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5040/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 41.72811287641525\n",
      "episode: 5041/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 144.5135262608528\n",
      "episode: 5042/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 84.70879852771759\n",
      "episode: 5043/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 192.9928178191185\n",
      "episode: 5044/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 155.70526766777039\n",
      "episode: 5045/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 20.03790283203125\n",
      "episode: 5046/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 66.365582883358\n",
      "episode: 5047/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 29.719133853912354\n",
      "episode: 5048/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 94.63002526760101\n",
      "episode: 5049/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 71.130750477314\n",
      "episode: 5050/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 30.260000348091125\n",
      "episode: 5051/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 12.767702996730804\n",
      "episode: 5052/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 164.99149906635284\n",
      "episode: 5053/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5054/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 29.995702147483826\n",
      "episode: 5055/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 111.03060066699982\n",
      "episode: 5056/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 84.94685590267181\n",
      "episode: 5057/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 169.22315925359726\n",
      "episode: 5058/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 72.05115354061127\n",
      "episode: 5059/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 146.09183537960052\n",
      "episode: 5060/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 5061/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 172.40543925762177\n",
      "episode: 5062/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 204.34547418355942\n",
      "episode: 5063/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 19.97750949859619\n",
      "episode: 5064/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.988876342773438\n",
      "episode: 5065/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 101.89239490032196\n",
      "episode: 5066/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 52.68478840589523\n",
      "episode: 5067/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 186.11621791124344\n",
      "episode: 5068/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 41.072258949279785\n",
      "episode: 5069/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 14.968753278255463\n",
      "episode: 5070/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 227.34501856565475\n",
      "episode: 5071/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 223.1959068775177\n",
      "episode: 5072/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 200.8450961112976\n",
      "episode: 5073/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 141.83968317508698\n",
      "episode: 5074/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 212.70804244279861\n",
      "episode: 5075/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 186.40534323453903\n",
      "episode: 5076/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.984545707702637\n",
      "episode: 5077/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 121.78946381807327\n",
      "episode: 5078/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 203.66698735952377\n",
      "episode: 5079/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 2498.691125333309\n",
      "episode: 5080/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 79.54906225204468\n",
      "episode: 5081/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 32.71312749385834\n",
      "episode: 5082/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 91.77750808000565\n",
      "episode: 5083/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 30.2041015625\n",
      "episode: 5084/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 30.207748413085938\n",
      "episode: 5085/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 61.19714778661728\n",
      "episode: 5086/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 151.22790896892548\n",
      "episode: 5087/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 143.99774247407913\n",
      "episode: 5088/8000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.976583778858185\n",
      "episode: 5089/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 146.7505087852478\n",
      "episode: 5090/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 113.95466721057892\n",
      "episode: 5091/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 200.0185815691948\n",
      "episode: 5092/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 193.79859989881516\n",
      "episode: 5093/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 298.3138816356659\n",
      "episode: 5094/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 97.89391535520554\n",
      "episode: 5095/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 2238.384017944336\n",
      "episode: 5096/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 20.232386589050293\n",
      "episode: 5097/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 22.76145339012146\n",
      "episode: 5098/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 41.52947390079498\n",
      "episode: 5099/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5100/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 29.92978411912918\n",
      "episode: 5101/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 29.936798453330994\n",
      "episode: 5102/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 39.92611491680145\n",
      "episode: 5103/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 60.66835969686508\n",
      "episode: 5104/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 30.49574851989746\n",
      "episode: 5105/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 18.68778032064438\n",
      "episode: 5106/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5107/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 7.171875\n",
      "episode: 5108/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.984302520751953\n",
      "episode: 5109/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 15.542971551418304\n",
      "episode: 5110/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 41.732538640499115\n",
      "episode: 5111/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 103.43958187103271\n",
      "episode: 5112/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 48.297933518886566\n",
      "episode: 5113/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 5114/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 18.946633398532867\n",
      "episode: 5115/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5116/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 100.61008149385452\n",
      "episode: 5117/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 19.125\n",
      "episode: 5118/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 5119/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 79.28079462051392\n",
      "episode: 5120/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 32.81470727920532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5121/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 52.106382608413696\n",
      "episode: 5122/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 29.936757802963257\n",
      "episode: 5123/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 89.77710121870041\n",
      "episode: 5124/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5125/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 20.03729248046875\n",
      "episode: 5126/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 43.03318476676941\n",
      "episode: 5127/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 39.91856384277344\n",
      "episode: 5128/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 24.7689146399498\n",
      "episode: 5129/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 29.957618713378906\n",
      "episode: 5130/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.980493485927582\n",
      "episode: 5131/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5132/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 59.82364135980606\n",
      "episode: 5133/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 19.98150634765625\n",
      "episode: 5134/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 81.86917299032211\n",
      "episode: 5135/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 136.2151154279709\n",
      "episode: 5136/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 21.18843364715576\n",
      "episode: 5137/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 187.65630912780762\n",
      "episode: 5138/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 186.7283717393875\n",
      "episode: 5139/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 35.59570336341858\n",
      "episode: 5140/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 186.76408523321152\n",
      "episode: 5141/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 54.47805058956146\n",
      "episode: 5142/8000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 201.86894190311432\n",
      "episode: 5143/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 217.16232162714005\n",
      "episode: 5144/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 22.738228797912598\n",
      "episode: 5145/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 6.800235211849213\n",
      "episode: 5146/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 221.3268804550171\n",
      "episode: 5147/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 117.78214967250824\n",
      "episode: 5148/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 112.63360786437988\n",
      "episode: 5149/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5150/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 187.7873266339302\n",
      "episode: 5151/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 92.5672704577446\n",
      "episode: 5152/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 182.6537111401558\n",
      "episode: 5153/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 212.41920137405396\n",
      "episode: 5154/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5155/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 31.268644094467163\n",
      "episode: 5156/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 30.207055985927582\n",
      "episode: 5157/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 121.13821923732758\n",
      "episode: 5158/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 82.58877152204514\n",
      "episode: 5159/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 266.8226970434189\n",
      "episode: 5160/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 210.31868487596512\n",
      "episode: 5161/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 235.16541814804077\n",
      "episode: 5162/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 218.00441765785217\n",
      "episode: 5163/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 93.62872648239136\n",
      "episode: 5164/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 109.02147388458252\n",
      "episode: 5165/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5166/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 59.537018954753876\n",
      "episode: 5167/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 70.37690317630768\n",
      "episode: 5168/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 94.85042649507523\n",
      "episode: 5169/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 57.78137570619583\n",
      "episode: 5170/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 131.89918380975723\n",
      "episode: 5171/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 186.98463642597198\n",
      "episode: 5172/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 194.79015338420868\n",
      "episode: 5173/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 49.99812960624695\n",
      "episode: 5174/8000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 68.20149385929108\n",
      "episode: 5175/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 83.83699989318848\n",
      "episode: 5176/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 132.50800567865372\n",
      "episode: 5177/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 174.45427024364471\n",
      "episode: 5178/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 160.1169376373291\n",
      "episode: 5179/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 9.977785050868988\n",
      "episode: 5180/8000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 22.762807428836823\n",
      "episode: 5181/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 32.750005066394806\n",
      "episode: 5182/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 136.36286842823029\n",
      "episode: 5183/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 44.71484953165054\n",
      "episode: 5184/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 10.186897337436676\n",
      "episode: 5185/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 194.91262191534042\n",
      "episode: 5186/8000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 84.62901145219803\n",
      "episode: 5187/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 29.085945188999176\n",
      "episode: 5188/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 197.2376316189766\n",
      "episode: 5189/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 59.54594415426254\n",
      "episode: 5190/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 72.64291405677795\n",
      "episode: 5191/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 46.856743931770325\n",
      "episode: 5192/8000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 711.1660516262054\n",
      "episode: 5193/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 137.8452410697937\n",
      "episode: 5194/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 33.92177081108093\n",
      "episode: 5195/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 49.717098236083984\n",
      "episode: 5196/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 9.976709365844727\n",
      "episode: 5197/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5198/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 137.47750967741013\n",
      "episode: 5199/8000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 49.63510000705719\n",
      "episode: 5200/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 82.84062910079956\n",
      "episode: 5201/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 18.95312511920929\n",
      "episode: 5202/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 52.74268335103989\n",
      "episode: 5203/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 38.81352114677429\n",
      "episode: 5204/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 182.4245747923851\n",
      "episode: 5205/8000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 79.8518734574318\n",
      "episode: 5206/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 203.57464653253555\n",
      "episode: 5207/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 120.34582024812698\n",
      "episode: 5208/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 72.66310721635818\n",
      "episode: 5209/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 22.548876404762268\n",
      "episode: 5210/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 18.945673763751984\n",
      "episode: 5211/8000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5212/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5213/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 76.54624551534653\n",
      "episode: 5214/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 12.851196765899658\n",
      "episode: 5215/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 2.7832417488098145\n",
      "episode: 5216/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 71.92832344770432\n",
      "episode: 5217/8000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 127.564956843853\n",
      "episode: 5218/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 101.06715208292007\n",
      "episode: 5219/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 97.88121789693832\n",
      "episode: 5220/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 144.7710525393486\n",
      "episode: 5221/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 30.392718374729156\n",
      "episode: 5222/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 21.613876342773438\n",
      "episode: 5223/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 1.8803070783615112\n",
      "episode: 5224/8000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 119.77590358257294\n",
      "episode: 5225/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 129.33329892158508\n",
      "episode: 5226/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 45.0200560092926\n",
      "episode: 5227/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 31.205322265625\n",
      "episode: 5228/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 159.01371240615845\n",
      "episode: 5229/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 28.488906919956207\n",
      "episode: 5230/8000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 91.84145420789719\n",
      "episode: 5231/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 9.976564407348633\n",
      "episode: 5232/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 140.34312468767166\n",
      "episode: 5233/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 23.47880220413208\n",
      "episode: 5234/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 49.997330367565155\n",
      "episode: 5235/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 155.2614040374756\n",
      "episode: 5236/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 58.92840933799744\n",
      "episode: 5237/8000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 59.4425134062767\n",
      "episode: 5238/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 41.892591774463654\n",
      "episode: 5239/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 9.478114783763885\n",
      "episode: 5240/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 66.08633935451508\n",
      "episode: 5241/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 91.49783825874329\n",
      "episode: 5242/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 101.68823784589767\n",
      "episode: 5243/8000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 70.00981509685516\n",
      "episode: 5244/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 175.46651631593704\n",
      "episode: 5245/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5246/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 33.00061810016632\n",
      "episode: 5247/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 134.72322303056717\n",
      "episode: 5248/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 0.01095283031463623\n",
      "episode: 5249/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 1109.6854705810547\n",
      "episode: 5250/8000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 90.0166711807251\n",
      "episode: 5251/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 35.504430174827576\n",
      "episode: 5252/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 229.80131947994232\n",
      "episode: 5253/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 231.80083388090134\n",
      "episode: 5254/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 181.87953120470047\n",
      "episode: 5255/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5256/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 1.0103641748428345\n",
      "episode: 5257/8000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 28.031410694122314\n",
      "episode: 5258/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 36.42230820655823\n",
      "episode: 5259/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 144.32055896520615\n",
      "episode: 5260/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 11.374873697757721\n",
      "episode: 5261/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 31.99117124080658\n",
      "episode: 5262/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 51.895041048526764\n",
      "episode: 5263/8000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 91.87498462200165\n",
      "episode: 5264/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 19.976945519447327\n",
      "episode: 5265/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 29.799957275390625\n",
      "episode: 5266/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 149.54140430688858\n",
      "episode: 5267/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 406.02813309431076\n",
      "episode: 5268/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 67.1977686882019\n",
      "episode: 5269/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 128.87683069705963\n",
      "episode: 5270/8000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 69.93776035308838\n",
      "episode: 5271/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 54.9792845249176\n",
      "episode: 5272/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 20.8023818731308\n",
      "episode: 5273/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 204.32746076583862\n",
      "episode: 5274/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 67.89156424999237\n",
      "episode: 5275/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 90.6403631567955\n",
      "episode: 5276/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 19.95312511920929\n",
      "episode: 5277/8000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 20.154013633728027\n",
      "episode: 5278/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 19.596435546875\n",
      "episode: 5279/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 21.084365248680115\n",
      "episode: 5280/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5281/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 5282/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.932333111763\n",
      "episode: 5283/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 60.837890625\n",
      "episode: 5284/8000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 112.02597230672836\n",
      "episode: 5285/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 21.916999757289886\n",
      "episode: 5286/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 137.31315487623215\n",
      "episode: 5287/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 106.75294554233551\n",
      "episode: 5288/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 1.999078631401062\n",
      "episode: 5289/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 12.1500244140625\n",
      "episode: 5290/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 111.48662501573563\n",
      "episode: 5291/8000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 5.054443359375\n",
      "episode: 5292/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 0.002025604248046875\n",
      "episode: 5293/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 185.73095816373825\n",
      "episode: 5294/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 112.58520025014877\n",
      "episode: 5295/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.977245509624481\n",
      "episode: 5296/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 195.5530537366867\n",
      "episode: 5297/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 42.691338539123535\n",
      "episode: 5298/8000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.98120266199112\n",
      "episode: 5299/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 200.2843752503395\n",
      "episode: 5300/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 38.01934498548508\n",
      "episode: 5301/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 0.0003364086151123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5302/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 209.66010695695877\n",
      "episode: 5303/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 62.64482539892197\n",
      "episode: 5304/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 132.57021409273148\n",
      "episode: 5305/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 65.00732898712158\n",
      "episode: 5306/8000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 137.56906133890152\n",
      "episode: 5307/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 72.0706958770752\n",
      "episode: 5308/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 70.72280073165894\n",
      "episode: 5309/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 83.67755419015884\n",
      "episode: 5310/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 114.60013568401337\n",
      "episode: 5311/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 49.5702018737793\n",
      "episode: 5312/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 209.6910856962204\n",
      "episode: 5313/8000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 164.8831403851509\n",
      "episode: 5314/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 152.8651111125946\n",
      "episode: 5315/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 162.8740593791008\n",
      "episode: 5316/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 59.77193558216095\n",
      "episode: 5317/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 19.95312762260437\n",
      "episode: 5318/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 200.53692680597305\n",
      "episode: 5319/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 5.1081180572509766e-05\n",
      "episode: 5320/8000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 42.81108969449997\n",
      "episode: 5321/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 112.10815298557281\n",
      "episode: 5322/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 198.9732146859169\n",
      "episode: 5323/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 133.30026644468307\n",
      "episode: 5324/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 191.66358840465546\n",
      "episode: 5325/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 207.66592472791672\n",
      "episode: 5326/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 192.69291442632675\n",
      "episode: 5327/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 165.33113366365433\n",
      "episode: 5328/8000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 207.79868721961975\n",
      "episode: 5329/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 11.62225341796875\n",
      "episode: 5330/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 166.81102067232132\n",
      "episode: 5331/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 0.0021376609802246094\n",
      "episode: 5332/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 238.78863167762756\n",
      "episode: 5333/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 72.85623180866241\n",
      "episode: 5334/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 22.784912109375\n",
      "episode: 5335/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 5336/8000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 151.0454347729683\n",
      "episode: 5337/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5338/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5339/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 30.353458523750305\n",
      "episode: 5340/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 9.687501788139343\n",
      "episode: 5341/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 19.97656261920929\n",
      "episode: 5342/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 81.03290116786957\n",
      "episode: 5343/8000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 164.31627106666565\n",
      "episode: 5344/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 177.3840457201004\n",
      "episode: 5345/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 179.2316613793373\n",
      "episode: 5346/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 137.80468952655792\n",
      "episode: 5347/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 0.000658571720123291\n",
      "episode: 5348/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 94.7306581735611\n",
      "episode: 5349/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 51.38319373130798\n",
      "episode: 5350/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 191.19941014051437\n",
      "episode: 5351/8000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 213.5824745297432\n",
      "episode: 5352/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 39.37646406888962\n",
      "episode: 5353/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 120.02859085798264\n",
      "episode: 5354/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 162.40837836265564\n",
      "episode: 5355/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 98.00465780496597\n",
      "episode: 5356/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 228.0912714600563\n",
      "episode: 5357/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 193.44692021608353\n",
      "episode: 5358/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 20.25460720062256\n",
      "episode: 5359/8000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 9.46875\n",
      "episode: 5360/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 91.47274792194366\n",
      "episode: 5361/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 89.46401691436768\n",
      "episode: 5362/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 21.95315271615982\n",
      "episode: 5363/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 0.0001881718635559082\n",
      "episode: 5364/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 72.30696034431458\n",
      "episode: 5365/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 89.73928880691528\n",
      "episode: 5366/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 109.16507995128632\n",
      "episode: 5367/8000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 68.1283403635025\n",
      "episode: 5368/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 28.9296875\n",
      "episode: 5369/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 32.720943570137024\n",
      "episode: 5370/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 204.7086786031723\n",
      "episode: 5371/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 19.97442626953125\n",
      "episode: 5372/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 112.0351932644844\n",
      "episode: 5373/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 35.50390625\n",
      "episode: 5374/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 62.775094985961914\n",
      "episode: 5375/8000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 131.7798997759819\n",
      "episode: 5376/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 118.79377752542496\n",
      "episode: 5377/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 5378/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 175.84633839130402\n",
      "episode: 5379/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 28.41209524869919\n",
      "episode: 5380/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 23.9453125\n",
      "episode: 5381/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 93.98050552606583\n",
      "episode: 5382/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 215.78246867656708\n",
      "episode: 5383/8000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 98.1112300157547\n",
      "episode: 5384/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 1268.0925736427307\n",
      "episode: 5385/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 92.29011678695679\n",
      "episode: 5386/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 240.14118045568466\n",
      "episode: 5387/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 161.4780728816986\n",
      "episode: 5388/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 9.89063036441803\n",
      "episode: 5389/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 103.94341671466827\n",
      "episode: 5390/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 109.84051716327667\n",
      "episode: 5391/8000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 23.602531492710114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5392/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 132.35049700737\n",
      "episode: 5393/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 14.8046875\n",
      "episode: 5394/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 71.97177028656006\n",
      "episode: 5395/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 82.64441579580307\n",
      "episode: 5396/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 91.81548178195953\n",
      "episode: 5397/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 102.82153421640396\n",
      "episode: 5398/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 79.81682753562927\n",
      "episode: 5399/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 106.11162477731705\n",
      "episode: 5400/8000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 35.35935306549072\n",
      "episode: 5401/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 32.72713214159012\n",
      "episode: 5402/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 179.56605952978134\n",
      "episode: 5403/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 37.155958116054535\n",
      "episode: 5404/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 238.5380807518959\n",
      "episode: 5405/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 110.1130843758583\n",
      "episode: 5406/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 134.0329003930092\n",
      "episode: 5407/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 172.48250275850296\n",
      "episode: 5408/8000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 162.93232583999634\n",
      "episode: 5409/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 125.47330391407013\n",
      "episode: 5410/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 145.0260598063469\n",
      "episode: 5411/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 102.62591934204102\n",
      "episode: 5412/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 89.79705959558487\n",
      "episode: 5413/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 62.673961758613586\n",
      "episode: 5414/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 81.82753092050552\n",
      "episode: 5415/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 55.369366347789764\n",
      "episode: 5416/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 168.73097431659698\n",
      "episode: 5417/8000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 220.27096682786942\n",
      "episode: 5418/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 185.61140471696854\n",
      "episode: 5419/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 98.0067600607872\n",
      "episode: 5420/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 49.98151481151581\n",
      "episode: 5421/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 2.5570392608642578e-05\n",
      "episode: 5422/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 215.683120906353\n",
      "episode: 5423/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 122.70970982313156\n",
      "episode: 5424/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 147.16982519626617\n",
      "episode: 5425/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 11.316883146762848\n",
      "episode: 5426/8000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 214.8487366437912\n",
      "episode: 5427/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 31.894539415836334\n",
      "episode: 5428/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 42.69175362586975\n",
      "episode: 5429/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 89.7700434923172\n",
      "episode: 5430/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 235.19392383098602\n",
      "episode: 5431/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 230.8905035853386\n",
      "episode: 5432/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 57.0338134765625\n",
      "episode: 5433/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 22.736370384693146\n",
      "episode: 5434/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 81.91905730962753\n",
      "episode: 5435/8000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 89.79283821582794\n",
      "episode: 5436/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 159.56867504119873\n",
      "episode: 5437/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 91.88184744119644\n",
      "episode: 5438/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 29.298073768615723\n",
      "episode: 5439/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 139.3542596101761\n",
      "episode: 5440/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 19.9224214553833\n",
      "episode: 5441/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 117.95234334468842\n",
      "episode: 5442/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 70.01575773954391\n",
      "episode: 5443/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 179.42538559436798\n",
      "episode: 5444/8000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 184.55848932266235\n",
      "episode: 5445/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 226.95184129476547\n",
      "episode: 5446/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 71.88851124048233\n",
      "episode: 5447/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 200.46121507883072\n",
      "episode: 5448/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 206.46062695980072\n",
      "episode: 5449/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 100.82020324468613\n",
      "episode: 5450/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 57.114518105983734\n",
      "episode: 5451/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 0.2011394500732422\n",
      "episode: 5452/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 49.113691210746765\n",
      "episode: 5453/8000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 5454/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 39.93133294582367\n",
      "episode: 5455/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 101.21864306926727\n",
      "episode: 5456/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 41.220643401145935\n",
      "episode: 5457/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 79.37386709451675\n",
      "episode: 5458/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 107.08737277984619\n",
      "episode: 5459/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 40.83267796039581\n",
      "episode: 5460/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 42.43188863992691\n",
      "episode: 5461/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 20.03790283203125\n",
      "episode: 5462/8000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 73.09018242359161\n",
      "episode: 5463/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5464/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 75.12097376585007\n",
      "episode: 5465/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5466/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 137.8229768872261\n",
      "episode: 5467/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 112.98487508296967\n",
      "episode: 5468/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 0.29135751724243164\n",
      "episode: 5469/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 42.81561541557312\n",
      "episode: 5470/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 99.84885168075562\n",
      "episode: 5471/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 29.94568020105362\n",
      "episode: 5472/8000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 19.953134775161743\n",
      "episode: 5473/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 5.576728463172913\n",
      "episode: 5474/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 149.25974929332733\n",
      "episode: 5475/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 159.58964431285858\n",
      "episode: 5476/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 122.26959180831909\n",
      "episode: 5477/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 94.40535628795624\n",
      "episode: 5478/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 67.03196120262146\n",
      "episode: 5479/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 79.74798727035522\n",
      "episode: 5480/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 21.671169221401215\n",
      "episode: 5481/8000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 21.940813541412354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5482/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5483/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 0.0034667253494262695\n",
      "episode: 5484/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 69.6127519607544\n",
      "episode: 5485/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 29.929774165153503\n",
      "episode: 5486/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 60.368708431720734\n",
      "episode: 5487/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 7.270453989505768\n",
      "episode: 5488/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 51.85092067718506\n",
      "episode: 5489/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 45.4140625\n",
      "episode: 5490/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 9.976569175720215\n",
      "episode: 5491/8000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 18.992233157157898\n",
      "episode: 5492/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5493/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 77.31877732276917\n",
      "episode: 5494/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5495/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 10.00048017501831\n",
      "episode: 5496/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 29.940895080566406\n",
      "episode: 5497/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 9.98440271615982\n",
      "episode: 5498/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 0.0034772157669067383\n",
      "episode: 5499/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 50.02202129364014\n",
      "episode: 5500/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 29.4296875\n",
      "episode: 5501/8000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 35.51922047138214\n",
      "episode: 5502/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 62.78634172677994\n",
      "episode: 5503/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 115.94076132774353\n",
      "episode: 5504/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 34.76863914728165\n",
      "episode: 5505/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 50.25018346309662\n",
      "episode: 5506/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 30.72625470161438\n",
      "episode: 5507/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 29.94075244665146\n",
      "episode: 5508/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 73.79594713449478\n",
      "episode: 5509/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 19.955025792121887\n",
      "episode: 5510/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 29.82031613588333\n",
      "episode: 5511/8000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5512/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 101.37822026014328\n",
      "episode: 5513/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 189.1464411020279\n",
      "episode: 5514/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 133.83224266767502\n",
      "episode: 5515/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 58.1656853556633\n",
      "episode: 5516/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 5517/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 79.77914118766785\n",
      "episode: 5518/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 21.708839774131775\n",
      "episode: 5519/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 83.46456396579742\n",
      "episode: 5520/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 99.18750321865082\n",
      "episode: 5521/8000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 30.031616926193237\n",
      "episode: 5522/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 38.8359432220459\n",
      "episode: 5523/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 59.851685881614685\n",
      "episode: 5524/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 67.70115661621094\n",
      "episode: 5525/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5526/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 81.80916899442673\n",
      "episode: 5527/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 28.47944325208664\n",
      "episode: 5528/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 20.484150886535645\n",
      "episode: 5529/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 19.953168988227844\n",
      "episode: 5530/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 2032.3899230957031\n",
      "episode: 5531/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 58.42745107412338\n",
      "episode: 5532/8000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 147.06803846359253\n",
      "episode: 5533/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 158.06307184696198\n",
      "episode: 5534/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 214.65971291065216\n",
      "episode: 5535/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 101.819728910923\n",
      "episode: 5536/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 29.898443400859833\n",
      "episode: 5537/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 91.48922222852707\n",
      "episode: 5538/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 69.83006870746613\n",
      "episode: 5539/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 153.050830245018\n",
      "episode: 5540/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 119.72283291816711\n",
      "episode: 5541/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 165.26589608192444\n",
      "episode: 5542/8000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 11.08987045288086\n",
      "episode: 5543/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 9.978447914123535\n",
      "episode: 5544/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 94.59763020277023\n",
      "episode: 5545/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 86.11052083969116\n",
      "episode: 5546/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 62.67408084869385\n",
      "episode: 5547/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 76.20214289426804\n",
      "episode: 5548/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 85.60093116760254\n",
      "episode: 5549/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 208.30436754226685\n",
      "episode: 5550/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 68.26251864433289\n",
      "episode: 5551/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 191.39378708600998\n",
      "episode: 5552/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 31.08918207883835\n",
      "episode: 5553/8000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 36.372034549713135\n",
      "episode: 5554/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 96.33320289850235\n",
      "episode: 5555/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 137.23059272766113\n",
      "episode: 5556/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5557/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 82.3233904838562\n",
      "episode: 5558/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 40.002410888671875\n",
      "episode: 5559/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 14.304708659648895\n",
      "episode: 5560/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 118.35835266113281\n",
      "episode: 5561/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 46.17464578151703\n",
      "episode: 5562/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5563/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 237.89807271957397\n",
      "episode: 5564/8000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 235.1596953868866\n",
      "episode: 5565/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 153.68375098705292\n",
      "episode: 5566/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5567/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 122.4572257399559\n",
      "episode: 5568/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 52.76447767019272\n",
      "episode: 5569/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 223.15882992744446\n",
      "episode: 5570/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 22.736328125\n",
      "episode: 5571/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 84.64274626970291\n",
      "episode: 5572/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 108.18536406755447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5573/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 19.664169371128082\n",
      "episode: 5574/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 49.750006556510925\n",
      "episode: 5575/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 54.906354665756226\n",
      "episode: 5576/8000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 38.50158613920212\n",
      "episode: 5577/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 5578/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 39.078404545784\n",
      "episode: 5579/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 19.95325595140457\n",
      "episode: 5580/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 235.9283167719841\n",
      "episode: 5581/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 32.84977567195892\n",
      "episode: 5582/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 191.6991823911667\n",
      "episode: 5583/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 169.30664056539536\n",
      "episode: 5584/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 214.67124915122986\n",
      "episode: 5585/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 114.58226335048676\n",
      "episode: 5586/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 174.34734344482422\n",
      "episode: 5587/8000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 0.0036370158195495605\n",
      "episode: 5588/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 231.91547644138336\n",
      "episode: 5589/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 174.86153775453568\n",
      "episode: 5590/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 19.953131079673767\n",
      "episode: 5591/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 145.36740297079086\n",
      "episode: 5592/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 8.225440979003906e-06\n",
      "episode: 5593/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 162.78314244747162\n",
      "episode: 5594/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 193.4848688840866\n",
      "episode: 5595/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 239.95978462696075\n",
      "episode: 5596/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 18.964004516601562\n",
      "episode: 5597/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 216.44422405958176\n",
      "episode: 5598/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 223.2304116487503\n",
      "episode: 5599/8000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 192.22029691934586\n",
      "episode: 5600/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 183.96869254112244\n",
      "episode: 5601/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 0.029281318187713623\n",
      "episode: 5602/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 49.906277775764465\n",
      "episode: 5603/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 128.43566769361496\n",
      "episode: 5604/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 19.96273362636566\n",
      "episode: 5605/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 147.51774334907532\n",
      "episode: 5606/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5607/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 8.059653103351593\n",
      "episode: 5608/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 120.46146231889725\n",
      "episode: 5609/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 114.59036445617676\n",
      "episode: 5610/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 218.81244772672653\n",
      "episode: 5611/8000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 184.97705417871475\n",
      "episode: 5612/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 234.50777125358582\n",
      "episode: 5613/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 117.95082342624664\n",
      "episode: 5614/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 223.49428606033325\n",
      "episode: 5615/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 139.72070217132568\n",
      "episode: 5616/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 42.72968769073486\n",
      "episode: 5617/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 141.99637699127197\n",
      "episode: 5618/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 232.43079560995102\n",
      "episode: 5619/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 52.814762353897095\n",
      "episode: 5620/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 0.1058686375617981\n",
      "episode: 5621/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5622/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 11.413446068763733\n",
      "episode: 5623/8000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 0.007055759429931641\n",
      "episode: 5624/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 28.687540411949158\n",
      "episode: 5625/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 5626/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 42.80726623535156\n",
      "episode: 5627/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5628/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 113.82846742868423\n",
      "episode: 5629/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 234.7680053114891\n",
      "episode: 5630/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 81.21238136291504\n",
      "episode: 5631/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 0.014508426189422607\n",
      "episode: 5632/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 15.067001342773438\n",
      "episode: 5633/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 63.094486951828\n",
      "episode: 5634/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 20.051483154296875\n",
      "episode: 5635/8000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 141.8561863899231\n",
      "episode: 5636/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 20.037717819213867\n",
      "episode: 5637/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 104.18773198127747\n",
      "episode: 5638/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 228.41363722085953\n",
      "episode: 5639/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 75.19069981575012\n",
      "episode: 5640/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 49.41378927230835\n",
      "episode: 5641/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5642/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 82.62208205461502\n",
      "episode: 5643/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 62.644479870796204\n",
      "episode: 5644/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 18.98575782775879\n",
      "episode: 5645/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 19.764999389648438\n",
      "episode: 5646/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 29.931572914123535\n",
      "episode: 5647/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 196.3053171634674\n",
      "episode: 5648/8000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 152.40774762630463\n",
      "episode: 5649/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 88.63780558109283\n",
      "episode: 5650/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5651/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 20.285923719406128\n",
      "episode: 5652/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 110.40824729204178\n",
      "episode: 5653/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 157.67214006185532\n",
      "episode: 5654/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 112.73104095458984\n",
      "episode: 5655/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 10.06085205078125\n",
      "episode: 5656/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 163.81391936540604\n",
      "episode: 5657/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 24.758824467658997\n",
      "episode: 5658/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 99.01042169332504\n",
      "episode: 5659/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 5660/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 310.5294492840767\n",
      "episode: 5661/8000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 10.088577270507812\n",
      "episode: 5662/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 30.666353702545166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5663/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 137.80097699165344\n",
      "episode: 5664/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 227.48215705156326\n",
      "episode: 5665/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 135.26486164331436\n",
      "episode: 5666/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 29.39094227552414\n",
      "episode: 5667/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 177.14653766155243\n",
      "episode: 5668/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 116.45866996049881\n",
      "episode: 5669/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 245.41106593608856\n",
      "episode: 5670/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 179.66026312112808\n",
      "episode: 5671/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 9.976565301418304\n",
      "episode: 5672/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 123.81513673067093\n",
      "episode: 5673/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 59.859417140483856\n",
      "episode: 5674/8000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 122.51321631669998\n",
      "episode: 5675/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 99.48688691854477\n",
      "episode: 5676/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 79.62978112697601\n",
      "episode: 5677/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 39.277829110622406\n",
      "episode: 5678/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 160.3067547082901\n",
      "episode: 5679/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 2008.2877004742622\n",
      "episode: 5680/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 538.2165008187294\n",
      "episode: 5681/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 162.37745314836502\n",
      "episode: 5682/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 83.75714415311813\n",
      "episode: 5683/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 14.542973577976227\n",
      "episode: 5684/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 37.939311265945435\n",
      "episode: 5685/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5686/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 102.64919471740723\n",
      "episode: 5687/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 79.9991267323494\n",
      "episode: 5688/8000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5689/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 193.614828646183\n",
      "episode: 5690/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5691/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 145.47897094488144\n",
      "episode: 5692/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 32.96850919723511\n",
      "episode: 5693/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 216.25917220115662\n",
      "episode: 5694/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 160.65345537662506\n",
      "episode: 5695/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 157.94372326135635\n",
      "episode: 5696/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 190.03255420923233\n",
      "episode: 5697/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 123.13091373443604\n",
      "episode: 5698/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 79.92205041646957\n",
      "episode: 5699/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 112.5367140173912\n",
      "episode: 5700/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 65.23040288686752\n",
      "episode: 5701/8000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 125.78571635484695\n",
      "episode: 5702/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 1.6765663027763367\n",
      "episode: 5703/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 25.057600796222687\n",
      "episode: 5704/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 244.9567255973816\n",
      "episode: 5705/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 37.98453629016876\n",
      "episode: 5706/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 167.52827686071396\n",
      "episode: 5707/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 61.119071662425995\n",
      "episode: 5708/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5709/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 5710/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 122.93879044055939\n",
      "episode: 5711/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 142.89424812793732\n",
      "episode: 5712/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 49.89751434326172\n",
      "episode: 5713/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 122.22372436523438\n",
      "episode: 5714/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 34.55601793527603\n",
      "episode: 5715/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 102.93698590993881\n",
      "episode: 5716/8000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 79.30059278011322\n",
      "episode: 5717/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 74.66749483346939\n",
      "episode: 5718/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 19.955068051815033\n",
      "episode: 5719/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 58.26022136211395\n",
      "episode: 5720/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 236.7670242190361\n",
      "episode: 5721/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 103.24050039052963\n",
      "episode: 5722/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 61.97876238822937\n",
      "episode: 5723/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 59.86033874750137\n",
      "episode: 5724/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 93.87228178977966\n",
      "episode: 5725/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 252.9657118320465\n",
      "episode: 5726/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 234.13853579759598\n",
      "episode: 5727/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 209.56341582536697\n",
      "episode: 5728/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 157.83194988965988\n",
      "episode: 5729/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 26.132266581058502\n",
      "episode: 5730/8000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 102.68422442674637\n",
      "episode: 5731/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 92.68064534664154\n",
      "episode: 5732/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 129.4805542230606\n",
      "episode: 5733/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 184.42702370882034\n",
      "episode: 5734/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 239.85292428731918\n",
      "episode: 5735/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 55.66644388437271\n",
      "episode: 5736/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 139.13512182235718\n",
      "episode: 5737/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 29.43214225769043\n",
      "episode: 5738/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 19.964374482631683\n",
      "episode: 5739/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 67.49057579040527\n",
      "episode: 5740/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 145.34152096509933\n",
      "episode: 5741/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 124.65264809131622\n",
      "episode: 5742/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 162.06695395708084\n",
      "episode: 5743/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 0.18600571155548096\n",
      "episode: 5744/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 189.1844806075096\n",
      "episode: 5745/8000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5746/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 19.17227727174759\n",
      "episode: 5747/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 122.6360451579094\n",
      "episode: 5748/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 10.019500732421875\n",
      "episode: 5749/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 108.89364713430405\n",
      "episode: 5750/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 69.25821751356125\n",
      "episode: 5751/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 0.005824923515319824\n",
      "episode: 5752/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 58.24042868614197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5753/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 19.955149054527283\n",
      "episode: 5754/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 39.82223641872406\n",
      "episode: 5755/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 115.3323717713356\n",
      "episode: 5756/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 17.124035120010376\n",
      "episode: 5757/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5758/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 8.601563394069672\n",
      "episode: 5759/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 213.60613495111465\n",
      "episode: 5760/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 149.94722950458527\n",
      "episode: 5761/8000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 19.5656835436821\n",
      "episode: 5762/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 126.35312205553055\n",
      "episode: 5763/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 81.23734939098358\n",
      "episode: 5764/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 117.36630004644394\n",
      "episode: 5765/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 17.97140121459961\n",
      "episode: 5766/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 36.155369222164154\n",
      "episode: 5767/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 19.97380417585373\n",
      "episode: 5768/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 17.431480407714844\n",
      "episode: 5769/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5770/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 78.21767330169678\n",
      "episode: 5771/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 52.75027686357498\n",
      "episode: 5772/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 51.285207748413086\n",
      "episode: 5773/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 19.77880859375\n",
      "episode: 5774/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 86.9627754688263\n",
      "episode: 5775/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 168.6691814661026\n",
      "episode: 5776/8000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 11.299781501293182\n",
      "episode: 5777/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 19.953248381614685\n",
      "episode: 5778/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 31.962851524353027\n",
      "episode: 5779/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 0.005476176738739014\n",
      "episode: 5780/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 10.740234375\n",
      "episode: 5781/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5782/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5783/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 19.015507102012634\n",
      "episode: 5784/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 154.97810727357864\n",
      "episode: 5785/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 32.70409607887268\n",
      "episode: 5786/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 27.116195678710938\n",
      "episode: 5787/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 165.91775953769684\n",
      "episode: 5788/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 220.44403058290482\n",
      "episode: 5789/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 39.91307878494263\n",
      "episode: 5790/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 39.0859375\n",
      "episode: 5791/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 56.773206889629364\n",
      "episode: 5792/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 61.120653092861176\n",
      "episode: 5793/8000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 62.83573001623154\n",
      "episode: 5794/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 63.38950955867767\n",
      "episode: 5795/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 9.976658999919891\n",
      "episode: 5796/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5797/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 15.634929656982422\n",
      "episode: 5798/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5799/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 101.75453585386276\n",
      "episode: 5800/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 83.01035380363464\n",
      "episode: 5801/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 101.74235850572586\n",
      "episode: 5802/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5803/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 174.3806627392769\n",
      "episode: 5804/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 22.605277061462402\n",
      "episode: 5805/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 65.27053636312485\n",
      "episode: 5806/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 148.96233749389648\n",
      "episode: 5807/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 39.94359344244003\n",
      "episode: 5808/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 63.427977323532104\n",
      "episode: 5809/8000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 19.99641126394272\n",
      "episode: 5810/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 150.6479115486145\n",
      "episode: 5811/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 99.7659769654274\n",
      "episode: 5812/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 59.6025447845459\n",
      "episode: 5813/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 19.1328125\n",
      "episode: 5814/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 62.98606914281845\n",
      "episode: 5815/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 20.679916381835938\n",
      "episode: 5816/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 19.421875\n",
      "episode: 5817/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 9.97671389579773\n",
      "episode: 5818/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 21.263671875\n",
      "episode: 5819/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 126.85876679420471\n",
      "episode: 5820/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 20.27783203125\n",
      "episode: 5821/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 16.808176040649414\n",
      "episode: 5822/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 905.4529267549515\n",
      "episode: 5823/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 135.52267587184906\n",
      "episode: 5824/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 90.26718771457672\n",
      "episode: 5825/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 179.0961582660675\n",
      "episode: 5826/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 93.3359603881836\n",
      "episode: 5827/8000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 47.55287176370621\n",
      "episode: 5828/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 80.31966280937195\n",
      "episode: 5829/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 127.28422904014587\n",
      "episode: 5830/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 86.7110949754715\n",
      "episode: 5831/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 122.93465584516525\n",
      "episode: 5832/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 140.51280117034912\n",
      "episode: 5833/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 39.906262159347534\n",
      "episode: 5834/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 48.72683119773865\n",
      "episode: 5835/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 53.57904052734375\n",
      "episode: 5836/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 19.6640625\n",
      "episode: 5837/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 132.72439271211624\n",
      "episode: 5838/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 102.57455879449844\n",
      "episode: 5839/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 104.94667518138885\n",
      "episode: 5840/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 2239.297821044922\n",
      "episode: 5841/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 9.976562917232513\n",
      "episode: 5842/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 19.484375\n",
      "episode: 5843/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 39.9130574464798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5844/8000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 114.63040632009506\n",
      "episode: 5845/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 49.13486623764038\n",
      "episode: 5846/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 78.41281777620316\n",
      "episode: 5847/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 69.5412666797638\n",
      "episode: 5848/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 123.25422310829163\n",
      "episode: 5849/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 80.14501953125\n",
      "episode: 5850/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5851/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 19.9864501953125\n",
      "episode: 5852/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 39.908912658691406\n",
      "episode: 5853/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 61.39320373535156\n",
      "episode: 5854/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 7.015950262546539\n",
      "episode: 5855/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 40.56139159202576\n",
      "episode: 5856/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 156.4154646396637\n",
      "episode: 5857/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 251.153824031353\n",
      "episode: 5858/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 201.51542621850967\n",
      "episode: 5859/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 235.09632724523544\n",
      "episode: 5860/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 5.891921639442444\n",
      "episode: 5861/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 29.958969116210938\n",
      "episode: 5862/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 69.58322525024414\n",
      "episode: 5863/8000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 91.75638163089752\n",
      "episode: 5864/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 40.804174304008484\n",
      "episode: 5865/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 48.423561811447144\n",
      "episode: 5866/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 62.640625\n",
      "episode: 5867/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5868/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 18.962266862392426\n",
      "episode: 5869/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 89.2500051856041\n",
      "episode: 5870/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 19.9765625\n",
      "episode: 5871/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 22.621093809604645\n",
      "episode: 5872/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 84.62325954437256\n",
      "episode: 5873/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 4.871093809604645\n",
      "episode: 5874/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 84.55766063928604\n",
      "episode: 5875/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 68.39699172973633\n",
      "episode: 5876/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 93.06645369529724\n",
      "episode: 5877/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 194.43450039625168\n",
      "episode: 5878/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 141.93634450435638\n",
      "episode: 5879/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 53.011958956718445\n",
      "episode: 5880/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 29.972004294395447\n",
      "episode: 5881/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5882/8000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 49.882812678813934\n",
      "episode: 5883/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 49.939575254917145\n",
      "episode: 5884/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 60.75677049160004\n",
      "episode: 5885/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5886/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 20.48101782798767\n",
      "episode: 5887/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 76.77787393331528\n",
      "episode: 5888/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 138.76635426282883\n",
      "episode: 5889/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 205.61609691381454\n",
      "episode: 5890/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 59.92652469873428\n",
      "episode: 5891/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 30.013897240161896\n",
      "episode: 5892/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 19.972335815429688\n",
      "episode: 5893/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 18.974400758743286\n",
      "episode: 5894/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 39.89453148841858\n",
      "episode: 5895/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 11.644798040390015\n",
      "episode: 5896/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 84.6851435303688\n",
      "episode: 5897/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 149.08481627702713\n",
      "episode: 5898/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 191.7569875717163\n",
      "episode: 5899/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 48.32151407003403\n",
      "episode: 5900/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 22.71875\n",
      "episode: 5901/8000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 98.05277121067047\n",
      "episode: 5902/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 167.87628948688507\n",
      "episode: 5903/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 74.12965935468674\n",
      "episode: 5904/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 132.14406579732895\n",
      "episode: 5905/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 191.049999833107\n",
      "episode: 5906/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 84.57598865032196\n",
      "episode: 5907/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 5908/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 233.14539635181427\n",
      "episode: 5909/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 127.65604966878891\n",
      "episode: 5910/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 143.58320593833923\n",
      "episode: 5911/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 169.62129044532776\n",
      "episode: 5912/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 181.80143064260483\n",
      "episode: 5913/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 122.20454525947571\n",
      "episode: 5914/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 39.9315881729126\n",
      "episode: 5915/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 237.18247950077057\n",
      "episode: 5916/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 186.5049090385437\n",
      "episode: 5917/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 19.940443515777588\n",
      "episode: 5918/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 39.898895502090454\n",
      "episode: 5919/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 15.375022888183594\n",
      "episode: 5920/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 197.92392092943192\n",
      "episode: 5921/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 89.26123815774918\n",
      "episode: 5922/8000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 37.906251430511475\n",
      "episode: 5923/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 86.29001522064209\n",
      "episode: 5924/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5925/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 82.54563456773758\n",
      "episode: 5926/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 31.21781349182129\n",
      "episode: 5927/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 125.16054975986481\n",
      "episode: 5928/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 139.74203592538834\n",
      "episode: 5929/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 0.19551265239715576\n",
      "episode: 5930/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 49.883092284202576\n",
      "episode: 5931/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 205.0996727347374\n",
      "episode: 5932/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 34.74929714202881\n",
      "episode: 5933/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 158.8795521259308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5934/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 8.592291593551636\n",
      "episode: 5935/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 80.98489284515381\n",
      "episode: 5936/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 76.21581071615219\n",
      "episode: 5937/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 29.703236639499664\n",
      "episode: 5938/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 216.53644746541977\n",
      "episode: 5939/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 29.92187511920929\n",
      "episode: 5940/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 61.78027367591858\n",
      "episode: 5941/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 28.46094399690628\n",
      "episode: 5942/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 0.41045331954956055\n",
      "episode: 5943/8000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 191.3894078731537\n",
      "episode: 5944/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 237.81943035125732\n",
      "episode: 5945/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 248.89712834358215\n",
      "episode: 5946/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 42.697402477264404\n",
      "episode: 5947/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 70.215118765831\n",
      "episode: 5948/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 9.914199352264404\n",
      "episode: 5949/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 32.712907910346985\n",
      "episode: 5950/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 87.12224191427231\n",
      "episode: 5951/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 200.07137823104858\n",
      "episode: 5952/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 61.8622522354126\n",
      "episode: 5953/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 95.03186118602753\n",
      "episode: 5954/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 183.919519841671\n",
      "episode: 5955/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 5956/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 28.846423387527466\n",
      "episode: 5957/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 18.179687559604645\n",
      "episode: 5958/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5959/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 140.9551808834076\n",
      "episode: 5960/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 158.85594898462296\n",
      "episode: 5961/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 190.54355996847153\n",
      "episode: 5962/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 30.085716247558594\n",
      "episode: 5963/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 113.94379150867462\n",
      "episode: 5964/8000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 234.36097294092178\n",
      "episode: 5965/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 60.736707746982574\n",
      "episode: 5966/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 9.953125\n",
      "episode: 5967/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 42.05392521619797\n",
      "episode: 5968/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.5411997437477112\n",
      "episode: 5969/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5970/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5971/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 77.72078603506088\n",
      "episode: 5972/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 102.24149465560913\n",
      "episode: 5973/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 9.976693332195282\n",
      "episode: 5974/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 81.83635741472244\n",
      "episode: 5975/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 22.766289234161377\n",
      "episode: 5976/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 62.73648798465729\n",
      "episode: 5977/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 32.70289611816406\n",
      "episode: 5978/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 195.9515107870102\n",
      "episode: 5979/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5980/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 35.60742938518524\n",
      "episode: 5981/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5982/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 20.27099609375\n",
      "episode: 5983/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 5984/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 32.73768800497055\n",
      "episode: 5985/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 41.14016681909561\n",
      "episode: 5986/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 9.999955475330353\n",
      "episode: 5987/8000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 221.67760598659515\n",
      "episode: 5988/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 187.35126197338104\n",
      "episode: 5989/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 195.10080367326736\n",
      "episode: 5990/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 54.7362060546875\n",
      "episode: 5991/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 150.64115232229233\n",
      "episode: 5992/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5993/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 90.19991058111191\n",
      "episode: 5994/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 84.29550820589066\n",
      "episode: 5995/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 89.26569133996964\n",
      "episode: 5996/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 28.656251072883606\n",
      "episode: 5997/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 98.7664241194725\n",
      "episode: 5998/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 124.4288802742958\n",
      "episode: 5999/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 10.319227278232574\n",
      "episode: 6000/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 84.83864283561707\n",
      "episode: 6001/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 0.0008773207664489746\n",
      "episode: 6002/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6003/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 39.947597563266754\n",
      "episode: 6004/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 88.50080448389053\n",
      "episode: 6005/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 59.920716285705566\n",
      "episode: 6006/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 9.988868713378906\n",
      "episode: 6007/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 62.27064514160156\n",
      "episode: 6008/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 120.22268623113632\n",
      "episode: 6009/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 107.33560490608215\n",
      "episode: 6010/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 123.6435027718544\n",
      "episode: 6011/8000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 146.23834908008575\n",
      "episode: 6012/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 18.96875\n",
      "episode: 6013/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 29.103523671627045\n",
      "episode: 6014/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 14.91595458984375\n",
      "episode: 6015/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 179.9376094341278\n",
      "episode: 6016/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 218.94018936157227\n",
      "episode: 6017/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 81.07253211736679\n",
      "episode: 6018/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 18.016493797302246\n",
      "episode: 6019/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 186.32716208696365\n",
      "episode: 6020/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 32.9215772151947\n",
      "episode: 6021/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 139.67035323381424\n",
      "episode: 6022/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 141.12640607357025\n",
      "episode: 6023/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 90.07422482967377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6024/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 178.16757708787918\n",
      "episode: 6025/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 27.505966186523438\n",
      "episode: 6026/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 0.060843467712402344\n",
      "episode: 6027/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 141.1640431880951\n",
      "episode: 6028/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 6029/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 39.0545768737793\n",
      "episode: 6030/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 64.38763743638992\n",
      "episode: 6031/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 95.38544327020645\n",
      "episode: 6032/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 124.16669172048569\n",
      "episode: 6033/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 12.032499253749847\n",
      "episode: 6034/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6035/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 20.6513671875\n",
      "episode: 6036/8000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 29.92996120452881\n",
      "episode: 6037/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 71.53226846456528\n",
      "episode: 6038/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6039/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 92.89051860570908\n",
      "episode: 6040/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 18.984375\n",
      "episode: 6041/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 20.094970703125\n",
      "episode: 6042/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 21.70391082763672\n",
      "episode: 6043/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 1047.5193798542023\n",
      "episode: 6044/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 19.937506556510925\n",
      "episode: 6045/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 81.72072046995163\n",
      "episode: 6046/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 82.30639809370041\n",
      "episode: 6047/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 90.9242262840271\n",
      "episode: 6048/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 199.959206700325\n",
      "episode: 6049/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 60.36295968294144\n",
      "episode: 6050/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 119.23005360364914\n",
      "episode: 6051/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 52.66601574420929\n",
      "episode: 6052/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 69.92093348503113\n",
      "episode: 6053/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 20.11840856075287\n",
      "episode: 6054/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 18.991464376449585\n",
      "episode: 6055/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 39.756418228149414\n",
      "episode: 6056/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 113.77304601669312\n",
      "episode: 6057/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 162.2096689939499\n",
      "episode: 6058/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 192.2491528391838\n",
      "episode: 6059/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 30.209698379039764\n",
      "episode: 6060/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 85.95391368865967\n",
      "episode: 6061/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 74.91476649045944\n",
      "episode: 6062/8000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 22.791296780109406\n",
      "episode: 6063/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 19.955249786376953\n",
      "episode: 6064/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 19.960927188396454\n",
      "episode: 6065/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 6066/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 202.80567461252213\n",
      "episode: 6067/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 61.64365768432617\n",
      "episode: 6068/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 42.269989013671875\n",
      "episode: 6069/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 57.14663791656494\n",
      "episode: 6070/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 142.56787109375\n",
      "episode: 6071/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 124.8475044965744\n",
      "episode: 6072/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 215.76985782384872\n",
      "episode: 6073/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 206.03113955259323\n",
      "episode: 6074/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 1.1424646377563477\n",
      "episode: 6075/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 92.74690341949463\n",
      "episode: 6076/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 79.09563797712326\n",
      "episode: 6077/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 0.005058348178863525\n",
      "episode: 6078/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 118.73253458738327\n",
      "episode: 6079/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 128.1144733428955\n",
      "episode: 6080/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 9.76051127910614\n",
      "episode: 6081/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 6082/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 52.4082053899765\n",
      "episode: 6083/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 39.92923069000244\n",
      "episode: 6084/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 49.966981053352356\n",
      "episode: 6085/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 218.1403222680092\n",
      "episode: 6086/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 59.85942542552948\n",
      "episode: 6087/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 29.773439586162567\n",
      "episode: 6088/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 2.753734588623047e-05\n",
      "episode: 6089/8000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 11.482427656650543\n",
      "episode: 6090/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 49.522665321826935\n",
      "episode: 6091/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 40.35976231098175\n",
      "episode: 6092/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 39.92088919878006\n",
      "episode: 6093/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 80.32622992992401\n",
      "episode: 6094/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 2463.4448680877686\n",
      "episode: 6095/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6096/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 32.71719264984131\n",
      "episode: 6097/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 66.02551919221878\n",
      "episode: 6098/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 19.95339870452881\n",
      "episode: 6099/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 19.9453125\n",
      "episode: 6100/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 32.219862937927246\n",
      "episode: 6101/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 0.0023154616355895996\n",
      "episode: 6102/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 20.03790283203125\n",
      "episode: 6103/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 52.11251735687256\n",
      "episode: 6104/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 63.774489521980286\n",
      "episode: 6105/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 42.15043348073959\n",
      "episode: 6106/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 9.978548049926758\n",
      "episode: 6107/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 21.613281309604645\n",
      "episode: 6108/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 29.1170791387558\n",
      "episode: 6109/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 70.46430778503418\n",
      "episode: 6110/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 7.215833902359009\n",
      "episode: 6111/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 57.17436242103577\n",
      "episode: 6112/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 6113/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 78.18142241239548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6114/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 137.21523731946945\n",
      "episode: 6115/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 124.45506978034973\n",
      "episode: 6116/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 70.06376022100449\n",
      "episode: 6117/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 231.7534942626953\n",
      "episode: 6118/8000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 59.922057807445526\n",
      "episode: 6119/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 9.978485107421875\n",
      "episode: 6120/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 242.16666448116302\n",
      "episode: 6121/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 6122/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 37.90628105401993\n",
      "episode: 6123/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6124/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 61.9098100066185\n",
      "episode: 6125/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 59.108962416648865\n",
      "episode: 6126/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 30.027512907981873\n",
      "episode: 6127/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 134.8382118344307\n",
      "episode: 6128/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6129/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 21.429688572883606\n",
      "episode: 6130/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6131/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.012409031391143799\n",
      "episode: 6132/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 8.544496417045593\n",
      "episode: 6133/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 19.95312511920929\n",
      "episode: 6134/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 60.61304581165314\n",
      "episode: 6135/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 82.58789706230164\n",
      "episode: 6136/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 41.17075228691101\n",
      "episode: 6137/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 18.953579783439636\n",
      "episode: 6138/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 29.953442096710205\n",
      "episode: 6139/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 177.92681324481964\n",
      "episode: 6140/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6141/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 153.9241639971733\n",
      "episode: 6142/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 20.13142955303192\n",
      "episode: 6143/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 39.92724806070328\n",
      "episode: 6144/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 114.356036901474\n",
      "episode: 6145/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 86.7335649728775\n",
      "episode: 6146/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6147/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 124.95335602760315\n",
      "episode: 6148/8000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 152.76885724067688\n",
      "episode: 6149/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6150/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6151/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 66.41614371538162\n",
      "episode: 6152/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 19.998900055885315\n",
      "episode: 6153/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 80.10385072231293\n",
      "episode: 6154/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 2055.911834716797\n",
      "episode: 6155/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 58.342591285705566\n",
      "episode: 6156/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6157/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 21.984349489212036\n",
      "episode: 6158/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 18.953125953674316\n",
      "episode: 6159/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 81.94772893190384\n",
      "episode: 6160/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6161/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 53.0351637005806\n",
      "episode: 6162/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 19.95313060283661\n",
      "episode: 6163/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 39.185730159282684\n",
      "episode: 6164/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.04839634895324707\n",
      "episode: 6165/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 2.7000904083251953e-05\n",
      "episode: 6166/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 43.92481642961502\n",
      "episode: 6167/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 22.73632901906967\n",
      "episode: 6168/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 48.21120876073837\n",
      "episode: 6169/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 52.6662894487381\n",
      "episode: 6170/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 20.06277370452881\n",
      "episode: 6171/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 60.0284309387207\n",
      "episode: 6172/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 57.98201495409012\n",
      "episode: 6173/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 59.885162115097046\n",
      "episode: 6174/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 5.152815222740173\n",
      "episode: 6175/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 95.89830350875854\n",
      "episode: 6176/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6177/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 147.94306635856628\n",
      "episode: 6178/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 75.42995417118073\n",
      "episode: 6179/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 226.35245788097382\n",
      "episode: 6180/8000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 155.92115211486816\n",
      "episode: 6181/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 107.08708333969116\n",
      "episode: 6182/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 246.586765229702\n",
      "episode: 6183/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 10.431974053382874\n",
      "episode: 6184/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 45.42844635248184\n",
      "episode: 6185/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 186.26876759529114\n",
      "episode: 6186/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 119.27880859375\n",
      "episode: 6187/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 39.890625\n",
      "episode: 6188/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 51.84560000896454\n",
      "episode: 6189/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 8.180908203125\n",
      "episode: 6190/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 29.109375\n",
      "episode: 6191/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 6.443250358104706\n",
      "episode: 6192/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 76.81845813989639\n",
      "episode: 6193/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 20.8531494140625\n",
      "episode: 6194/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 32.40134745836258\n",
      "episode: 6195/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 0.1911388635635376\n",
      "episode: 6196/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 93.90703105926514\n",
      "episode: 6197/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 86.94085502624512\n",
      "episode: 6198/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 31.8922917842865\n",
      "episode: 6199/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 10.513681530952454\n",
      "episode: 6200/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 39.90855830907822\n",
      "episode: 6201/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 63.85196155309677\n",
      "episode: 6202/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 9.95103931427002\n",
      "episode: 6203/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 6204/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 64.37675476074219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6205/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 39.89847952127457\n",
      "episode: 6206/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 41.520508766174316\n",
      "episode: 6207/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 21.993785858154297\n",
      "episode: 6208/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 104.57951837778091\n",
      "episode: 6209/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6210/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 59.67298036813736\n",
      "episode: 6211/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 94.23400110006332\n",
      "episode: 6212/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 5.501508712768555e-05\n",
      "episode: 6213/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 29.40627771615982\n",
      "episode: 6214/8000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 97.38699841499329\n",
      "episode: 6215/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 181.68159759044647\n",
      "episode: 6216/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 52.39259696006775\n",
      "episode: 6217/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 52.632729947566986\n",
      "episode: 6218/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6219/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 135.83321332931519\n",
      "episode: 6220/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 39.37896537780762\n",
      "episode: 6221/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 101.74930733442307\n",
      "episode: 6222/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 82.16805505752563\n",
      "episode: 6223/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 31.16996306180954\n",
      "episode: 6224/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 30.459960997104645\n",
      "episode: 6225/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 18.9453125\n",
      "episode: 6226/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 10.088577270507812\n",
      "episode: 6227/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 91.96109586954117\n",
      "episode: 6228/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6229/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.14783483743667603\n",
      "episode: 6230/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6231/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 84.92077606916428\n",
      "episode: 6232/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 18.97054100036621\n",
      "episode: 6233/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 39.908136427402496\n",
      "episode: 6234/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 33.14953309297562\n",
      "episode: 6235/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 52.14694130420685\n",
      "episode: 6236/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 11.363540887832642\n",
      "episode: 6237/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 22.734375\n",
      "episode: 6238/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 125.67699384689331\n",
      "episode: 6239/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 5.635745346546173\n",
      "episode: 6240/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 236.78896015882492\n",
      "episode: 6241/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 214.25606685876846\n",
      "episode: 6242/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 109.74724125862122\n",
      "episode: 6243/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.94558620452881\n",
      "episode: 6244/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 137.67963254451752\n",
      "episode: 6245/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 18.96875035762787\n",
      "episode: 6246/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6247/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6248/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 29.934256732463837\n",
      "episode: 6249/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 32.22703438997269\n",
      "episode: 6250/8000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 88.21374976634979\n",
      "episode: 6251/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 72.62524747848511\n",
      "episode: 6252/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 59.40065002441406\n",
      "episode: 6253/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6254/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 6255/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 115.72713202238083\n",
      "episode: 6256/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 18.740314304828644\n",
      "episode: 6257/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 50.08818054199219\n",
      "episode: 6258/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 6259/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 50.976515769958496\n",
      "episode: 6260/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 37.24836587905884\n",
      "episode: 6261/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 59.38637971878052\n",
      "episode: 6262/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 19.6640625\n",
      "episode: 6263/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 10.067294955253601\n",
      "episode: 6264/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 18.953565657138824\n",
      "episode: 6265/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 6266/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 39.57813102006912\n",
      "episode: 6267/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 48.47992700338364\n",
      "episode: 6268/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 185.36851888895035\n",
      "episode: 6269/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 130.36445820331573\n",
      "episode: 6270/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6271/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 27.195891857147217\n",
      "episode: 6272/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 29.869304656982422\n",
      "episode: 6273/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 44.31987923383713\n",
      "episode: 6274/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 29.41162109375\n",
      "episode: 6275/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 87.97822570800781\n",
      "episode: 6276/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6277/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 9.99786376953125\n",
      "episode: 6278/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 43.00124794244766\n",
      "episode: 6279/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 75.36977285146713\n",
      "episode: 6280/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 1825.9510079622269\n",
      "episode: 6281/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 39.052455842494965\n",
      "episode: 6282/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 9.989089488983154\n",
      "episode: 6283/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 89.52274364233017\n",
      "episode: 6284/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 22.755348205566406\n",
      "episode: 6285/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 81.83008861541748\n",
      "episode: 6286/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 6287/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 6288/8000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 74.35982018709183\n",
      "episode: 6289/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 39.09375\n",
      "episode: 6290/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 29.392615854740143\n",
      "episode: 6291/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 48.961039543151855\n",
      "episode: 6292/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 22.047118186950684\n",
      "episode: 6293/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 69.82215887308121\n",
      "episode: 6294/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 9.970782935619354\n",
      "episode: 6295/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 0.002895176410675049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6296/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 12.757877349853516\n",
      "episode: 6297/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 52.66609859466553\n",
      "episode: 6298/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 20.02221691608429\n",
      "episode: 6299/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 64.18437904119492\n",
      "episode: 6300/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 51.8933584690094\n",
      "episode: 6301/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 59.76395958662033\n",
      "episode: 6302/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 57.23212093114853\n",
      "episode: 6303/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 22.878173828125\n",
      "episode: 6304/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 21.91699481010437\n",
      "episode: 6305/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 84.95895385742188\n",
      "episode: 6306/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 18.954477310180664\n",
      "episode: 6307/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 79.83632093667984\n",
      "episode: 6308/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 39.12311267852783\n",
      "episode: 6309/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 29.139633178710938\n",
      "episode: 6310/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 153.95159536600113\n",
      "episode: 6311/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 159.70263576507568\n",
      "episode: 6312/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 62.666837215423584\n",
      "episode: 6313/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 31.86907970905304\n",
      "episode: 6314/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 86.17896902561188\n",
      "episode: 6315/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 50.023379266262054\n",
      "episode: 6316/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 19.94534021615982\n",
      "episode: 6317/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 128.85449302196503\n",
      "episode: 6318/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6319/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 18.954856753349304\n",
      "episode: 6320/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 42.13103860616684\n",
      "episode: 6321/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 19.828017473220825\n",
      "episode: 6322/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 11.611297607421875\n",
      "episode: 6323/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 32.73040008544922\n",
      "episode: 6324/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 23.67950439453125\n",
      "episode: 6325/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 19.953126549720764\n",
      "episode: 6326/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6327/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 42.760839104652405\n",
      "episode: 6328/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 30.40045553445816\n",
      "episode: 6329/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 48.37805253267288\n",
      "episode: 6330/8000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 30.733800947666168\n",
      "episode: 6331/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 32.75988918542862\n",
      "episode: 6332/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 46.650569677352905\n",
      "episode: 6333/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 145.97881507873535\n",
      "episode: 6334/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 198.18801200389862\n",
      "episode: 6335/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 161.26346516609192\n",
      "episode: 6336/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 107.89950686693192\n",
      "episode: 6337/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 44.52154731750488\n",
      "episode: 6338/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 1.913309097290039e-05\n",
      "episode: 6339/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.08736824989318848\n",
      "episode: 6340/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 170.39453488588333\n",
      "episode: 6341/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 49.951966285705566\n",
      "episode: 6342/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 26.42297899723053\n",
      "episode: 6343/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 120.58209246397018\n",
      "episode: 6344/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 88.29063546657562\n",
      "episode: 6345/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 20.09637278318405\n",
      "episode: 6346/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 145.00342535972595\n",
      "episode: 6347/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6348/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.5043957233428955\n",
      "episode: 6349/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 116.95921003818512\n",
      "episode: 6350/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 21.98437112569809\n",
      "episode: 6351/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 42.41244262456894\n",
      "episode: 6352/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 38.971381306648254\n",
      "episode: 6353/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 12.611500024795532\n",
      "episode: 6354/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 47.91597753763199\n",
      "episode: 6355/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 163.3951080441475\n",
      "episode: 6356/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.921961545944214\n",
      "episode: 6357/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 81.36658358573914\n",
      "episode: 6358/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 83.9124447107315\n",
      "episode: 6359/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 49.39213055372238\n",
      "episode: 6360/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 157.0190343260765\n",
      "episode: 6361/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 42.68951213359833\n",
      "episode: 6362/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 123.77353435754776\n",
      "episode: 6363/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6364/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 10.012128829956055\n",
      "episode: 6365/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 42.580163419246674\n",
      "episode: 6366/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 41.6212158203125\n",
      "episode: 6367/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 95.71291607618332\n",
      "episode: 6368/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 5.134213089942932\n",
      "episode: 6369/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6370/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 39.906250059604645\n",
      "episode: 6371/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 78.85042077302933\n",
      "episode: 6372/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 10.06298828125\n",
      "episode: 6373/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 20.515519201755524\n",
      "episode: 6374/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 148.5955103635788\n",
      "episode: 6375/8000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 41.62146681547165\n",
      "episode: 6376/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 19.945353507995605\n",
      "episode: 6377/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 104.65996438264847\n",
      "episode: 6378/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 40.00062841176987\n",
      "episode: 6379/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 20.30908203125\n",
      "episode: 6380/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 77.33659791946411\n",
      "episode: 6381/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.21220695972442627\n",
      "episode: 6382/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 7.64917117357254\n",
      "episode: 6383/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 78.22650623321533\n",
      "episode: 6384/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6385/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 65.78386127948761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6386/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6387/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 1018.7014061808586\n",
      "episode: 6388/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 21.693359434604645\n",
      "episode: 6389/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 92.62610882520676\n",
      "episode: 6390/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 42.69138079881668\n",
      "episode: 6391/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 49.89473867416382\n",
      "episode: 6392/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 39.25390625\n",
      "episode: 6393/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 105.93427789211273\n",
      "episode: 6394/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 70.101458132267\n",
      "episode: 6395/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.4798855781555176\n",
      "episode: 6396/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 14.484377920627594\n",
      "episode: 6397/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 8.2578125\n",
      "episode: 6398/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 175.78987962007523\n",
      "episode: 6399/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 62.20508289337158\n",
      "episode: 6400/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 119.30018353462219\n",
      "episode: 6401/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 185.70520877838135\n",
      "episode: 6402/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 243.38888710737228\n",
      "episode: 6403/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 141.93362605571747\n",
      "episode: 6404/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 89.79098981618881\n",
      "episode: 6405/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 136.9981232881546\n",
      "episode: 6406/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6407/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 39.930251359939575\n",
      "episode: 6408/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 145.3262293934822\n",
      "episode: 6409/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6410/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6411/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 183.06785786151886\n",
      "episode: 6412/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 111.10949349403381\n",
      "episode: 6413/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 36.813200771808624\n",
      "episode: 6414/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6415/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 158.07066988945007\n",
      "episode: 6416/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 151.369682431221\n",
      "episode: 6417/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 127.97863936424255\n",
      "episode: 6418/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6419/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 202.52546846866608\n",
      "episode: 6420/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 159.3299006819725\n",
      "episode: 6421/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 16.223548889160156\n",
      "episode: 6422/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 124.42814117670059\n",
      "episode: 6423/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 38.89531832933426\n",
      "episode: 6424/8000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6425/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 18.062500059604645\n",
      "episode: 6426/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 21.17842137813568\n",
      "episode: 6427/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 19.953168988227844\n",
      "episode: 6428/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 70.82149124145508\n",
      "episode: 6429/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 84.81796443462372\n",
      "episode: 6430/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 33.785770654678345\n",
      "episode: 6431/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 56.84631931781769\n",
      "episode: 6432/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 69.91960859298706\n",
      "episode: 6433/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 8.122406005859375\n",
      "episode: 6434/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 187.73438465595245\n",
      "episode: 6435/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 6436/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 51.8937206864357\n",
      "episode: 6437/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 224.8835352063179\n",
      "episode: 6438/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 140.60446441173553\n",
      "episode: 6439/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 99.02186489105225\n",
      "episode: 6440/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6441/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 17.90628808736801\n",
      "episode: 6442/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 105.54871892929077\n",
      "episode: 6443/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 196.5320407152176\n",
      "episode: 6444/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 34.8767072558403\n",
      "episode: 6445/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 18.189293444156647\n",
      "episode: 6446/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 89.56261825561523\n",
      "episode: 6447/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 69.9408255815506\n",
      "episode: 6448/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 114.55223727226257\n",
      "episode: 6449/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 129.82053434848785\n",
      "episode: 6450/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 19.95314610004425\n",
      "episode: 6451/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 43.590765595436096\n",
      "episode: 6452/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 112.57667726278305\n",
      "episode: 6453/8000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 93.9467556476593\n",
      "episode: 6454/8000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 39.91655874252319\n",
      "episode: 6455/8000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 62.71759796142578\n",
      "episode: 6456/8000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 19.95680522918701\n",
      "episode: 6457/8000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 46.77119082212448\n",
      "episode: 6458/8000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 161.51553982496262\n",
      "episode: 6459/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 127.19710570573807\n",
      "episode: 6460/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 19.937978148460388\n",
      "episode: 6461/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 9.484375\n",
      "episode: 6462/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 39.864066541194916\n",
      "episode: 6463/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 19.987380504608154\n",
      "episode: 6464/8000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 156.1814848780632\n",
      "episode: 6465/8000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 19.034729063510895\n",
      "episode: 6466/8000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 9.729484558105469\n",
      "episode: 6467/8000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 155.9222131371498\n",
      "episode: 6468/8000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 49.8828125\n",
      "episode: 6469/8000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 72.61150991916656\n",
      "episode: 6470/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 9.981521725654602\n",
      "episode: 6471/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 54.68070310354233\n",
      "episode: 6472/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 42.69153743982315\n",
      "episode: 6473/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 17.112548828125\n",
      "episode: 6474/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 94.79403328895569\n",
      "episode: 6475/8000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 34.72047233581543\n",
      "episode: 6476/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 79.88092368841171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6477/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 179.03638517856598\n",
      "episode: 6478/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 39.906251549720764\n",
      "episode: 6479/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 19.7900390625\n",
      "episode: 6480/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 10.351317167282104\n",
      "episode: 6481/8000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 93.4169921875\n",
      "episode: 6482/8000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 196.55283051729202\n",
      "episode: 6483/8000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 3800.761601626873\n",
      "episode: 6484/8000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 144.00262641906738\n",
      "episode: 6485/8000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 58.92847818136215\n",
      "episode: 6486/8000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 82.33767944574356\n",
      "episode: 6487/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 3.5808661580085754\n",
      "episode: 6488/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 18.984375\n",
      "episode: 6489/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 1.00390625\n",
      "episode: 6490/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 202.40373492240906\n",
      "episode: 6491/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 103.96204817295074\n",
      "episode: 6492/8000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 39.64065271615982\n",
      "episode: 6493/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 0.0791015625\n",
      "episode: 6494/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 137.97731494903564\n",
      "episode: 6495/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 20.020859122276306\n",
      "episode: 6496/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 49.969963014125824\n",
      "episode: 6497/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 6498/8000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 108.28304648399353\n",
      "episode: 6499/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 29.398211538791656\n",
      "episode: 6500/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 61.82331585884094\n",
      "episode: 6501/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 59.46056652069092\n",
      "episode: 6502/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6503/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 42.762393951416016\n",
      "episode: 6504/8000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 27.4578857421875\n",
      "episode: 6505/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 12.749690115451813\n",
      "episode: 6506/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 158.92594361305237\n",
      "episode: 6507/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 144.35870575904846\n",
      "episode: 6508/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6509/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6510/8000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6511/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 166.8753743171692\n",
      "episode: 6512/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6513/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 200.38442653417587\n",
      "episode: 6514/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 214.16382503509521\n",
      "episode: 6515/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 136.49336856603622\n",
      "episode: 6516/8000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 97.54859137535095\n",
      "episode: 6517/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 39.90652370452881\n",
      "episode: 6518/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 69.84090757369995\n",
      "episode: 6519/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 19.953739643096924\n",
      "episode: 6520/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 41.14559292793274\n",
      "episode: 6521/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 49.8843337893486\n",
      "episode: 6522/8000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 50.4276779294014\n",
      "episode: 6523/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6524/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 192.91251266002655\n",
      "episode: 6525/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 12.761651039123535\n",
      "episode: 6526/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 110.69055235385895\n",
      "episode: 6527/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 40.80832123756409\n",
      "episode: 6528/8000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 176.6926538348198\n",
      "episode: 6529/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 151.11255931854248\n",
      "episode: 6530/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 114.00839281082153\n",
      "episode: 6531/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 99.08318603038788\n",
      "episode: 6532/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 209.35292571783066\n",
      "episode: 6533/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 1090.775602698326\n",
      "episode: 6534/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 7.99733829498291\n",
      "episode: 6535/8000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 0.0001322031021118164\n",
      "episode: 6536/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 29.936701953411102\n",
      "episode: 6537/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 120.93756264448166\n",
      "episode: 6538/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 159.68797898292542\n",
      "episode: 6539/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 100.66409373283386\n",
      "episode: 6540/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 85.46311563253403\n",
      "episode: 6541/8000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 121.70564389228821\n",
      "episode: 6542/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 50.52813744544983\n",
      "episode: 6543/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 66.64496499300003\n",
      "episode: 6544/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 6545/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 2.783227026462555\n",
      "episode: 6546/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 6547/8000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 45.086477398872375\n",
      "episode: 6548/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 8.556286633014679\n",
      "episode: 6549/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 140.87930119037628\n",
      "episode: 6550/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 91.37814158201218\n",
      "episode: 6551/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 6552/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 98.89588582515717\n",
      "episode: 6553/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 231.05508196353912\n",
      "episode: 6554/8000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 39.11733430624008\n",
      "episode: 6555/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 162.12318873405457\n",
      "episode: 6556/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 39.90625\n",
      "episode: 6557/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 30.096040189266205\n",
      "episode: 6558/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 9.741982638835907\n",
      "episode: 6559/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 20.28564453125\n",
      "episode: 6560/8000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 143.3248433470726\n",
      "episode: 6561/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 52.383851051330566\n",
      "episode: 6562/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 127.79574537277222\n",
      "episode: 6563/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 9.996309757232666\n",
      "episode: 6564/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 23.7977294921875\n",
      "episode: 6565/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 144.1875975728035\n",
      "episode: 6566/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6567/8000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 19.953248381614685\n",
      "episode: 6568/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 20.142714142799377\n",
      "episode: 6569/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 159.7446403503418\n",
      "episode: 6570/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6571/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 115.45192241668701\n",
      "episode: 6572/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 6573/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 96.94015103578568\n",
      "episode: 6574/8000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 0.00020182132720947266\n",
      "episode: 6575/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 111.77330899238586\n",
      "episode: 6576/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6577/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 78.9296903014183\n",
      "episode: 6578/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 141.0103418827057\n",
      "episode: 6579/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 121.59348279237747\n",
      "episode: 6580/8000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 101.82041472196579\n",
      "episode: 6581/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6582/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 9.976563453674316\n",
      "episode: 6583/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 6584/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 39.71560841798782\n",
      "episode: 6585/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 186.3735729455948\n",
      "episode: 6586/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 230.43066442012787\n",
      "episode: 6587/8000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 117.90803575515747\n",
      "episode: 6588/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 163.6082090139389\n",
      "episode: 6589/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 54.39137452840805\n",
      "episode: 6590/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 51.00661754608154\n",
      "episode: 6591/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 170.69081354141235\n",
      "episode: 6592/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 163.94914203882217\n",
      "episode: 6593/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6594/8000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 89.45115911960602\n",
      "episode: 6595/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 18.921875298023224\n",
      "episode: 6596/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 0.003498554229736328\n",
      "episode: 6597/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 39.90641838312149\n",
      "episode: 6598/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 241.98022025823593\n",
      "episode: 6599/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 85.33709615468979\n",
      "episode: 6600/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 223.41335666179657\n",
      "episode: 6601/8000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 29.929688096046448\n",
      "episode: 6602/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 40.01385498046875\n",
      "episode: 6603/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 143.35224032402039\n",
      "episode: 6604/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 92.59186172485352\n",
      "episode: 6605/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 88.32048469781876\n",
      "episode: 6606/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 3.0994415283203125e-06\n",
      "episode: 6607/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 31.987438201904297\n",
      "episode: 6608/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 29.93016290664673\n",
      "episode: 6609/8000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 154.16203594207764\n",
      "episode: 6610/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 156.36731094121933\n",
      "episode: 6611/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 8.772993445396423\n",
      "episode: 6612/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 38.771670281887054\n",
      "episode: 6613/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 155.20162534713745\n",
      "episode: 6614/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 62.74193513393402\n",
      "episode: 6615/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 21.91699504852295\n",
      "episode: 6616/8000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 145.09294652938843\n",
      "episode: 6617/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 20.79327154159546\n",
      "episode: 6618/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 131.70130443572998\n",
      "episode: 6619/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 82.47723650932312\n",
      "episode: 6620/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 30.373893558979034\n",
      "episode: 6621/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 154.48159754276276\n",
      "episode: 6622/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6623/8000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 10.821446418762207\n",
      "episode: 6624/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 61.06533467769623\n",
      "episode: 6625/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 29.07063114643097\n",
      "episode: 6626/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 22.736379384994507\n",
      "episode: 6627/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 9.976565599441528\n",
      "episode: 6628/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 62.01785272359848\n",
      "episode: 6629/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 1544.640317082405\n",
      "episode: 6630/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6631/8000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 29.955026626586914\n",
      "episode: 6632/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 27.21574968099594\n",
      "episode: 6633/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 39.921875\n",
      "episode: 6634/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 6635/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 6.602069020271301\n",
      "episode: 6636/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 116.9904352426529\n",
      "episode: 6637/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 53.99856686592102\n",
      "episode: 6638/8000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 121.95236194133759\n",
      "episode: 6639/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 39.35964846611023\n",
      "episode: 6640/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6641/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 39.204466819763184\n",
      "episode: 6642/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 2.205371856689453e-05\n",
      "episode: 6643/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 19.937790989875793\n",
      "episode: 6644/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 10.539493441581726\n",
      "episode: 6645/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 35.61147826910019\n",
      "episode: 6646/8000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 35.33026123046875\n",
      "episode: 6647/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 92.5091912150383\n",
      "episode: 6648/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 19.95312762260437\n",
      "episode: 6649/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 29.28125\n",
      "episode: 6650/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 162.46315556764603\n",
      "episode: 6651/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 45.58398699760437\n",
      "episode: 6652/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 32.713000655174255\n",
      "episode: 6653/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 39.946302473545074\n",
      "episode: 6654/8000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 9.726619362831116\n",
      "episode: 6655/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 29.93269920349121\n",
      "episode: 6656/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 62.10540306568146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6657/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 8.629392743110657\n",
      "episode: 6658/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 126.39198142290115\n",
      "episode: 6659/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 9.7109375\n",
      "episode: 6660/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 184.433995783329\n",
      "episode: 6661/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 1.4991249442100525\n",
      "episode: 6662/8000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 18.60772705078125\n",
      "episode: 6663/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 81.75580847263336\n",
      "episode: 6664/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 237.09581190347672\n",
      "episode: 6665/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 21.96112060546875\n",
      "episode: 6666/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 115.54542684555054\n",
      "episode: 6667/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 49.73231518268585\n",
      "episode: 6668/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 52.31903076171875\n",
      "episode: 6669/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 0.17154818773269653\n",
      "episode: 6670/8000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 18.96875035762787\n",
      "episode: 6671/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 578.8226746916771\n",
      "episode: 6672/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 132.15433812141418\n",
      "episode: 6673/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 126.85072839260101\n",
      "episode: 6674/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 184.98723310232162\n",
      "episode: 6675/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 40.019999504089355\n",
      "episode: 6676/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 243.38050216436386\n",
      "episode: 6677/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 86.15985202789307\n",
      "episode: 6678/8000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 94.39606803655624\n",
      "episode: 6679/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 141.70396035909653\n",
      "episode: 6680/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 130.9570380449295\n",
      "episode: 6681/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 109.54178982973099\n",
      "episode: 6682/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 79.34002685546875\n",
      "episode: 6683/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 88.78722584247589\n",
      "episode: 6684/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 137.18294483423233\n",
      "episode: 6685/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 40.16441947221756\n",
      "episode: 6686/8000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 192.48139661550522\n",
      "episode: 6687/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 90.61824750900269\n",
      "episode: 6688/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 136.09758281707764\n",
      "episode: 6689/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 32.720752596855164\n",
      "episode: 6690/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 153.26459074020386\n",
      "episode: 6691/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 8.292641460895538\n",
      "episode: 6692/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 20.40649938583374\n",
      "episode: 6693/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 92.02416515350342\n",
      "episode: 6694/8000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 121.93363726139069\n",
      "episode: 6695/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6696/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 51.588332414627075\n",
      "episode: 6697/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 30.071533203125\n",
      "episode: 6698/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 89.27352285385132\n",
      "episode: 6699/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 32.712890625\n",
      "episode: 6700/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6701/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 29.90883868932724\n",
      "episode: 6702/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 74.27507638931274\n",
      "episode: 6703/8000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 8.659514784812927\n",
      "episode: 6704/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 86.8179139494896\n",
      "episode: 6705/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 19.953125953674316\n",
      "episode: 6706/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6707/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 39.99097537994385\n",
      "episode: 6708/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 51.530694007873535\n",
      "episode: 6709/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 19.96884649991989\n",
      "episode: 6710/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 61.82677561044693\n",
      "episode: 6711/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 187.95507127046585\n",
      "episode: 6712/8000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 228.9510555267334\n",
      "episode: 6713/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 118.37510800361633\n",
      "episode: 6714/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 156.0797003507614\n",
      "episode: 6715/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 35.19534784555435\n",
      "episode: 6716/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 67.7452621459961\n",
      "episode: 6717/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 138.71573513746262\n",
      "episode: 6718/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 9.991954445838928\n",
      "episode: 6719/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 119.40321999788284\n",
      "episode: 6720/8000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 202.83591932058334\n",
      "episode: 6721/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 69.205078125\n",
      "episode: 6722/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 68.79618126153946\n",
      "episode: 6723/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 83.91862469911575\n",
      "episode: 6724/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 2.8281250596046448\n",
      "episode: 6725/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 26.928970336914062\n",
      "episode: 6726/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 9.15625\n",
      "episode: 6727/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 52.34462505578995\n",
      "episode: 6728/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 185.03903210163116\n",
      "episode: 6729/8000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 82.13458049297333\n",
      "episode: 6730/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 101.77389538288116\n",
      "episode: 6731/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 54.85274678468704\n",
      "episode: 6732/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 118.46333730220795\n",
      "episode: 6733/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 294.9041356444359\n",
      "episode: 6734/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 84.91648077964783\n",
      "episode: 6735/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 30.555407226085663\n",
      "episode: 6736/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 59.13597846031189\n",
      "episode: 6737/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 9.981243133544922\n",
      "episode: 6738/8000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 102.14379346370697\n",
      "episode: 6739/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 29.9630126953125\n",
      "episode: 6740/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 20.32335263490677\n",
      "episode: 6741/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 255.68668049573898\n",
      "episode: 6742/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 16.281254410743713\n",
      "episode: 6743/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 131.47076165676117\n",
      "episode: 6744/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 122.33628797531128\n",
      "episode: 6745/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 22.811215102672577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6746/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 49.0625\n",
      "episode: 6747/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 153.38890105485916\n",
      "episode: 6748/8000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 6749/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 81.4241349697113\n",
      "episode: 6750/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 78.754638671875\n",
      "episode: 6751/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 39.908135414123535\n",
      "episode: 6752/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 49.876714646816254\n",
      "episode: 6753/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 122.41055124998093\n",
      "episode: 6754/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 18.4609375\n",
      "episode: 6755/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 24.95167511701584\n",
      "episode: 6756/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 39.90625\n",
      "episode: 6757/8000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 58.542684674263\n",
      "episode: 6758/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 36.39513850212097\n",
      "episode: 6759/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 42.96630859375\n",
      "episode: 6760/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 1701.3693199157715\n",
      "episode: 6761/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 81.32926732301712\n",
      "episode: 6762/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 19.964374482631683\n",
      "episode: 6763/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 141.23886895179749\n",
      "episode: 6764/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 175.46378976106644\n",
      "episode: 6765/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 41.72385883331299\n",
      "episode: 6766/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 0.0048996806144714355\n",
      "episode: 6767/8000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 170.36519092321396\n",
      "episode: 6768/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 19.836280345916748\n",
      "episode: 6769/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 20.040096521377563\n",
      "episode: 6770/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6771/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 3.767578125\n",
      "episode: 6772/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 166.43016874790192\n",
      "episode: 6773/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 77.05995762348175\n",
      "episode: 6774/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 6775/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 193.58458590507507\n",
      "episode: 6776/8000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 87.6239498257637\n",
      "episode: 6777/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 164.32095229625702\n",
      "episode: 6778/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 41.346821904182434\n",
      "episode: 6779/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 74.0339024066925\n",
      "episode: 6780/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 10.318053722381592\n",
      "episode: 6781/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 8.992187857627869\n",
      "episode: 6782/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 171.3902908563614\n",
      "episode: 6783/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6784/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 40.08034658432007\n",
      "episode: 6785/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 39.89062511920929\n",
      "episode: 6786/8000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 81.27704185247421\n",
      "episode: 6787/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 105.06867241859436\n",
      "episode: 6788/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 0.16662698984146118\n",
      "episode: 6789/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 125.87178206443787\n",
      "episode: 6790/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 243.3599852323532\n",
      "episode: 6791/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 197.05889874696732\n",
      "episode: 6792/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 95.67200565338135\n",
      "episode: 6793/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 18.953125\n",
      "episode: 6794/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 91.92500865459442\n",
      "episode: 6795/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 4.403738856315613\n",
      "episode: 6796/8000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 25.87807935476303\n",
      "episode: 6797/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 68.04735112190247\n",
      "episode: 6798/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 131.48257541656494\n",
      "episode: 6799/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 85.936603307724\n",
      "episode: 6800/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 39.906250059604645\n",
      "episode: 6801/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 133.045414686203\n",
      "episode: 6802/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 3514.8927459716797\n",
      "episode: 6803/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 19.953493118286133\n",
      "episode: 6804/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 66.51368033885956\n",
      "episode: 6805/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 6806/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 120.48490279912949\n",
      "episode: 6807/8000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 9.8359375\n",
      "episode: 6808/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 10.28125\n",
      "episode: 6809/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 9.48437511920929\n",
      "episode: 6810/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 68.44228053092957\n",
      "episode: 6811/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 42.589335441589355\n",
      "episode: 6812/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 98.50230300426483\n",
      "episode: 6813/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 107.47910916805267\n",
      "episode: 6814/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 69.1707808971405\n",
      "episode: 6815/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 121.97306084632874\n",
      "episode: 6816/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 59.89167022705078\n",
      "episode: 6817/8000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 59.797989308834076\n",
      "episode: 6818/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 162.53132408857346\n",
      "episode: 6819/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 45.68379783630371\n",
      "episode: 6820/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 0.003453075885772705\n",
      "episode: 6821/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 39.90625023841858\n",
      "episode: 6822/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 8.759462535381317\n",
      "episode: 6823/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 3.0685606002807617\n",
      "episode: 6824/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 57.24826669692993\n",
      "episode: 6825/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 7.3633716106414795\n",
      "episode: 6826/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 104.86454075574875\n",
      "episode: 6827/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 39.94249963760376\n",
      "episode: 6828/8000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 37.84446567296982\n",
      "episode: 6829/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 91.89788550138474\n",
      "episode: 6830/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 116.15895223617554\n",
      "episode: 6831/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 201.2972342967987\n",
      "episode: 6832/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 194.28841841220856\n",
      "episode: 6833/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 8.058776021003723\n",
      "episode: 6834/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 73.49121797084808\n",
      "episode: 6835/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 262.39217817783356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6836/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 177.30963230133057\n",
      "episode: 6837/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 60.878476083278656\n",
      "episode: 6838/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 91.6709156036377\n",
      "episode: 6839/8000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 163.31790512800217\n",
      "episode: 6840/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 6.94837749004364\n",
      "episode: 6841/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 66.69114279747009\n",
      "episode: 6842/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 51.22745096683502\n",
      "episode: 6843/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 39.90625\n",
      "episode: 6844/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 8.609375\n",
      "episode: 6845/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 36.24119567871094\n",
      "episode: 6846/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 51.02174186706543\n",
      "episode: 6847/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 31.988983988761902\n",
      "episode: 6848/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 84.5614737868309\n",
      "episode: 6849/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 120.98378276824951\n",
      "episode: 6850/8000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 106.80586159229279\n",
      "episode: 6851/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 96.7469043135643\n",
      "episode: 6852/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 35.036490738391876\n",
      "episode: 6853/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 19.953162670135498\n",
      "episode: 6854/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 107.7320556640625\n",
      "episode: 6855/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 64.31396150588989\n",
      "episode: 6856/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 104.44629007577896\n",
      "episode: 6857/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 14.875999450683594\n",
      "episode: 6858/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 19.965438842773438\n",
      "episode: 6859/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 39.90625071525574\n",
      "episode: 6860/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 44.14532262086868\n",
      "episode: 6861/8000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 9.976600170135498\n",
      "episode: 6862/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 34.91812413930893\n",
      "episode: 6863/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 6864/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 38.36346435546875\n",
      "episode: 6865/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 69.54923987388611\n",
      "episode: 6866/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 28.860671997070312\n",
      "episode: 6867/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 150.0467106103897\n",
      "episode: 6868/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 43.5177618265152\n",
      "episode: 6869/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 101.05543577671051\n",
      "episode: 6870/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 134.7317614555359\n",
      "episode: 6871/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 109.8926568031311\n",
      "episode: 6872/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 29.92968761920929\n",
      "episode: 6873/8000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 38.299801886081696\n",
      "episode: 6874/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 19.9765625\n",
      "episode: 6875/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 92.65454232692719\n",
      "episode: 6876/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 6877/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 41.35009765625\n",
      "episode: 6878/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 9.948335886001587\n",
      "episode: 6879/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 113.68113970756531\n",
      "episode: 6880/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 68.57058620452881\n",
      "episode: 6881/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 10.335384368896484\n",
      "episode: 6882/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 81.14027011394501\n",
      "episode: 6883/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6884/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 71.13901597261429\n",
      "episode: 6885/8000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 9.484375417232513\n",
      "episode: 6886/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 86.78927457332611\n",
      "episode: 6887/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 19.95313173532486\n",
      "episode: 6888/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 12.763736724853516\n",
      "episode: 6889/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 29.96445882320404\n",
      "episode: 6890/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 90.47775596380234\n",
      "episode: 6891/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 162.2876946926117\n",
      "episode: 6892/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 6893/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 101.9282488822937\n",
      "episode: 6894/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 0.006927490234375\n",
      "episode: 6895/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 9.978553235530853\n",
      "episode: 6896/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 81.87607073783875\n",
      "episode: 6897/8000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 9.484375357627869\n",
      "episode: 6898/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 139.70213705301285\n",
      "episode: 6899/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 73.99512338638306\n",
      "episode: 6900/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 29.390667259693146\n",
      "episode: 6901/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 19.6640625\n",
      "episode: 6902/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 69.14431756734848\n",
      "episode: 6903/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 77.09407895803452\n",
      "episode: 6904/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 19.664068579673767\n",
      "episode: 6905/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 43.00927734375\n",
      "episode: 6906/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 8.200137972831726\n",
      "episode: 6907/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 49.91322761774063\n",
      "episode: 6908/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 148.84562385082245\n",
      "episode: 6909/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 83.49199867248535\n",
      "episode: 6910/8000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 131.53907579183578\n",
      "episode: 6911/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6912/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 94.10985308885574\n",
      "episode: 6913/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 265.16937106847763\n",
      "episode: 6914/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 62.72668468952179\n",
      "episode: 6915/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 5.434044897556305\n",
      "episode: 6916/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 86.3535544872284\n",
      "episode: 6917/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 76.83883625268936\n",
      "episode: 6918/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 123.53697228431702\n",
      "episode: 6919/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 38.35681188106537\n",
      "episode: 6920/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 96.4716227054596\n",
      "episode: 6921/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6922/8000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 38.54565554857254\n",
      "episode: 6923/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 185.86502873897552\n",
      "episode: 6924/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 61.580214977264404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6925/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 126.8204054236412\n",
      "episode: 6926/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 39.932716369628906\n",
      "episode: 6927/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 11.34108018875122\n",
      "episode: 6928/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 29.392090797424316\n",
      "episode: 6929/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 87.81055599451065\n",
      "episode: 6930/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 42.579262375831604\n",
      "episode: 6931/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 15.60937511920929\n",
      "episode: 6932/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 20.037317752838135\n",
      "episode: 6933/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 73.66128540039062\n",
      "episode: 6934/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 15.832709431648254\n",
      "episode: 6935/8000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 19.953151643276215\n",
      "episode: 6936/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 122.50374412536621\n",
      "episode: 6937/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 113.02975654602051\n",
      "episode: 6938/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 47.60190623998642\n",
      "episode: 6939/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 166.52202773094177\n",
      "episode: 6940/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 21.984344482421875\n",
      "episode: 6941/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 42.070749163627625\n",
      "episode: 6942/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 214.75653702020645\n",
      "episode: 6943/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 171.6917536854744\n",
      "episode: 6944/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 19.797146320343018\n",
      "episode: 6945/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 126.7570549249649\n",
      "episode: 6946/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 94.58538180589676\n",
      "episode: 6947/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 96.43773543834686\n",
      "episode: 6948/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 31.91717565059662\n",
      "episode: 6949/8000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 10.29489779472351\n",
      "episode: 6950/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 30.242854356765747\n",
      "episode: 6951/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 72.68762212991714\n",
      "episode: 6952/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 114.68350124359131\n",
      "episode: 6953/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 162.42152172327042\n",
      "episode: 6954/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 38.98951768875122\n",
      "episode: 6955/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 19.125272750854492\n",
      "episode: 6956/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 55.994153916835785\n",
      "episode: 6957/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 39.8831125497818\n",
      "episode: 6958/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 142.34119790792465\n",
      "episode: 6959/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 78.42060935497284\n",
      "episode: 6960/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 79.24757730960846\n",
      "episode: 6961/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 62.4565452337265\n",
      "episode: 6962/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6963/8000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 34.849609375\n",
      "episode: 6964/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 9.191375732421875\n",
      "episode: 6965/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 10.114227294921875\n",
      "episode: 6966/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 19.845550537109375\n",
      "episode: 6967/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 39.88292193412781\n",
      "episode: 6968/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 39.464688301086426\n",
      "episode: 6969/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 171.81986314058304\n",
      "episode: 6970/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 22.073040008544922\n",
      "episode: 6971/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 81.87165838479996\n",
      "episode: 6972/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 105.95909875631332\n",
      "episode: 6973/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 47.89172238111496\n",
      "episode: 6974/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 246.7982076406479\n",
      "episode: 6975/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 18.953125\n",
      "episode: 6976/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 0.3405325412750244\n",
      "episode: 6977/8000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 39.90625\n",
      "episode: 6978/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6979/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 157.90232706069946\n",
      "episode: 6980/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 6981/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 19.936508178710938\n",
      "episode: 6982/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 67.52151256799698\n",
      "episode: 6983/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 20.501676321029663\n",
      "episode: 6984/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 39.90684235095978\n",
      "episode: 6985/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 9.5167236328125\n",
      "episode: 6986/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 2.7832093238830566\n",
      "episode: 6987/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 41.77734375\n",
      "episode: 6988/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 73.08154320716858\n",
      "episode: 6989/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 140.82672595977783\n",
      "episode: 6990/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 18.921875\n",
      "episode: 6991/8000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 39.58903646469116\n",
      "episode: 6992/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 89.22899234294891\n",
      "episode: 6993/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 183.7108108997345\n",
      "episode: 6994/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 256.0038824081421\n",
      "episode: 6995/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 195.71971195936203\n",
      "episode: 6996/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 113.46642071008682\n",
      "episode: 6997/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 79.90057373046875\n",
      "episode: 6998/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 101.06325179338455\n",
      "episode: 6999/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 7000/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 52.26252770423889\n",
      "episode: 7001/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 15.578125298023224\n",
      "episode: 7002/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 45.48841726779938\n",
      "episode: 7003/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 99.56231820583344\n",
      "episode: 7004/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 1447.5142520666122\n",
      "episode: 7005/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 20.406494140625\n",
      "episode: 7006/8000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 42.53526383638382\n",
      "episode: 7007/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 237.03038996458054\n",
      "episode: 7008/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 68.49753218889236\n",
      "episode: 7009/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 42.712890625\n",
      "episode: 7010/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 79.81263864040375\n",
      "episode: 7011/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 29.921875\n",
      "episode: 7012/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 15.016587376594543\n",
      "episode: 7013/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 75.4441350698471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7014/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 29.667989671230316\n",
      "episode: 7015/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 159.15132820606232\n",
      "episode: 7016/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 108.84836506843567\n",
      "episode: 7017/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 7018/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 19.953682482242584\n",
      "episode: 7019/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7020/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 131.3112149834633\n",
      "episode: 7021/8000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 192.3476783633232\n",
      "episode: 7022/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 108.13441491127014\n",
      "episode: 7023/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 158.13658332824707\n",
      "episode: 7024/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 189.70688539743423\n",
      "episode: 7025/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 229.72609496116638\n",
      "episode: 7026/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 221.2577994465828\n",
      "episode: 7027/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 128.11733973026276\n",
      "episode: 7028/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 61.08517211675644\n",
      "episode: 7029/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 111.80094826221466\n",
      "episode: 7030/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 0.0006819963455200195\n",
      "episode: 7031/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 228.87645995616913\n",
      "episode: 7032/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 56.87503981590271\n",
      "episode: 7033/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 59.83976489305496\n",
      "episode: 7034/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 176.1164601445198\n",
      "episode: 7035/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 70.46491479873657\n",
      "episode: 7036/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 3.325669825077057\n",
      "episode: 7037/8000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 117.74376547336578\n",
      "episode: 7038/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7039/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 22.744140625\n",
      "episode: 7040/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 159.3655213713646\n",
      "episode: 7041/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 162.14452117681503\n",
      "episode: 7042/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 54.35590612888336\n",
      "episode: 7043/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 7044/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 41.213373720645905\n",
      "episode: 7045/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 59.94336199760437\n",
      "episode: 7046/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 228.94813853502274\n",
      "episode: 7047/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 234.6671480536461\n",
      "episode: 7048/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 159.6959183216095\n",
      "episode: 7049/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 29.263559460639954\n",
      "episode: 7050/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 148.07067263126373\n",
      "episode: 7051/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 120.06441301107407\n",
      "episode: 7052/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 96.04505401849747\n",
      "episode: 7053/8000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 9.328125\n",
      "episode: 7054/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 99.25431609153748\n",
      "episode: 7055/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 39.906292259693146\n",
      "episode: 7056/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 92.0184440612793\n",
      "episode: 7057/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 99.05603313446045\n",
      "episode: 7058/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 59.937742590904236\n",
      "episode: 7059/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 189.60695028305054\n",
      "episode: 7060/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 39.37476736307144\n",
      "episode: 7061/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7062/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 19.95312589406967\n",
      "episode: 7063/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 257.51283580064774\n",
      "episode: 7064/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 44.06001931428909\n",
      "episode: 7065/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 22.744343996047974\n",
      "episode: 7066/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 56.39921861886978\n",
      "episode: 7067/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 30.240023255348206\n",
      "episode: 7068/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 129.9454698562622\n",
      "episode: 7069/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 77.68857181072235\n",
      "episode: 7070/8000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 7071/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 37.734498381614685\n",
      "episode: 7072/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 103.6746432185173\n",
      "episode: 7073/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 71.19030851125717\n",
      "episode: 7074/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 46.77860164642334\n",
      "episode: 7075/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 7076/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 1033.2333509922028\n",
      "episode: 7077/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 89.04546201229095\n",
      "episode: 7078/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 42.774257600307465\n",
      "episode: 7079/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 41.16908359527588\n",
      "episode: 7080/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 19.921877443790436\n",
      "episode: 7081/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 18.9687562584877\n",
      "episode: 7082/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 148.31820505857468\n",
      "episode: 7083/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 82.59674060344696\n",
      "episode: 7084/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 44.439739525318146\n",
      "episode: 7085/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 194.1611680984497\n",
      "episode: 7086/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 40.03612893819809\n",
      "episode: 7087/8000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7088/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 52.66804838180542\n",
      "episode: 7089/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 84.42387211322784\n",
      "episode: 7090/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 31.90280246734619\n",
      "episode: 7091/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 41.80908644199371\n",
      "episode: 7092/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 32.74563181400299\n",
      "episode: 7093/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 19.970564126968384\n",
      "episode: 7094/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 148.15920650959015\n",
      "episode: 7095/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 25.1619873046875\n",
      "episode: 7096/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 107.61810463666916\n",
      "episode: 7097/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7098/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 39.990478515625\n",
      "episode: 7099/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 59.95936036109924\n",
      "episode: 7100/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 89.86323422193527\n",
      "episode: 7101/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 100.30730944871902\n",
      "episode: 7102/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 125.42399030923843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7103/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 19.953126847743988\n",
      "episode: 7104/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 4.96084600687027\n",
      "episode: 7105/8000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7106/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7107/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 102.01708126068115\n",
      "episode: 7108/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 154.35404747724533\n",
      "episode: 7109/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 88.00781351327896\n",
      "episode: 7110/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 68.17247104644775\n",
      "episode: 7111/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 27.35085666179657\n",
      "episode: 7112/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 2.642578125\n",
      "episode: 7113/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 177.32499969005585\n",
      "episode: 7114/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 38.66406923532486\n",
      "episode: 7115/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 161.8620901107788\n",
      "episode: 7116/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 196.13269346952438\n",
      "episode: 7117/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 145.57470792531967\n",
      "episode: 7118/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 79.05287843942642\n",
      "episode: 7119/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 102.38480877876282\n",
      "episode: 7120/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 39.91482639312744\n",
      "episode: 7121/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 7122/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7123/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 68.853451192379\n",
      "episode: 7124/8000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 32.712890625\n",
      "episode: 7125/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 51.820231914520264\n",
      "episode: 7126/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 84.82716280221939\n",
      "episode: 7127/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 69.89851731061935\n",
      "episode: 7128/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 198.67524576187134\n",
      "episode: 7129/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 87.2115495800972\n",
      "episode: 7130/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7131/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7132/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 58.77762424945831\n",
      "episode: 7133/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 22.736407697200775\n",
      "episode: 7134/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 22.465676069259644\n",
      "episode: 7135/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 52.5743408203125\n",
      "episode: 7136/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7137/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 92.6309825181961\n",
      "episode: 7138/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 20.082977294921875\n",
      "episode: 7139/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 131.33015036582947\n",
      "episode: 7140/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 59.954812586307526\n",
      "episode: 7141/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 248.53323364257812\n",
      "episode: 7142/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 175.42614245414734\n",
      "episode: 7143/8000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 160.21627992391586\n",
      "episode: 7144/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 102.11737251281738\n",
      "episode: 7145/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 79.00384646654129\n",
      "episode: 7146/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 193.50636214017868\n",
      "episode: 7147/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 11.896993815898895\n",
      "episode: 7148/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 40.64088535308838\n",
      "episode: 7149/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 82.13593143224716\n",
      "episode: 7150/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 53.18984317779541\n",
      "episode: 7151/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 138.01884347200394\n",
      "episode: 7152/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 19.914066314697266\n",
      "episode: 7153/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 135.9874582886696\n",
      "episode: 7154/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 20.082977294921875\n",
      "episode: 7155/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 32.70174789428711\n",
      "episode: 7156/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 49.48126220703125\n",
      "episode: 7157/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 4.760742545127869\n",
      "episode: 7158/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 123.21749120950699\n",
      "episode: 7159/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 29.982379734516144\n",
      "episode: 7160/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 52.976116478443146\n",
      "episode: 7161/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 72.04061752557755\n",
      "episode: 7162/8000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 96.29633283615112\n",
      "episode: 7163/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 59.275322914123535\n",
      "episode: 7164/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 37.98621243238449\n",
      "episode: 7165/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 72.23372000455856\n",
      "episode: 7166/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 69.87218284606934\n",
      "episode: 7167/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 199.48301047086716\n",
      "episode: 7168/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 165.17941772937775\n",
      "episode: 7169/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 104.45749706029892\n",
      "episode: 7170/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 19.671916663646698\n",
      "episode: 7171/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 58.751953125\n",
      "episode: 7172/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 55.41424572467804\n",
      "episode: 7173/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 32.71289074420929\n",
      "episode: 7174/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 18.525642216205597\n",
      "episode: 7175/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 59.521549224853516\n",
      "episode: 7176/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 6.895264029502869\n",
      "episode: 7177/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 51.92440605163574\n",
      "episode: 7178/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 19.953127562999725\n",
      "episode: 7179/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 92.52726304531097\n",
      "episode: 7180/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 191.03034776449203\n",
      "episode: 7181/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7182/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 131.02895671129227\n",
      "episode: 7183/8000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 89.50247794389725\n",
      "episode: 7184/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 165.5402711033821\n",
      "episode: 7185/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 0.002916097640991211\n",
      "episode: 7186/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 208.01551467180252\n",
      "episode: 7187/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 266.3512327671051\n",
      "episode: 7188/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 72.17655754089355\n",
      "episode: 7189/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 30.23974609375\n",
      "episode: 7190/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 140.908203125\n",
      "episode: 7191/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 50.20688307285309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7192/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 99.84263253211975\n",
      "episode: 7193/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 104.87346142530441\n",
      "episode: 7194/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 67.81015110015869\n",
      "episode: 7195/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 195.0892562866211\n",
      "episode: 7196/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 124.65616619586945\n",
      "episode: 7197/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 100.07514429092407\n",
      "episode: 7198/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 161.90376287698746\n",
      "episode: 7199/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 39.90625262260437\n",
      "episode: 7200/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 209.41857665777206\n",
      "episode: 7201/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 199.53624057769775\n",
      "episode: 7202/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 54.82756632566452\n",
      "episode: 7203/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 123.78198719024658\n",
      "episode: 7204/8000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 59.0551832318306\n",
      "episode: 7205/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 39.987504959106445\n",
      "episode: 7206/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 99.01604348421097\n",
      "episode: 7207/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 20.818359434604645\n",
      "episode: 7208/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 49.435333251953125\n",
      "episode: 7209/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 72.23405772447586\n",
      "episode: 7210/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 7211/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 7212/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 96.97290104627609\n",
      "episode: 7213/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 45.53002941608429\n",
      "episode: 7214/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 115.50108349323273\n",
      "episode: 7215/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 102.4307946562767\n",
      "episode: 7216/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 22.74802017211914\n",
      "episode: 7217/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 197.57863402366638\n",
      "episode: 7218/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 40.184990882873535\n",
      "episode: 7219/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 125.23693406581879\n",
      "episode: 7220/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 2031.9753836989403\n",
      "episode: 7221/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 34.72957903146744\n",
      "episode: 7222/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 170.56056851148605\n",
      "episode: 7223/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 72.74121487140656\n",
      "episode: 7224/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 121.00239133834839\n",
      "episode: 7225/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7226/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 114.68036890029907\n",
      "episode: 7227/8000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 86.53713536262512\n",
      "episode: 7228/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 0.02500736713409424\n",
      "episode: 7229/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 69.83597975969315\n",
      "episode: 7230/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 39.90839147567749\n",
      "episode: 7231/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 89.46092987060547\n",
      "episode: 7232/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 9.460945308208466\n",
      "episode: 7233/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 22.73635482788086\n",
      "episode: 7234/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 209.4987296462059\n",
      "episode: 7235/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 52.20963627099991\n",
      "episode: 7236/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 50.336182594299316\n",
      "episode: 7237/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 31.99609887599945\n",
      "episode: 7238/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 96.07986253499985\n",
      "episode: 7239/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 115.5157800912857\n",
      "episode: 7240/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 114.88680475950241\n",
      "episode: 7241/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 85.1367198228836\n",
      "episode: 7242/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 55.56256711483002\n",
      "episode: 7243/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7244/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 90.45478338003159\n",
      "episode: 7245/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 7.331371307373047e-05\n",
      "episode: 7246/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 98.6946913599968\n",
      "episode: 7247/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 20.28564453125\n",
      "episode: 7248/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 67.53957146406174\n",
      "episode: 7249/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7250/8000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 27.782729148864746\n",
      "episode: 7251/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 9.46903795003891\n",
      "episode: 7252/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 113.99239701032639\n",
      "episode: 7253/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 19.95339870452881\n",
      "episode: 7254/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 199.97636514902115\n",
      "episode: 7255/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 169.43966871500015\n",
      "episode: 7256/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 147.90128070116043\n",
      "episode: 7257/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 234.5799366235733\n",
      "episode: 7258/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7259/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 29.72833251953125\n",
      "episode: 7260/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 39.908135414123535\n",
      "episode: 7261/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 20.092945218086243\n",
      "episode: 7262/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 52.50125551223755\n",
      "episode: 7263/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 94.92468923330307\n",
      "episode: 7264/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 136.64699447155\n",
      "episode: 7265/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 55.88359194993973\n",
      "episode: 7266/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 0.0019912123680114746\n",
      "episode: 7267/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 16.989748895168304\n",
      "episode: 7268/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 84.73592960834503\n",
      "episode: 7269/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 154.6787211894989\n",
      "episode: 7270/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 7271/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 82.79595613479614\n",
      "episode: 7272/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 0.0006618499755859375\n",
      "episode: 7273/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 65.62820166349411\n",
      "episode: 7274/8000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 58.708953857421875\n",
      "episode: 7275/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 19.955108642578125\n",
      "episode: 7276/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 19.125041484832764\n",
      "episode: 7277/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 45.3556187748909\n",
      "episode: 7278/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 55.68992209434509\n",
      "episode: 7279/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 2.5119158029556274\n",
      "episode: 7280/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 51.47363471984863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7281/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 198.90664547681808\n",
      "episode: 7282/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 45.483009457588196\n",
      "episode: 7283/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 228.44693434238434\n",
      "episode: 7284/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 153.52884310483932\n",
      "episode: 7285/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 99.1078610420227\n",
      "episode: 7286/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 31.95404052734375\n",
      "episode: 7287/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 97.40410858392715\n",
      "episode: 7288/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 81.4447780251503\n",
      "episode: 7289/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7290/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7291/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 74.86895751953125\n",
      "episode: 7292/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7293/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 7.872153878211975\n",
      "episode: 7294/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 1973.8261734247208\n",
      "episode: 7295/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 69.842433989048\n",
      "episode: 7296/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 12.8677978515625\n",
      "episode: 7297/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 200.75978821516037\n",
      "episode: 7298/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 164.7796550989151\n",
      "episode: 7299/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.037600934505462646\n",
      "episode: 7300/8000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 245.7466139793396\n",
      "episode: 7301/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 64.68711292743683\n",
      "episode: 7302/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 75.14263707399368\n",
      "episode: 7303/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 40.54883420467377\n",
      "episode: 7304/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 72.1275006532669\n",
      "episode: 7305/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 109.75515925884247\n",
      "episode: 7306/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 53.67638427019119\n",
      "episode: 7307/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 0.726222574710846\n",
      "episode: 7308/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 131.18758481740952\n",
      "episode: 7309/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 39.906276762485504\n",
      "episode: 7310/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 155.43473726511002\n",
      "episode: 7311/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 0.39620441198349\n",
      "episode: 7312/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 40.519408881664276\n",
      "episode: 7313/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 81.00142186880112\n",
      "episode: 7314/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 49.25919437408447\n",
      "episode: 7315/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 128.19242721796036\n",
      "episode: 7316/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 64.52233123779297\n",
      "episode: 7317/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 16.234375\n",
      "episode: 7318/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 29.767676949501038\n",
      "episode: 7319/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 20.040346682071686\n",
      "episode: 7320/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 62.1181902885437\n",
      "episode: 7321/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 29.14374941587448\n",
      "episode: 7322/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 85.49468278884888\n",
      "episode: 7323/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 50.98517179489136\n",
      "episode: 7324/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 61.858595073223114\n",
      "episode: 7325/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 8.193498492240906\n",
      "episode: 7326/8000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 110.95849168300629\n",
      "episode: 7327/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 42.267578125\n",
      "episode: 7328/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 99.42873334884644\n",
      "episode: 7329/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 39.40910184383392\n",
      "episode: 7330/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 129.77560234069824\n",
      "episode: 7331/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 138.6855525970459\n",
      "episode: 7332/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 168.37429559230804\n",
      "episode: 7333/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 122.89322525262833\n",
      "episode: 7334/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 59.86134773492813\n",
      "episode: 7335/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 21.14022958278656\n",
      "episode: 7336/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 143.6178556084633\n",
      "episode: 7337/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 29.81556785106659\n",
      "episode: 7338/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 109.19518440961838\n",
      "episode: 7339/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 68.86130619049072\n",
      "episode: 7340/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 189.23449099063873\n",
      "episode: 7341/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 59.073263227939606\n",
      "episode: 7342/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 19.9550199508667\n",
      "episode: 7343/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 34.421875953674316\n",
      "episode: 7344/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 20.761428833007812\n",
      "episode: 7345/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 58.281107902526855\n",
      "episode: 7346/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 59.30146199464798\n",
      "episode: 7347/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 147.2957785129547\n",
      "episode: 7348/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 173.3901738524437\n",
      "episode: 7349/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 16.641615867614746\n",
      "episode: 7350/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 65.27347666025162\n",
      "episode: 7351/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 56.72557592391968\n",
      "episode: 7352/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 66.94285053014755\n",
      "episode: 7353/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 67.30157935619354\n",
      "episode: 7354/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7355/8000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 31.171576142311096\n",
      "episode: 7356/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 102.47705805301666\n",
      "episode: 7357/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 97.67587822675705\n",
      "episode: 7358/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 19.957073211669922\n",
      "episode: 7359/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 71.81479072570801\n",
      "episode: 7360/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 12.128906607627869\n",
      "episode: 7361/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 41.4404296875\n",
      "episode: 7362/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 85.30043840408325\n",
      "episode: 7363/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 76.1313139796257\n",
      "episode: 7364/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 118.33356350660324\n",
      "episode: 7365/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 0.19406908750534058\n",
      "episode: 7366/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 92.54176890850067\n",
      "episode: 7367/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 19.953359007835388\n",
      "episode: 7368/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 1.5497207641601562e-05\n",
      "episode: 7369/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 197.19456779956818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7370/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 68.63830834627151\n",
      "episode: 7371/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7372/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 15.96875\n",
      "episode: 7373/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 79.1743745803833\n",
      "episode: 7374/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 114.30357050895691\n",
      "episode: 7375/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 408.5512776374817\n",
      "episode: 7376/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 77.14643830060959\n",
      "episode: 7377/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 9.976563453674316\n",
      "episode: 7378/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 60.012850284576416\n",
      "episode: 7379/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 24.23828125\n",
      "episode: 7380/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 69.85731333494186\n",
      "episode: 7381/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 83.61416208744049\n",
      "episode: 7382/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 42.90466904640198\n",
      "episode: 7383/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 44.704033851623535\n",
      "episode: 7384/8000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 114.03107345104218\n",
      "episode: 7385/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 15.1058349609375\n",
      "episode: 7386/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 28.47007119655609\n",
      "episode: 7387/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 29.143270432949066\n",
      "episode: 7388/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 127.5197805762291\n",
      "episode: 7389/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 233.77013754844666\n",
      "episode: 7390/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 60.971750020980835\n",
      "episode: 7391/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 185.627869784832\n",
      "episode: 7392/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 19.867263793945312\n",
      "episode: 7393/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 7394/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 39.875\n",
      "episode: 7395/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 118.92181766033173\n",
      "episode: 7396/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 57.85717862844467\n",
      "episode: 7397/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 121.47772216796875\n",
      "episode: 7398/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 19.95511621236801\n",
      "episode: 7399/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7400/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 29.90625\n",
      "episode: 7401/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 20.171148657798767\n",
      "episode: 7402/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7403/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 10.894035339355469\n",
      "episode: 7404/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 181.80538201332092\n",
      "episode: 7405/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 29.7969069480896\n",
      "episode: 7406/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 18.81402587890625\n",
      "episode: 7407/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 75.22625833749771\n",
      "episode: 7408/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 87.23268789052963\n",
      "episode: 7409/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 128.9475833773613\n",
      "episode: 7410/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 17.86695098876953\n",
      "episode: 7411/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 141.19552677869797\n",
      "episode: 7412/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 7413/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 82.59574508666992\n",
      "episode: 7414/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 89.75126081705093\n",
      "episode: 7415/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 7416/8000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 99.71875095367432\n",
      "episode: 7417/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 43.90429949760437\n",
      "episode: 7418/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 138.14087045192719\n",
      "episode: 7419/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 18.483052253723145\n",
      "episode: 7420/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 52.5657958984375\n",
      "episode: 7421/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 155.54723650217056\n",
      "episode: 7422/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 161.39617830514908\n",
      "episode: 7423/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 59.85938239097595\n",
      "episode: 7424/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 89.75781428813934\n",
      "episode: 7425/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 0.7483550310134888\n",
      "episode: 7426/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 20.406494140625\n",
      "episode: 7427/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 76.84069955348969\n",
      "episode: 7428/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 193.09672313928604\n",
      "episode: 7429/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 44.75380390882492\n",
      "episode: 7430/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 118.49945718050003\n",
      "episode: 7431/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 148.1181371808052\n",
      "episode: 7432/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 62.3383549451828\n",
      "episode: 7433/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 125.97012513875961\n",
      "episode: 7434/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 180.93151795864105\n",
      "episode: 7435/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 28.453125059604645\n",
      "episode: 7436/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 54.89062523841858\n",
      "episode: 7437/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 66.35810965299606\n",
      "episode: 7438/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 53.80598330497742\n",
      "episode: 7439/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 79.80680495500565\n",
      "episode: 7440/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 19.126900672912598\n",
      "episode: 7441/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 39.911746978759766\n",
      "episode: 7442/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 147.3280878663063\n",
      "episode: 7443/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 88.38798362016678\n",
      "episode: 7444/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 20.271165788173676\n",
      "episode: 7445/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 74.77244299650192\n",
      "episode: 7446/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 8.552016496658325\n",
      "episode: 7447/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 204.2304921746254\n",
      "episode: 7448/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 600.7061473727226\n",
      "episode: 7449/8000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 19.13281750679016\n",
      "episode: 7450/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 21.917211294174194\n",
      "episode: 7451/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 6.503963887691498\n",
      "episode: 7452/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 7.652370452880859\n",
      "episode: 7453/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 69.8136357665062\n",
      "episode: 7454/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 79.51297497749329\n",
      "episode: 7455/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 182.66944074630737\n",
      "episode: 7456/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 107.83639031648636\n",
      "episode: 7457/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 29.117190301418304\n",
      "episode: 7458/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 102.90344017744064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7459/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 107.63793981075287\n",
      "episode: 7460/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 2.7954578399658203e-05\n",
      "episode: 7461/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 29.86272621154785\n",
      "episode: 7462/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 46.81237840652466\n",
      "episode: 7463/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 21.916015625\n",
      "episode: 7464/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 11.111365914344788\n",
      "episode: 7465/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 12.628906786441803\n",
      "episode: 7466/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 72.30655241012573\n",
      "episode: 7467/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 73.89491987228394\n",
      "episode: 7468/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 49.43497836589813\n",
      "episode: 7469/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 182.15203392505646\n",
      "episode: 7470/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 250.32598847150803\n",
      "episode: 7471/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 10.06134033203125\n",
      "episode: 7472/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 60.736970365047455\n",
      "episode: 7473/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 59.03112894296646\n",
      "episode: 7474/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 136.6899601817131\n",
      "episode: 7475/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7476/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 94.17195922136307\n",
      "episode: 7477/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 52.70052719116211\n",
      "episode: 7478/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 101.27275061607361\n",
      "episode: 7479/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 32.755921363830566\n",
      "episode: 7480/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 79.98336720466614\n",
      "episode: 7481/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 5.507469177246094e-05\n",
      "episode: 7482/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 214.54610127210617\n",
      "episode: 7483/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 39.84512996673584\n",
      "episode: 7484/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 39.97540283203125\n",
      "episode: 7485/8000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 155.12873303890228\n",
      "episode: 7486/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 39.843750953674316\n",
      "episode: 7487/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 103.63560622930527\n",
      "episode: 7488/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 70.52441734075546\n",
      "episode: 7489/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 100.04536563158035\n",
      "episode: 7490/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 195.84716129302979\n",
      "episode: 7491/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 92.62590777873993\n",
      "episode: 7492/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 136.26409685611725\n",
      "episode: 7493/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 99.98632860183716\n",
      "episode: 7494/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 75.07839131355286\n",
      "episode: 7495/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 37.57421934604645\n",
      "episode: 7496/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 39.88473892211914\n",
      "episode: 7497/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 182.19182151556015\n",
      "episode: 7498/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 125.29098308086395\n",
      "episode: 7499/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 8.757135212421417\n",
      "episode: 7500/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7501/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 19.92187511920929\n",
      "episode: 7502/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 109.5018857717514\n",
      "episode: 7503/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 241.52574521303177\n",
      "episode: 7504/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 62.95202451944351\n",
      "episode: 7505/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7506/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 49.50804114341736\n",
      "episode: 7507/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 39.16290283203125\n",
      "episode: 7508/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 222.0758377313614\n",
      "episode: 7509/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 48.67261612415314\n",
      "episode: 7510/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 73.56381368637085\n",
      "episode: 7511/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 43.10740661621094\n",
      "episode: 7512/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 6.104927599430084\n",
      "episode: 7513/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 55.35497295856476\n",
      "episode: 7514/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 91.17383474111557\n",
      "episode: 7515/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 60.435546875\n",
      "episode: 7516/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 77.20857864618301\n",
      "episode: 7517/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 66.09751904010773\n",
      "episode: 7518/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 19.95316106081009\n",
      "episode: 7519/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 38.11988151073456\n",
      "episode: 7520/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 21.097041070461273\n",
      "episode: 7521/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 63.94902515411377\n",
      "episode: 7522/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 31.948760986328125\n",
      "episode: 7523/8000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 35.58872598409653\n",
      "episode: 7524/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 11.43243408203125\n",
      "episode: 7525/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 59.85321497917175\n",
      "episode: 7526/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 18.421875\n",
      "episode: 7527/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 68.09314632415771\n",
      "episode: 7528/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 29.907442092895508\n",
      "episode: 7529/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.462929666042328\n",
      "episode: 7530/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 21.223742306232452\n",
      "episode: 7531/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 72.65349566936493\n",
      "episode: 7532/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7533/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 18.560546875\n",
      "episode: 7534/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7535/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 57.68947321176529\n",
      "episode: 7536/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 32.712893068790436\n",
      "episode: 7537/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 81.73679196834564\n",
      "episode: 7538/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 68.69262635707855\n",
      "episode: 7539/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 95.64456629753113\n",
      "episode: 7540/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 143.5785300731659\n",
      "episode: 7541/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 177.60715860128403\n",
      "episode: 7542/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 28.45312625169754\n",
      "episode: 7543/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 216.43935364484787\n",
      "episode: 7544/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7545/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 86.97499084472656\n",
      "episode: 7546/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 111.32748305797577\n",
      "episode: 7547/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 104.84883463382721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7548/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 163.7095228433609\n",
      "episode: 7549/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 158.46621704101562\n",
      "episode: 7550/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 8.494901597499847\n",
      "episode: 7551/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 66.26762688159943\n",
      "episode: 7552/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 3.4206718802452087\n",
      "episode: 7553/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 223.82078981399536\n",
      "episode: 7554/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.978452682495117\n",
      "episode: 7555/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 39.949499905109406\n",
      "episode: 7556/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 92.41620707511902\n",
      "episode: 7557/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 60.77833819389343\n",
      "episode: 7558/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 917.316162109375\n",
      "episode: 7559/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 38.352349281311035\n",
      "episode: 7560/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 21.0625\n",
      "episode: 7561/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 19.703125\n",
      "episode: 7562/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 144.81646996736526\n",
      "episode: 7563/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 81.27987813949585\n",
      "episode: 7564/8000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.43766176700592\n",
      "episode: 7565/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 52.126953125\n",
      "episode: 7566/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 54.35804891586304\n",
      "episode: 7567/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 29.272104501724243\n",
      "episode: 7568/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 72.18248015642166\n",
      "episode: 7569/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 28.8828125\n",
      "episode: 7570/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 110.02094459533691\n",
      "episode: 7571/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 83.42586123943329\n",
      "episode: 7572/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 9.976567268371582\n",
      "episode: 7573/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 59.89382117986679\n",
      "episode: 7574/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 72.40111601352692\n",
      "episode: 7575/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 145.52322763204575\n",
      "episode: 7576/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 180.17570304870605\n",
      "episode: 7577/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 108.9140625\n",
      "episode: 7578/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 28.67236328125\n",
      "episode: 7579/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 20.572753965854645\n",
      "episode: 7580/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 49.09320068359375\n",
      "episode: 7581/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 928.2463989257812\n",
      "episode: 7582/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 74.53991705179214\n",
      "episode: 7583/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 31.89355480670929\n",
      "episode: 7584/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 14.277383625507355\n",
      "episode: 7585/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.00019782781600952148\n",
      "episode: 7586/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 182.25642651319504\n",
      "episode: 7587/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 142.8402931690216\n",
      "episode: 7588/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 70.06264907121658\n",
      "episode: 7589/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 59.343752920627594\n",
      "episode: 7590/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 111.91050231456757\n",
      "episode: 7591/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 152.8103011250496\n",
      "episode: 7592/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 190.14846688508987\n",
      "episode: 7593/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 112.66358977556229\n",
      "episode: 7594/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 7.984375\n",
      "episode: 7595/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 19.9453125\n",
      "episode: 7596/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 52.66649007797241\n",
      "episode: 7597/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 19.953167259693146\n",
      "episode: 7598/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7599/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7600/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 93.46983027458191\n",
      "episode: 7601/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 42.79851710796356\n",
      "episode: 7602/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7603/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 100.43098449707031\n",
      "episode: 7604/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 70.94805908203125\n",
      "episode: 7605/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0006048679351806641\n",
      "episode: 7606/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 213.63262712955475\n",
      "episode: 7607/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 107.33208698034286\n",
      "episode: 7608/8000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 2.599909722805023\n",
      "episode: 7609/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 170.52233856916428\n",
      "episode: 7610/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.00011754035949707031\n",
      "episode: 7611/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 70.0865707397461\n",
      "episode: 7612/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 19.923783481121063\n",
      "episode: 7613/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 8.334139883518219\n",
      "episode: 7614/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 227.7069934606552\n",
      "episode: 7615/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 115.3999018073082\n",
      "episode: 7616/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 1656.8170253634453\n",
      "episode: 7617/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 79.78407299518585\n",
      "episode: 7618/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 70.05788624286652\n",
      "episode: 7619/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7620/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 18.96875035762787\n",
      "episode: 7621/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 88.02463817596436\n",
      "episode: 7622/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 107.73931515216827\n",
      "episode: 7623/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 10.139404296875\n",
      "episode: 7624/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 201.64177083969116\n",
      "episode: 7625/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 86.84989476203918\n",
      "episode: 7626/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 41.04657655954361\n",
      "episode: 7627/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 52.65824592113495\n",
      "episode: 7628/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 90.84464764595032\n",
      "episode: 7629/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 62.91603833436966\n",
      "episode: 7630/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 20.423112869262695\n",
      "episode: 7631/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 16.7578125\n",
      "episode: 7632/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 156.5030927658081\n",
      "episode: 7633/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 248.4791797399521\n",
      "episode: 7634/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 302.63536167144775\n",
      "episode: 7635/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 178.81028360128403\n",
      "episode: 7636/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 30.01534903049469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7637/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 39.94777202606201\n",
      "episode: 7638/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 59.56681311130524\n",
      "episode: 7639/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 81.01023834943771\n",
      "episode: 7640/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 81.27980160713196\n",
      "episode: 7641/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 51.17383807897568\n",
      "episode: 7642/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 36.9530765414238\n",
      "episode: 7643/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 56.99516075849533\n",
      "episode: 7644/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 51.74024713039398\n",
      "episode: 7645/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.015421807765960693\n",
      "episode: 7646/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 22.738281846046448\n",
      "episode: 7647/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 166.15137261152267\n",
      "episode: 7648/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 75.65161138772964\n",
      "episode: 7649/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 59.40478515625\n",
      "episode: 7650/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 94.70065307617188\n",
      "episode: 7651/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 58.39929389953613\n",
      "episode: 7652/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 151.321852684021\n",
      "episode: 7653/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 208.50718235969543\n",
      "episode: 7654/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7655/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7656/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 111.91604441404343\n",
      "episode: 7657/8000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4.649162292480469e-05\n",
      "episode: 7658/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 91.94543570280075\n",
      "episode: 7659/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 223.62815696001053\n",
      "episode: 7660/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 188.45379877090454\n",
      "episode: 7661/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 186.70718717575073\n",
      "episode: 7662/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.433750331401825\n",
      "episode: 7663/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 218.11806923151016\n",
      "episode: 7664/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 37.14108520746231\n",
      "episode: 7665/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4.8399658203125\n",
      "episode: 7666/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.63592529296875\n",
      "episode: 7667/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 1457.568712234497\n",
      "episode: 7668/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 33.86344391107559\n",
      "episode: 7669/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 81.93041425943375\n",
      "episode: 7670/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 2076.106689810753\n",
      "episode: 7671/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 34.04640293121338\n",
      "episode: 7672/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 59.57363271713257\n",
      "episode: 7673/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.51649010181427\n",
      "episode: 7674/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 76.01393169164658\n",
      "episode: 7675/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 160.1465390920639\n",
      "episode: 7676/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.864081382751465\n",
      "episode: 7677/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 111.73950630426407\n",
      "episode: 7678/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 107.39279496669769\n",
      "episode: 7679/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 44.857095301151276\n",
      "episode: 7680/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 82.8848123550415\n",
      "episode: 7681/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 265.8988810181618\n",
      "episode: 7682/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 16.247305929660797\n",
      "episode: 7683/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 38.778778076171875\n",
      "episode: 7684/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 117.52290815114975\n",
      "episode: 7685/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 84.37106513977051\n",
      "episode: 7686/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7687/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 43.91607677936554\n",
      "episode: 7688/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 13.539876520633698\n",
      "episode: 7689/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.953306794166565\n",
      "episode: 7690/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 75.59241485595703\n",
      "episode: 7691/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 92.63438034057617\n",
      "episode: 7692/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 104.64377880096436\n",
      "episode: 7693/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.5841201543808\n",
      "episode: 7694/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.16290283203125\n",
      "episode: 7695/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.50080966949463\n",
      "episode: 7696/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.28507912158966\n",
      "episode: 7697/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.9805400967597961\n",
      "episode: 7698/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.937525629997253\n",
      "episode: 7699/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 99.85040295124054\n",
      "episode: 7700/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 269.07735192775726\n",
      "episode: 7701/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.13776785135269\n",
      "episode: 7702/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 137.7087543606758\n",
      "episode: 7703/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 22.693359375\n",
      "episode: 7704/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.931937336921692\n",
      "episode: 7705/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 210.08839559555054\n",
      "episode: 7706/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 61.88564682006836\n",
      "episode: 7707/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 21.3779296875\n",
      "episode: 7708/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 114.08943551778793\n",
      "episode: 7709/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 109.94947475194931\n",
      "episode: 7710/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.42124938964844\n",
      "episode: 7711/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.56423109769821\n",
      "episode: 7712/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 21.61328160762787\n",
      "episode: 7713/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.484375357627869\n",
      "episode: 7714/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 32.3916392326355\n",
      "episode: 7715/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.87689983844757\n",
      "episode: 7716/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 108.63440907001495\n",
      "episode: 7717/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 40.184990882873535\n",
      "episode: 7718/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 7719/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 7720/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 25.1797935962677\n",
      "episode: 7721/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.953125\n",
      "episode: 7722/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 222.36464846134186\n",
      "episode: 7723/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 78.36010485887527\n",
      "episode: 7724/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 42.67970544099808\n",
      "episode: 7725/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.194834232330322\n",
      "episode: 7726/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 54.61166286468506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7727/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 215.81419664621353\n",
      "episode: 7728/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.250150680541992\n",
      "episode: 7729/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 166.18581384420395\n",
      "episode: 7730/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 71.57582473754883\n",
      "episode: 7731/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 116.7025163769722\n",
      "episode: 7732/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 50.15966796875\n",
      "episode: 7733/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.965443670749664\n",
      "episode: 7734/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 172.2417002916336\n",
      "episode: 7735/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7736/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.45123291015625\n",
      "episode: 7737/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 2.53564453125\n",
      "episode: 7738/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.953359961509705\n",
      "episode: 7739/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 25.6401064991951\n",
      "episode: 7740/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.90856111049652\n",
      "episode: 7741/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.48309326171875\n",
      "episode: 7742/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 42.81768035888672\n",
      "episode: 7743/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.90629631280899\n",
      "episode: 7744/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 41.711879909038544\n",
      "episode: 7745/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 34.495577335357666\n",
      "episode: 7746/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 190.19046288728714\n",
      "episode: 7747/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.958984375\n",
      "episode: 7748/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 160.10489958524704\n",
      "episode: 7749/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.95312637090683\n",
      "episode: 7750/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.08298987150192261\n",
      "episode: 7751/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 111.99374639987946\n",
      "episode: 7752/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.494141578674316\n",
      "episode: 7753/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 58.4453547000885\n",
      "episode: 7754/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.959716796875\n",
      "episode: 7755/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 461.333099424839\n",
      "episode: 7756/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.990512251853943\n",
      "episode: 7757/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 244.08471542596817\n",
      "episode: 7758/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 37.92968785762787\n",
      "episode: 7759/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 194.54044890403748\n",
      "episode: 7760/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.24701422452927\n",
      "episode: 7761/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.31787109375\n",
      "episode: 7762/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 104.73337310552597\n",
      "episode: 7763/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7764/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 107.0144664645195\n",
      "episode: 7765/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 74.96092331409454\n",
      "episode: 7766/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.3028993010521\n",
      "episode: 7767/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 161.81015175580978\n",
      "episode: 7768/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.46005177497864\n",
      "episode: 7769/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 144.91500306129456\n",
      "episode: 7770/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 117.58913516998291\n",
      "episode: 7771/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 89.03376388549805\n",
      "episode: 7772/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 94.34593403339386\n",
      "episode: 7773/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 46.954625606536865\n",
      "episode: 7774/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 24.668186843395233\n",
      "episode: 7775/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.54701763391495\n",
      "episode: 7776/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 120.2795998454094\n",
      "episode: 7777/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 50.364927649497986\n",
      "episode: 7778/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 197.92150402069092\n",
      "episode: 7779/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 125.37127685546875\n",
      "episode: 7780/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.0342265367508\n",
      "episode: 7781/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 90.40409046411514\n",
      "episode: 7782/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.95339298248291\n",
      "episode: 7783/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 70.8480042219162\n",
      "episode: 7784/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 91.86803871393204\n",
      "episode: 7785/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.390661120414734\n",
      "episode: 7786/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.54688060283661\n",
      "episode: 7787/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.93762242794037\n",
      "episode: 7788/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.978119850158691\n",
      "episode: 7789/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 152.62703055143356\n",
      "episode: 7790/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 70.94960236549377\n",
      "episode: 7791/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 129.25295799970627\n",
      "episode: 7792/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.6875\n",
      "episode: 7793/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.201717674732208\n",
      "episode: 7794/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.195313930511475\n",
      "episode: 7795/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 38.55609142780304\n",
      "episode: 7796/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 49.2421875\n",
      "episode: 7797/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7798/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7799/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7800/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 74.65070307254791\n",
      "episode: 7801/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 52.73748779296875\n",
      "episode: 7802/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7803/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 15.378932774066925\n",
      "episode: 7804/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 101.77212715148926\n",
      "episode: 7805/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 101.22984313964844\n",
      "episode: 7806/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 718.0374889373779\n",
      "episode: 7807/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.0699713230133\n",
      "episode: 7808/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 214.54877483844757\n",
      "episode: 7809/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.2828369140625\n",
      "episode: 7810/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 136.92815971374512\n",
      "episode: 7811/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7812/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 218.97473776340485\n",
      "episode: 7813/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 23.61328125\n",
      "episode: 7814/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.00015676021575927734\n",
      "episode: 7815/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.976604402065277\n",
      "episode: 7816/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 168.18782544136047\n",
      "episode: 7817/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.6581506729126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7818/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 54.74803304672241\n",
      "episode: 7819/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 232.3127965927124\n",
      "episode: 7820/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 191.54794669151306\n",
      "episode: 7821/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 108.13376814126968\n",
      "episode: 7822/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 50.05180025100708\n",
      "episode: 7823/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.17642211914062\n",
      "episode: 7824/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 86.54581815004349\n",
      "episode: 7825/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 72.27640056610107\n",
      "episode: 7826/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 102.53945744037628\n",
      "episode: 7827/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 148.50183022022247\n",
      "episode: 7828/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.55079305171967\n",
      "episode: 7829/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.954916954040527\n",
      "episode: 7830/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.117323517799377\n",
      "episode: 7831/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 191.94174867868423\n",
      "episode: 7832/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0006653070449829102\n",
      "episode: 7833/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 153.3905121088028\n",
      "episode: 7834/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.953248143196106\n",
      "episode: 7835/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 164.61379396915436\n",
      "episode: 7836/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.81452757120132\n",
      "episode: 7837/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 59.540462017059326\n",
      "episode: 7838/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 61.18174362182617\n",
      "episode: 7839/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 72.49314975738525\n",
      "episode: 7840/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 86.66796875\n",
      "episode: 7841/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 279.74475955963135\n",
      "episode: 7842/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 222.61558145284653\n",
      "episode: 7843/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 143.577346265316\n",
      "episode: 7844/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 149.0955886244774\n",
      "episode: 7845/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 27.76068687438965\n",
      "episode: 7846/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 182.59637761116028\n",
      "episode: 7847/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 54.44531315565109\n",
      "episode: 7848/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.87327188253403\n",
      "episode: 7849/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.93328756093979\n",
      "episode: 7850/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.40095615386963\n",
      "episode: 7851/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 69.83596706390381\n",
      "episode: 7852/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 95.47202777862549\n",
      "episode: 7853/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 228.88443726301193\n",
      "episode: 7854/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 208.05834060907364\n",
      "episode: 7855/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 81.08193743228912\n",
      "episode: 7856/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 131.1417902112007\n",
      "episode: 7857/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 115.61920213699341\n",
      "episode: 7858/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 53.942315101623535\n",
      "episode: 7859/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.57119750976562\n",
      "episode: 7860/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 486.9698917269707\n",
      "episode: 7861/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 77.01669520139694\n",
      "episode: 7862/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.981700897216797\n",
      "episode: 7863/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 30.390207290649414\n",
      "episode: 7864/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 124.46933913230896\n",
      "episode: 7865/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 41.872069358825684\n",
      "episode: 7866/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 110.02008247375488\n",
      "episode: 7867/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.00017178058624267578\n",
      "episode: 7868/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.162662744522095\n",
      "episode: 7869/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 162.63186198472977\n",
      "episode: 7870/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 53.623255491256714\n",
      "episode: 7871/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 101.16096591949463\n",
      "episode: 7872/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.95492935180664\n",
      "episode: 7873/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 51.809624671936035\n",
      "episode: 7874/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 155.82974642515182\n",
      "episode: 7875/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 40.57421964406967\n",
      "episode: 7876/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0019857287406921387\n",
      "episode: 7877/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 221.8362038731575\n",
      "episode: 7878/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 60.37710529565811\n",
      "episode: 7879/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 59.47275352478027\n",
      "episode: 7880/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 105.50859326124191\n",
      "episode: 7881/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 129.50886964797974\n",
      "episode: 7882/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7883/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 208.24270522594452\n",
      "episode: 7884/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 32.783192574977875\n",
      "episode: 7885/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 3606.277961730957\n",
      "episode: 7886/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 223.86255198717117\n",
      "episode: 7887/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 7888/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 77.43803453445435\n",
      "episode: 7889/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 71.11870992183685\n",
      "episode: 7890/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.103463172912598\n",
      "episode: 7891/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 75.68768405914307\n",
      "episode: 7892/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.73427939414978\n",
      "episode: 7893/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 70.49638420343399\n",
      "episode: 7894/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 7895/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 16.031255424022675\n",
      "episode: 7896/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 7.354248046875\n",
      "episode: 7897/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 26.36885553598404\n",
      "episode: 7898/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 32.910361528396606\n",
      "episode: 7899/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.232948303222656\n",
      "episode: 7900/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 89.26690673828125\n",
      "episode: 7901/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 53.93896484375\n",
      "episode: 7902/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 7903/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 169.1342698931694\n",
      "episode: 7904/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 11.854304432868958\n",
      "episode: 7905/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 91.82181239128113\n",
      "episode: 7906/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.08198857307434082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7907/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 57.447742104530334\n",
      "episode: 7908/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.57635498046875\n",
      "episode: 7909/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 5.645176589488983\n",
      "episode: 7910/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.728145241737366\n",
      "episode: 7911/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.57567071914673\n",
      "episode: 7912/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 105.34301710128784\n",
      "episode: 7913/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 75.40860003232956\n",
      "episode: 7914/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7915/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 33.938446044921875\n",
      "episode: 7916/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 115.39856499433517\n",
      "episode: 7917/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 7918/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.92686641216278\n",
      "episode: 7919/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.467482805252075\n",
      "episode: 7920/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 90.89570140838623\n",
      "episode: 7921/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.95431423187256\n",
      "episode: 7922/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.843886613845825\n",
      "episode: 7923/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 22.76013195514679\n",
      "episode: 7924/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 54.54978883266449\n",
      "episode: 7925/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7926/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 49.42546182870865\n",
      "episode: 7927/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.6640664935112\n",
      "episode: 7928/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 74.70840173959732\n",
      "episode: 7929/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 48.75515127182007\n",
      "episode: 7930/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 34.08380126953125\n",
      "episode: 7931/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 35.18963623046875\n",
      "episode: 7932/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.96361541748047\n",
      "episode: 7933/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7934/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 216.43225824832916\n",
      "episode: 7935/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 197.40322530269623\n",
      "episode: 7936/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 7937/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 7938/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 59.22054445743561\n",
      "episode: 7939/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7940/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 56.90012228488922\n",
      "episode: 7941/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 201.36356449127197\n",
      "episode: 7942/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.731394350528717\n",
      "episode: 7943/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7944/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 68.78159999847412\n",
      "episode: 7945/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 225.24697679281235\n",
      "episode: 7946/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 224.40814197063446\n",
      "episode: 7947/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 126.98977106809616\n",
      "episode: 7948/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 102.73917186260223\n",
      "episode: 7949/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.38678753376007\n",
      "episode: 7950/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 98.87112891674042\n",
      "episode: 7951/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.8872074484825134\n",
      "episode: 7952/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 98.62566888332367\n",
      "episode: 7953/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.828125\n",
      "episode: 7954/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7955/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7956/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.023438274860382\n",
      "episode: 7957/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 246.67586302757263\n",
      "episode: 7958/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 81.6289090514183\n",
      "episode: 7959/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 32.72281736135483\n",
      "episode: 7960/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.976604759693146\n",
      "episode: 7961/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 84.99396842718124\n",
      "episode: 7962/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 122.48708271980286\n",
      "episode: 7963/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.51579010486603\n",
      "episode: 7964/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.614632368087769\n",
      "episode: 7965/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.484375357627869\n",
      "episode: 7966/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 7967/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.031250953674316\n",
      "episode: 7968/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 12.857421875\n",
      "episode: 7969/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.632110595703125e-05\n",
      "episode: 7970/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 31.928711116313934\n",
      "episode: 7971/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 96.40677261352539\n",
      "episode: 7972/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 2.783326506614685\n",
      "episode: 7973/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 97.62339073419571\n",
      "episode: 7974/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 61.241875410079956\n",
      "episode: 7975/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7976/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.437657177448273\n",
      "episode: 7977/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.976565301418304\n",
      "episode: 7978/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.97848129272461\n",
      "episode: 7979/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 132.5270619392395\n",
      "episode: 7980/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 7.632988154888153\n",
      "episode: 7981/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 89.70434355735779\n",
      "episode: 7982/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 56.562526524066925\n",
      "episode: 7983/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 1.025390625\n",
      "episode: 7984/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.984458863735199\n",
      "episode: 7985/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7986/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 30.27099609375\n",
      "episode: 7987/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 72.63401544094086\n",
      "episode: 7988/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.140898764133453\n",
      "episode: 7989/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 7990/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 76.75528013706207\n",
      "episode: 7991/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.955048084259033\n",
      "episode: 7992/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.95315146446228\n",
      "episode: 7993/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 69.70934081077576\n",
      "episode: 7994/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 23.880886018276215\n",
      "episode: 7995/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.10949957370758\n",
      "episode: 7996/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 221.43207603693008\n",
      "episode: 7997/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.906256437301636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7998/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.65849632024765\n",
      "episode: 7999/8000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 49.801478028297424\n",
      "Finished in 46730.355 second(s)\n"
     ]
    }
   ],
   "source": [
    "exploration_rate, t2, accumulated_rewards = csrl.train_DQN(EPISODES=8000,num_steps=500) #8000, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e61105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "        \n",
    "ax1.set_xlabel('episode(s)') \n",
    "ax1.set_ylabel('epsilon', color = 'red') \n",
    "ax1.plot(t2, exploration_rate, color = 'red') \n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "# Adding Twin Axes\n",
    "ax2 = ax1.twinx() \n",
    "ax2.set_ylabel('accumulated rewards/100 episodes', color = 'blue') \n",
    "ax2.plot(t2, accumulated_rewards, color = 'blue') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue') \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62dbad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START STATE: (0, 0, 6, 3)\n",
      "(0, 0, 6, 3)\n",
      "state: (0, 0, 6, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 3)\n",
      "state: (0, 0, 7, 3)\n",
      "action selected: 3\n",
      "reward: 0.0019200871902449804\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 3\n",
      "reward: 7.240692982834674e-05\n",
      "(0, 0, 7, 1)\n",
      "state: (0, 0, 7, 1)\n",
      "action selected: 1\n",
      "reward: 9.979695112982972\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 0, 2)\n",
      "state: (0, 1, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 3)\n",
      "state: (0, 1, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 4)\n",
      "state: (0, 1, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 5)\n",
      "state: (0, 1, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 6)\n",
      "state: (0, 1, 0, 6)\n",
      "action selected: 2\n",
      "reward: 3.979312117660319e-12\n",
      "(0, 1, 0, 7)\n",
      "state: (0, 1, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.979168751707526\n",
      "(0, 1, 0, 8)\n",
      "state: (0, 1, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00015045410774047445\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.9995450979408\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 5)\n",
      "state: (0, 1, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 6)\n",
      "state: (0, 1, 2, 6)\n",
      "action selected: 2\n",
      "reward: 0.00047295337874005426\n",
      "(0, 1, 2, 7)\n",
      "state: (0, 1, 2, 7)\n",
      "action selected: 2\n",
      "reward: 1.0547861164611725e-05\n",
      "(0, 1, 2, 8)\n",
      "state: (0, 1, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.976868550669517\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 9.437410828643126\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 0\n",
      "reward: 1.903160444420527\n",
      "(0, 0, 8, 2)\n",
      "state: (0, 0, 8, 2)\n",
      "action selected: 3\n",
      "reward: 9.97471687118367\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 2)\n",
      "state: (0, 1, 2, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 2.1246839312425123e-30\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.11027519527910884\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.00013612656996454816\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.11027754214312135\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.00013623915034376993\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.10468016883509794\n",
      "accumulated_rewards_per_episode: 61.578697378997475\n",
      "START STATE: (0, 0, 9, 2)\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 1\n",
      "reward: 0.27693995064436516\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.974033544635246\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 2)\n",
      "state: (0, 1, 2, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 6.350415307876991e-31\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.13510362462429037\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.10808289969943233\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.1351036246242904\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.1350956899575146\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493356595121422\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.1349995227085845\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218385134867\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576873135\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218346764582\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576139808\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218346753733\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576139702\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218346753735\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576139705\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218346753733\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.03859819541779421\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.13510362462429046\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13503371856872928\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493274858459048\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.038601327624561074\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.13510362462429049\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13503740766132025\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493276766007856\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.13499951160727064\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349321836998774\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576660033\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218346761704\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.03859819541798383\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.1351036246242905\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13503740032284078\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493276756063313\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499951160589171\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218369985863\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576660008\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.134932183467617\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576139774\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218346753738\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576139705\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218346753735\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576139705\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1351036246242905\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 0\n",
      "reward: 0.1351036246242905\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13510274947659928\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.027026133604039992\n",
      "(0, 2, 2, 9)\n",
      "state: (0, 2, 2, 9)\n",
      "action selected: 0\n",
      "reward: 0.13483827589388012\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13491737204113352\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499922593847896\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.12396086160294938\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13050832893845957\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0382527732982489\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.001149670976811336\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.1348296577423647\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499444001652813\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493219367916423\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950737154762\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1349321834738922\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.1349995057609813\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349321834675366\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1349995057613973\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13510362462429065\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 0\n",
      "reward: 0.1351036246242907\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13510274971513317\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493351975751125\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499952118953537\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349321838255548\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.03859819691390797\n",
      "(0, 2, 2, 8)\n",
      "state: (0, 2, 2, 8)\n",
      "action selected: 0\n",
      "reward: 0.027498885741829703\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0007511631887528535\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.13482958448170232\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499443808476766\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349321936105685\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950737650282\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218347362285\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576097286\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493218346753655\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499950576139727\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218346753746\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.1349995057613972\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1238549886460772\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499979687336866\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13492625259125277\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499937350713204\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493218165632914\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499950576200515\n",
      "accumulated_rewards_per_episode: 20.57042459776704\n",
      "START STATE: (0, 0, 9, 8)\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 2.671463321807573e-11\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.153873782374111\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 5.543578388317489e-34\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.944772001830044\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010656516776599624\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 2.7750637852010094\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.945683217436573\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.511538271981039e-28\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.9447658298931\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 7)\n",
      "state: (0, 0, 7, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 7)\n",
      "state: (0, 2, 6, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 6)\n",
      "state: (0, 2, 6, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 5)\n",
      "state: (0, 2, 6, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 4)\n",
      "state: (0, 2, 6, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 7, 3)\n",
      "state: (0, 2, 7, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 2)\n",
      "state: (0, 2, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 5, 2)\n",
      "state: (0, 2, 5, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 2)\n",
      "state: (0, 2, 4, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 5, 2)\n",
      "state: (0, 2, 5, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 2)\n",
      "state: (0, 2, 4, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 5, 2)\n",
      "state: (0, 2, 5, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 1)\n",
      "state: (0, 2, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 1)\n",
      "state: (0, 2, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 1)\n",
      "state: (0, 2, 3, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 3, 1)\n",
      "state: (0, 2, 3, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 0)\n",
      "state: (0, 2, 2, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 1)\n",
      "state: (0, 2, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 1)\n",
      "state: (0, 2, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 41.76426518192932\n",
      "START STATE: (0, 0, 8, 5)\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 4.2832002068609775e-05\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.950359871725293\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 6)\n",
      "state: (0, 1, 0, 6)\n",
      "action selected: 2\n",
      "reward: 1.9073145067919026\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.02424809535772161\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.922887702343393\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010662034340037331\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.949921044624679\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 2)\n",
      "state: (0, 1, 3, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 1)\n",
      "state: (0, 2, 3, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 0)\n",
      "state: (0, 2, 2, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 1)\n",
      "state: (0, 2, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 2)\n",
      "state: (0, 2, 2, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 3)\n",
      "state: (0, 2, 2, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 4)\n",
      "state: (0, 2, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 5)\n",
      "state: (0, 2, 2, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 6)\n",
      "state: (0, 2, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 1.2454779735357755e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 5.8012423178222743e-11\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 2.8391396796216356e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4965383632638882e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4668310772058123e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661752209029603e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.466160742069238e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661604224317966e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661604153754261e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661604152196486e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661604152162096e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661604152161335e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 5.939530552501716e-11\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 2.8747643818821353e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 8.418822942018668e-10\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 1.1624230044995097e-09\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 4.5053530089749356e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.5337138102726941e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4676586083039884e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661936485297027e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 1.0996223563267638e-09\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 9.63964973030244e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.6483495667113636e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 8.375807654087061e-10\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 1.1642979549214363e-09\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 3\n",
      "reward: 1.1640303647749136e-09\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 2.4039343545694377e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.487088851532813e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4666258956761174e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4661707755550112e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4275720811254026e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.4652050025187386e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 8.369287799036065e-10\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 1.1624153039599017e-09\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 4.465561544552506e-12\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.5328294337883735e-12\n",
      "accumulated_rewards_per_episode: 31.754880681629988\n",
      "START STATE: (0, 0, 6, 2)\n",
      "(0, 0, 6, 2)\n",
      "state: (0, 0, 6, 2)\n",
      "action selected: 1\n",
      "reward: 0.12477718360071298\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 6, 2)\n",
      "state: (0, 0, 6, 2)\n",
      "action selected: 1\n",
      "reward: 0.02664030302810647\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0005995715201283266\n",
      "(0, 0, 7, 1)\n",
      "state: (0, 0, 7, 1)\n",
      "action selected: 1\n",
      "reward: 9.97969645054678\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 5.6878930474942685e-37\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.979150839624245\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 1.2431907493291073e-09\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 2.7836951545418867\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 2.898399827963845\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 3)\n",
      "state: (0, 1, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 9.627454987479138e-07\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.97555092145341\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.08592268287698235\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.975567511537003\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 4.798908843378775e-10\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.975538952916256\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 55.80554036407794\n",
      "START STATE: (0, 0, 7, 2)\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 1\n",
      "reward: 0.46911286576869476\n",
      "(0, 0, 8, 2)\n",
      "state: (0, 0, 8, 2)\n",
      "action selected: 3\n",
      "reward: 9.96100810500341\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 3)\n",
      "state: (0, 1, 2, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.3147277606719765e-08\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.13785277337127616\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0001701690601019632\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.13785570657369658\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13802307455005178\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13813469536163298\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13813469536162876\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.018882032136824135\n",
      "(0, 2, 2, 9)\n",
      "state: (0, 2, 2, 9)\n",
      "action selected: 0\n",
      "reward: 0.13786202713957796\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1381346953616384\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.13813469536163836\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.138115122753538\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13796067873670267\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1380245675347757\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594386899358\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202423067\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869865057\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1380245520219443\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594386989085\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13813458306906481\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.13813469536163844\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13810671255651136\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13796053370458733\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802456506891445\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943864933333\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202349243\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594386986388\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194416\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13085643323378995\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13792203742920672\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795802496453322\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802453282947505\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13775253850708483\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13802079829917163\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1268642580513014\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13813469536163858\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.13752983151744094\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13801860918964406\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1261718906380255\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.1380270679511805\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13795331449371326\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802810504832086\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594060359539\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455312722461\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13775254138631873\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13802079818963517\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13795938825815152\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802824227875427\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795940789566408\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1380245531696855\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594386746579\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202230338\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869889382\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1381346953616386\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0006807819855189898\n",
      "(0, 2, 2, 9)\n",
      "state: (0, 2, 2, 9)\n",
      "action selected: 0\n",
      "reward: 0.13785824906865593\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13796078639926637\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13813467790457756\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.13813469536163864\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13810670007056414\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13796053352657983\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1380245650650425\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943864927762\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202349134\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.1379594386986389\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194425\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890864\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890898\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890895\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890895\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890895\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13795943869890895\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13802455202194439\n",
      "accumulated_rewards_per_episode: 20.631464476224007\n",
      "START STATE: (0, 0, 6, 8)\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 3\n",
      "reward: 2.717091515003515e-12\n",
      "(0, 0, 8, 2)\n",
      "state: (0, 0, 8, 2)\n",
      "action selected: 3\n",
      "reward: 9.464025775588537\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.464025548470039\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 9)\n",
      "state: (0, 0, 9, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 8.9526899984295\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 2)\n",
      "state: (0, 1, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 2)\n",
      "state: (0, 1, 4, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 4)\n",
      "state: (0, 1, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 5)\n",
      "state: (0, 1, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 6)\n",
      "state: (0, 1, 0, 6)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.7739255636348469\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.9160378841758101\n",
      "(0, 1, 0, 7)\n",
      "state: (0, 1, 0, 7)\n",
      "action selected: 2\n",
      "reward: 2.6874002111771964\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.463174260339745\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 42.721279241818394\n",
      "START STATE: (0, 0, 5, 6)\n",
      "(0, 0, 5, 6)\n",
      "state: (0, 0, 5, 6)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 6)\n",
      "state: (0, 0, 6, 6)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 6, 7)\n",
      "state: (0, 2, 6, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 7, 7)\n",
      "state: (0, 2, 7, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 7)\n",
      "state: (0, 2, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 6)\n",
      "state: (0, 2, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 5)\n",
      "state: (0, 2, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 4)\n",
      "state: (0, 2, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 3)\n",
      "state: (0, 2, 8, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 2)\n",
      "state: (0, 2, 8, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 1)\n",
      "state: (0, 2, 8, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 8, 1)\n",
      "state: (0, 2, 8, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 9, 0)\n",
      "state: (0, 2, 9, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 0)\n",
      "state: (0, 2, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START STATE: (0, 0, 2, 9)\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 9)\n",
      "state: (0, 0, 9, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0004641624778288994\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.979566181951272\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 3)\n",
      "state: (0, 1, 2, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 4)\n",
      "state: (0, 2, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 5)\n",
      "state: (0, 2, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 2.925666781461127e-25\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019499727450566031\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4070979398887176e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.001950014957945787\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019499424795784473\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.40710456888183e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149425275659\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0015633577031325138\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.001951115471328471\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.001952457100693546\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.001816680893006895\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0019487697953670057\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.001951432898739375\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0015744970897081947\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.0019539571680661514\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.0019508866096699304\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0019514485460389902\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.496904629815975e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500157050198867\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409162791218362e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.001950014979154295\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090904082945878e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.001950014978736616\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903485573105e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787363798\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409090348507985e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787363794\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903485079433e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787363794\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903485079433e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787363794\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903485079433e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787363794\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903485079433e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.00039076325480283104\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 1.0631345340957444e-05\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019499979233785526\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.415907409226438e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149767716214\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409095980337086e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 2\n",
      "reward: 0.0019500149787367114\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.4090903531624084e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0018488754946585286\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.3981925840350184e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0018491948648330855\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.405580432382782e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019499826418160411\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409088285556103e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149690138094\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409090347005494e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019500149787335143\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 2.409090348506734e-06\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.001950014978736378\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0015633579170810155\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.00195396134760658\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0019537932302509577\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 4.034425048991e-06\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.00010265744864865465\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 4.787622788754384e-06\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 2.5121582626564313e-06\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 2.4616994642432618e-06\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0014045702839713195\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 0.0019508018393229066\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 7.494326001179e-06\n",
      "accumulated_rewards_per_episode: 10.048790815129994\n",
      "START STATE: (0, 0, 6, 4)\n",
      "(0, 0, 6, 4)\n",
      "state: (0, 0, 6, 4)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 4)\n",
      "state: (0, 0, 7, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 3)\n",
      "state: (0, 0, 7, 3)\n",
      "action selected: 3\n",
      "reward: 2.6701638960575863e-05\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 3\n",
      "reward: 1.0261700032712063e-06\n",
      "(0, 0, 7, 1)\n",
      "state: (0, 0, 7, 1)\n",
      "action selected: 1\n",
      "reward: 9.979697642352766\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 0)\n",
      "state: (0, 1, 0, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 1)\n",
      "state: (0, 1, 0, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 2)\n",
      "state: (0, 1, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 3)\n",
      "state: (0, 1, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 4)\n",
      "state: (0, 1, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 5)\n",
      "state: (0, 1, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.95988162767767\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010693827437776527\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.979590693228333\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 2)\n",
      "state: (0, 1, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 2)\n",
      "state: (0, 1, 2, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 6)\n",
      "state: (0, 2, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 2.8700414212237538e-06\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 0.13482751288205796\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349331233375672\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13509890152093806\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.1351031830312649\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13507635345776767\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493285122143145\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499908248604048\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349317427593598\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499906451470042\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493174243496459\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499906450869043\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493174243487588\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1349990645086893\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.12798748035749302\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13489526576152763\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493039091712486\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.1349990463896657\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.1349317421821616\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13080255166945595\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 2\n",
      "reward: 0.13483384273284088\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493285376791672\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499915501008178\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493174321854057\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499906450368643\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.134931742435027\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499906450869525\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.1349317424348759\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.13499906450868923\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493174243487582\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499906450868923\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493174243487577\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.1350989389371388\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.1351031830312649\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.13507635352308023\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.13493285122271417\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.13499908248604828\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.13493174275936\n",
      "accumulated_rewards_per_episode: 34.90218038021771\n",
      "START STATE: (0, 0, 8, 7)\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 7)\n",
      "state: (0, 0, 7, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 7)\n",
      "state: (0, 2, 6, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 6)\n",
      "state: (0, 2, 6, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 5)\n",
      "state: (0, 2, 6, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 4)\n",
      "state: (0, 2, 6, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 2)\n",
      "state: (0, 2, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 1)\n",
      "state: (0, 2, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 1)\n",
      "state: (0, 2, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 1)\n",
      "state: (0, 2, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 1)\n",
      "state: (0, 2, 3, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 0)\n",
      "state: (0, 2, 2, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 1)\n",
      "state: (0, 2, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 2)\n",
      "state: (0, 2, 2, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 2)\n",
      "state: (0, 2, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 3)\n",
      "state: (0, 2, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 4)\n",
      "state: (0, 2, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 5)\n",
      "state: (0, 2, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 2, 8)\n",
      "state: (0, 2, 2, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START STATE: (0, 0, 9, 0)\n",
      "(0, 0, 9, 0)\n",
      "state: (0, 0, 9, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 0)\n",
      "state: (0, 1, 9, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.5188454985044538e-24\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.979316338319741\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 7)\n",
      "state: (0, 0, 3, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 3.503524861254203e-08\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.978886064375438\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.6322160596288553e-36\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.978446183651924\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 7)\n",
      "state: (0, 0, 6, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 7, 7)\n",
      "state: (0, 2, 7, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 7, 6)\n",
      "state: (0, 2, 7, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 7, 5)\n",
      "state: (0, 2, 7, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 8, 5)\n",
      "state: (0, 2, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 8, 4)\n",
      "state: (0, 2, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 7, 4)\n",
      "state: (0, 2, 7, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 7, 3)\n",
      "state: (0, 2, 7, 3)\n",
      "action selected: 0\n",
      "reward: 1.2607328262916016e-11\n",
      "(0, 2, 7, 2)\n",
      "state: (0, 2, 7, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 2)\n",
      "state: (0, 2, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 1)\n",
      "state: (0, 2, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 1)\n",
      "state: (0, 2, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 1)\n",
      "state: (0, 2, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 1)\n",
      "state: (0, 2, 3, 1)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 0)\n",
      "state: (0, 2, 2, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 1)\n",
      "state: (0, 2, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 2)\n",
      "state: (0, 2, 2, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 3)\n",
      "state: (0, 2, 2, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 4)\n",
      "state: (0, 2, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 5)\n",
      "state: (0, 2, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 29.936648621394962\n",
      "START STATE: (0, 0, 2, 0)\n",
      "(0, 0, 2, 0)\n",
      "state: (0, 0, 2, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 0)\n",
      "state: (0, 0, 3, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 0)\n",
      "state: (0, 0, 4, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 0)\n",
      "state: (0, 0, 5, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 0)\n",
      "state: (0, 0, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 4, 0)\n",
      "state: (0, 0, 4, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 0)\n",
      "state: (0, 0, 5, 0)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 0)\n",
      "state: (0, 0, 6, 0)\n",
      "action selected: 1\n",
      "reward: 1.1086715287885457e-06\n",
      "(0, 0, 7, 0)\n",
      "state: (0, 0, 7, 0)\n",
      "action selected: 1\n",
      "reward: 9.157256791700698\n",
      "(0, 0, 8, 0)\n",
      "state: (0, 0, 8, 0)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 8, 0)\n",
      "state: (0, 1, 8, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 2)\n",
      "state: (0, 1, 2, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 3)\n",
      "state: (0, 2, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 4)\n",
      "state: (0, 2, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 3.8928269929462106e-17\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.042487485267297294\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 6)\n",
      "state: (0, 2, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 2.644114663844548e-05\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.2143996385680864\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0002646822581445568\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.21440411205437634\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.2073772526430045\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840503\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482831399572017\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584051\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986376881885\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840506\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409321667\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483435553632926\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.214838017458405\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.20793634927839824\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840492\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482632123282475\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840495\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.2148298623442936\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.214838017458405\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409242716\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483435553631172\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.214838017458405\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21483801745840503\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.214838017458405\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21479411798112374\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483357988795998\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.21468013426368596\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584051\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21483002535102114\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840514\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986416395158\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148378609026257\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.20841335929872998\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840522\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.2148266115535538\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148342845451329\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.21468016358126077\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584052\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21483801745840525\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.21483801745840522\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.15195271199806315\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 2\n",
      "reward: 0.21267381961499274\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840514\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482879085548678\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584052\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21483631923413904\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.2148380174584052\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21479581962478467\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840522\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482984716882916\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840522\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986408489668\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584052\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409328775\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840525\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409329186\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840528\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409329188\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584053\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409329194\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584053\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409329194\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584053\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482986409329194\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.2148380174584053\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21483801745840525\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.2128216216416099\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21477332131186344\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 2\n",
      "reward: 0.21483801745840533\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21479484872794785\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 0\n",
      "reward: 0.21483801745840525\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.21482984669355806\n",
      "accumulated_rewards_per_episode: 24.14928120044364\n",
      "START STATE: (0, 0, 7, 1)\n",
      "(0, 0, 7, 1)\n",
      "state: (0, 0, 7, 1)\n",
      "action selected: 1\n",
      "reward: 9.144903745709597\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 4.0343460337872607e-17\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.979584799164705\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 1\n",
      "reward: 6.852662477139049\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 3)\n",
      "state: (0, 1, 9, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 3)\n",
      "state: (0, 1, 8, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 3)\n",
      "state: (0, 1, 7, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 0, 1)\n",
      "state: (0, 1, 0, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 2)\n",
      "state: (0, 1, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 3)\n",
      "state: (0, 1, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 6)\n",
      "state: (0, 1, 2, 6)\n",
      "action selected: 2\n",
      "reward: 0.03360622880387911\n",
      "(0, 1, 2, 7)\n",
      "state: (0, 1, 2, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 3, 7)\n",
      "state: (0, 1, 3, 7)\n",
      "action selected: 0\n",
      "reward: 0.033560937200382765\n",
      "(0, 1, 2, 7)\n",
      "state: (0, 1, 2, 7)\n",
      "action selected: 2\n",
      "reward: 0.0007481270908094681\n",
      "(0, 1, 2, 8)\n",
      "state: (0, 1, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.978844905058677\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 4, 7)\n",
      "state: (0, 0, 4, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 5, 7)\n",
      "state: (0, 0, 5, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 7)\n",
      "state: (0, 0, 6, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 7)\n",
      "state: (0, 2, 5, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 5, 8)\n",
      "state: (0, 2, 5, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 5, 7)\n",
      "state: (0, 2, 5, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 5, 6)\n",
      "state: (0, 2, 5, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 6)\n",
      "state: (0, 2, 4, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 6)\n",
      "state: (0, 2, 3, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 7)\n",
      "state: (0, 2, 3, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 2, 9)\n",
      "state: (0, 2, 2, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 36.0239112201671\n",
      "START STATE: (0, 0, 7, 3)\n",
      "(0, 0, 7, 3)\n",
      "state: (0, 0, 7, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00040280524260612974\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.97959060839196\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 3.326598471218682e-21\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.979584640304518\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0001069382086528101\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 2.783820355277914\n",
      "(0, 0, 8, 2)\n",
      "state: (0, 0, 8, 2)\n",
      "action selected: 3\n",
      "reward: 9.980243930313161\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 2.0646369578021687e-31\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 7)\n",
      "state: (0, 1, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.96207383822167\n",
      "(0, 1, 0, 8)\n",
      "state: (0, 1, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010693342987870186\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 2.784653702824208\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.980052981144064\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 6)\n",
      "state: (0, 1, 2, 6)\n",
      "action selected: 2\n",
      "reward: 0.03360596787017613\n",
      "(0, 1, 2, 7)\n",
      "state: (0, 1, 2, 7)\n",
      "action selected: 2\n",
      "reward: 0.0007491704122316045\n",
      "(0, 1, 2, 8)\n",
      "state: (0, 1, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.978773476714029\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 65.46376534835507\n",
      "START STATE: (0, 0, 5, 6)\n",
      "(0, 0, 5, 6)\n",
      "state: (0, 0, 5, 6)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 6)\n",
      "state: (0, 0, 6, 6)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 7, 6)\n",
      "state: (0, 2, 7, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 6)\n",
      "state: (0, 2, 6, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 5)\n",
      "state: (0, 2, 6, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 4)\n",
      "state: (0, 2, 6, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 7, 3)\n",
      "state: (0, 2, 7, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 7, 3)\n",
      "state: (0, 2, 7, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 2)\n",
      "state: (0, 2, 6, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 5, 2)\n",
      "state: (0, 2, 5, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 2)\n",
      "state: (0, 2, 4, 2)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 5, 2)\n",
      "state: (0, 2, 5, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 2)\n",
      "state: (0, 2, 4, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 4, 3)\n",
      "state: (0, 2, 4, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 5, 3)\n",
      "state: (0, 2, 5, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 2, 6, 3)\n",
      "state: (0, 2, 6, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 6, 2)\n",
      "state: (0, 2, 6, 2)\n",
      "action selected: 3\n",
      "reward: 8.147601632962345e-11\n",
      "(0, 2, 7, 2)\n",
      "state: (0, 2, 7, 2)\n",
      "action selected: 3\n",
      "reward: 2.2902067258820156e-12\n",
      "(0, 2, 7, 1)\n",
      "state: (0, 2, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 6, 1)\n",
      "state: (0, 2, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 1)\n",
      "state: (0, 2, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 5, 0)\n",
      "state: (0, 2, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 4, 0)\n",
      "state: (0, 2, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 3, 0)\n",
      "state: (0, 2, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 2, 0)\n",
      "state: (0, 2, 2, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 1)\n",
      "state: (0, 2, 2, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 2)\n",
      "state: (0, 2, 2, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 3)\n",
      "state: (0, 2, 2, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 4)\n",
      "state: (0, 2, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 5)\n",
      "state: (0, 2, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 2.81745815721163e-24\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.348645072078734e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.1540210582476322e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.8731276639058125e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 2.676482206879205e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 9.367782439545386e-14\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 3\n",
      "reward: 9.356047515794336e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 1.9339056819028768e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 6.760545834060645e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 9.352676101824437e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 8.08826258955357e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 1\n",
      "reward: 7.536527581874645e-15\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.347944159804e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 3.6684772010309844e-17\n",
      "(0, 2, 2, 8)\n",
      "state: (0, 2, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.298430138629284e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.1536627735783895e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.348839498073417e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.154977573612091e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.8731464343911498e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 8.687598243524751e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 2\n",
      "reward: 9.367782410583946e-14\n",
      "(0, 2, 0, 9)\n",
      "state: (0, 2, 0, 9)\n",
      "action selected: 3\n",
      "reward: 9.367120315885678e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 1.9345283795940523e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.148704941303384e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1788879945322902e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1796339809385057e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1796522038449023e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1796526451131784e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 7.88494725495195e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.3291349549295293e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.182962884221123e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1797259537276974e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 6)\n",
      "state: (0, 2, 0, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 8.863579018116547e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 6.708027676175528e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.352576105823397e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 8.064324737556326e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 1\n",
      "reward: 9.334287733439144e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.1976717159022838e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.8731515458268044e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.349383198700652e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 2.592824313668349e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 2.723640920508018e-14\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.349195787220936e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.4658465633364567e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.34886269267779e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.1552341502376459e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 8.608617163129894e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 9.36058650386155e-14\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 9.355491140370699e-14\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 1.1968956679519578e-16\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.873856688838276e-14\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.349383751888193e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 1.9463170193537183e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 8.857623858590438e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 1.867159611982968e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1949223175083e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 2\n",
      "reward: 8.8474108413377e-14\n",
      "(0, 2, 0, 8)\n",
      "state: (0, 2, 0, 8)\n",
      "action selected: 3\n",
      "reward: 1.866981275998401e-16\n",
      "(0, 2, 0, 7)\n",
      "state: (0, 2, 0, 7)\n",
      "action selected: 0\n",
      "reward: 1.1949165714432342e-16\n",
      "accumulated_rewards_per_episode: 8.625685484520219e-11\n",
      "START STATE: (0, 0, 1, 4)\n",
      "(0, 0, 1, 4)\n",
      "state: (0, 0, 1, 4)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 4)\n",
      "state: (0, 0, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 2\n",
      "reward: 3.704585275812797e-07\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 2\n",
      "reward: 1.452272621130929e-08\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 2\n",
      "reward: 0.007422953747976455\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.011865587349959506\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.011962567154222416\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.011964713600654231\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 2)\n",
      "state: (0, 0, 8, 2)\n",
      "action selected: 3\n",
      "reward: 9.482351109594362\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 1.8789584635524983\n",
      "(0, 1, 2, 7)\n",
      "state: (0, 1, 2, 7)\n",
      "action selected: 2\n",
      "reward: 0.05099349949893711\n",
      "(0, 1, 2, 8)\n",
      "state: (0, 1, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.481683641261826\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 6.262501971235163e-06\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.481559141670383\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 2)\n",
      "state: (0, 1, 2, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 2)\n",
      "state: (0, 2, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 2)\n",
      "state: (0, 2, 2, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 3)\n",
      "state: (0, 2, 2, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 4)\n",
      "state: (0, 2, 2, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 5)\n",
      "state: (0, 2, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 2, 1, 5)\n",
      "state: (0, 2, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 6)\n",
      "state: (0, 2, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 9)\n",
      "state: (0, 2, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 1, 8)\n",
      "state: (0, 2, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 2, 1, 7)\n",
      "state: (0, 2, 1, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 2, 2, 7)\n",
      "state: (0, 2, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 30.418768324914048\n",
      "START STATE: (0, 0, 1, 8)\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 7)\n",
      "state: (0, 0, 3, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 7)\n",
      "state: (0, 0, 4, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010692978428525996\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.978798040084218\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 8.94290924365011e-14\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.978779960263715\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 7)\n",
      "state: (0, 0, 4, 7)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 6)\n",
      "state: (0, 0, 4, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 4, 7)\n",
      "state: (0, 0, 4, 7)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010692487123428923\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.978339897969683\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 2)\n",
      "state: (0, 1, 4, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 5.517787466975251e-27\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.977466202543399\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010692309076286122\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.97746635660787\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 2)\n",
      "state: (0, 1, 4, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 49.89117123521525\n",
      "START STATE: (0, 0, 7, 4)\n",
      "(0, 0, 7, 4)\n",
      "state: (0, 0, 7, 4)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00011301454971978777\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.97959671646732\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 0, 1)\n",
      "state: (0, 1, 0, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 2)\n",
      "state: (0, 1, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 3)\n",
      "state: (0, 1, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 4)\n",
      "state: (0, 1, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 5)\n",
      "state: (0, 1, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 6)\n",
      "state: (0, 1, 0, 6)\n",
      "action selected: 2\n",
      "reward: 5.5095696362539405e-14\n",
      "(0, 1, 0, 7)\n",
      "state: (0, 1, 0, 7)\n",
      "action selected: 2\n",
      "reward: 9.948017379949341\n",
      "(0, 1, 0, 8)\n",
      "state: (0, 1, 0, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 4)\n",
      "state: (0, 0, 7, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 3)\n",
      "state: (0, 0, 7, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0019396022729609465\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.945691715199466\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 6)\n",
      "state: (0, 1, 0, 6)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.2964572618499592\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.875827207052016\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 4)\n",
      "state: (0, 0, 7, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 7, 3)\n",
      "state: (0, 0, 7, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 3\n",
      "reward: 0.00046664227999301366\n",
      "(0, 0, 7, 2)\n",
      "state: (0, 0, 7, 2)\n",
      "action selected: 3\n",
      "reward: 1.0371449093185887e-05\n",
      "(0, 0, 7, 1)\n",
      "state: (0, 0, 7, 1)\n",
      "action selected: 1\n",
      "reward: 9.951664094408022\n",
      "(0, 0, 8, 1)\n",
      "state: (0, 0, 8, 1)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 1, 9, 1)\n",
      "state: (0, 1, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 0)\n",
      "state: (0, 1, 7, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 0)\n",
      "state: (0, 1, 6, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 0)\n",
      "state: (0, 1, 5, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 0)\n",
      "state: (0, 1, 4, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 0)\n",
      "state: (0, 1, 3, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 4)\n",
      "state: (0, 1, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 5)\n",
      "state: (0, 1, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 1.6009554147506184e-05\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.94332824549898\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 60.943128260531076\n",
      "START STATE: (0, 0, 9, 9)\n",
      "(0, 0, 9, 9)\n",
      "state: (0, 0, 9, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 9)\n",
      "state: (0, 0, 9, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010788129722416228\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.97959685540761\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 4.7286791318619195e-35\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.979144734557496\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 8)\n",
      "state: (0, 0, 4, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 8)\n",
      "state: (0, 0, 5, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 8)\n",
      "state: (0, 0, 6, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 8)\n",
      "state: (0, 0, 7, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 8)\n",
      "state: (0, 0, 8, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 7)\n",
      "state: (0, 0, 8, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 6)\n",
      "state: (0, 0, 8, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 5)\n",
      "state: (0, 0, 8, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 4)\n",
      "state: (0, 0, 8, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 8, 3)\n",
      "state: (0, 0, 8, 3)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.00010692884724930815\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.978710943815617\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 9, 2)\n",
      "state: (0, 1, 9, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 2)\n",
      "state: (0, 1, 8, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 2)\n",
      "state: (0, 1, 7, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 0, 1)\n",
      "state: (0, 1, 0, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n",
      "reward: 4.760560312094424e-10\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.97679788040949\n",
      "(0, 1, 1, 8)\n",
      "state: (0, 1, 1, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 8, 9)\n",
      "state: (0, 0, 8, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 9)\n",
      "state: (0, 0, 9, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 8)\n",
      "state: (0, 0, 9, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 7)\n",
      "state: (0, 0, 9, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 6)\n",
      "state: (0, 0, 9, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 5)\n",
      "state: (0, 0, 9, 5)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 4)\n",
      "state: (0, 0, 9, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 9, 3)\n",
      "state: (0, 0, 9, 3)\n",
      "action selected: 3\n",
      "reward: 0.0841195590606302\n",
      "(0, 0, 9, 2)\n",
      "state: (0, 0, 9, 2)\n",
      "action selected: 3\n",
      "reward: 9.976820100373732\n",
      "(0, 0, 9, 1)\n",
      "state: (0, 0, 9, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 8, 1)\n",
      "state: (0, 1, 8, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 7, 1)\n",
      "state: (0, 1, 7, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 6, 1)\n",
      "state: (0, 1, 6, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 5, 2)\n",
      "state: (0, 1, 5, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 5, 1)\n",
      "state: (0, 1, 5, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 4, 2)\n",
      "state: (0, 1, 4, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 1, 4, 1)\n",
      "state: (0, 1, 4, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 3, 1)\n",
      "state: (0, 1, 3, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 1)\n",
      "state: (0, 1, 2, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 2, 0)\n",
      "state: (0, 1, 2, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 1, 1, 0)\n",
      "state: (0, 1, 1, 0)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 1)\n",
      "state: (0, 1, 1, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 2)\n",
      "state: (0, 1, 1, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 3)\n",
      "state: (0, 1, 1, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 4)\n",
      "state: (0, 1, 1, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 5)\n",
      "state: (0, 1, 1, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 1, 1, 6)\n",
      "state: (0, 1, 1, 6)\n",
      "action selected: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 1.4309777628427602e-13\n",
      "(0, 1, 1, 7)\n",
      "state: (0, 1, 1, 7)\n",
      "action selected: 2\n",
      "reward: 9.975957684300027\n",
      "accumulated_rewards_per_episode: 59.95136256854528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x224d7d27550>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x224d7d5ceb0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######### verify the dqn_cnn policy\n",
    "'''\n",
    "Parameters\n",
    "----------\n",
    "start : (r,c) = POMDP state\n",
    "    The start state of the product POMDPs.\n",
    "\n",
    "EPISODES : int\n",
    "    The number of episodes.\n",
    "\n",
    "num_steps : int \n",
    "    The episode length.\n",
    "\n",
    "'''\n",
    "\n",
    "from dqn_cnn import DQNAgent\n",
    "EPISODES=20\n",
    "num_steps=100\n",
    "\n",
    "Path = []\n",
    "\n",
    "gamma=0.99999\n",
    "gammaB=0.9\n",
    "\n",
    "# the defined belief_state size and action size\n",
    "belief_state_size = np.shape(csrl.belief_state)\n",
    "#action_size = np.shape(csrl.A)\n",
    "\n",
    "# find the size of belief_state for np.reshape\n",
    "prod_b_state_size = 1\n",
    "for i in range(len(belief_state_size)):\n",
    "    prod_b_state_size = prod_b_state_size * belief_state_size[i]\n",
    "# find the size of action for np.reshape\n",
    "\n",
    "# action size\n",
    "#prod_action_size = csrl.shape[4]\n",
    "prod_action_size = 4\n",
    "\n",
    "agent = DQNAgent(prod_b_state_size, csrl.shape[2], csrl.shape[3], csrl.shape[1], prod_action_size, gamma, gammaB)\n",
    "agent.load(\"./save/DQN_CNN_10_frontier.h5\")\n",
    "agent.epsilon = 0\n",
    "done = False\n",
    "num_episode_for_reward = 100 # print the accumulated reward per num of episode\n",
    "# initialize the list for plot\n",
    "accumulated_rewards=[]\n",
    "exploration_rate=[]\n",
    "accumulated_rewards_hundred_steps = []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    accumulated_rewards_per_episode=0\n",
    "    done = False\n",
    "    subpath = []\n",
    "\n",
    "    pomdp_state = csrl.pomdp.random_state()\n",
    "    while csrl.pomdp.label[pomdp_state[0],pomdp_state[1]] == ('c',) or csrl.pomdp.structure[(pomdp_state[0],pomdp_state[1])]=='B':\n",
    "        #print('state in c and B, state is regenerated')\n",
    "        pomdp_state = csrl.pomdp.random_state()\n",
    "    #pomdp_state = (9, 7)\n",
    "\n",
    "    state = (csrl.shape[0]-1,csrl.oa.q0)+(pomdp_state) # select the start product state\n",
    "    print('START STATE: '+str(state))\n",
    "    belief_state = csrl.belief_state # initialize the belief state\n",
    "    \n",
    "    csrl.track = [0,1] #self.initial_track # initialize frontier set = [0,1]\n",
    "    ###print('begin new episode, self.track is reset')\n",
    "    ###print('frontier reset as: [' + str(self.track)[1:-1] + ']')\n",
    "    reshaped_reward = csrl.reshaped_reward_init\n",
    "    ###print('begin new episode, reward is reset to initial reward')\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        print(state)\n",
    "        subpath.append(state)\n",
    "        # reshape the belief state as the input to acquire the action\n",
    "        input_b_state = np.reshape(belief_state,(1, csrl.shape[2], csrl.shape[3], csrl.shape[1]))\n",
    "        print('state: '+str(state))\n",
    "        #print('input_b_state: '+str(input_b_state))\n",
    "\n",
    "        # verify the existence of action and select the action from the belief_state\n",
    "        action_probs = agent.act_trained(input_b_state)\n",
    "        action_probs = np.reshape(action_probs,(prod_action_size,1))\n",
    "        #print('action_probs: '+str(action_probs))\n",
    "\n",
    "        i = 0\n",
    "        possible_actions = []\n",
    "        for i in range(len(csrl.A[state])):\n",
    "            possible_actions.append(action_probs[csrl.A[state][i]])\n",
    "        action = csrl.A[state][np.argmax(possible_actions)]\n",
    "        #print('possible_actions :'+str(possible_actions))\n",
    "        print('action selected: '+str(action))\n",
    "\n",
    "        ################## The agnet on POMDP simualtion\n",
    "\n",
    "        # agent moves to the next state\n",
    "        states, probs = csrl.transition_probs[state][action]\n",
    "        next_state = states[np.random.choice(len(states),p=probs)]\n",
    "        # find the observation states' list and the corresponding probabilities\n",
    "        obsv_states, obsv_probs = csrl.pomdp.get_observation_prob(next_state[-2:])\n",
    "        # observe the next state\n",
    "        obsv_state = csrl.pomdp.generate_obsv_state(obsv_states, obsv_probs)\n",
    "\n",
    "        ################## The belief_state update with the loops\n",
    "\n",
    "        # temproraily store the current belief state\n",
    "        current_belief_state = belief_state\n",
    "\n",
    "        # multiply the transition probability matrix\n",
    "        belief_state_after_transition = []\n",
    "        for s in csrl.states():\n",
    "            belief_state_after_transition.append(belief_state[s]*csrl.belief_transition_probs[s][action])\n",
    "        belief_state_after_transition = sum(belief_state_after_transition)\n",
    "        # update the belief state with the observation probability matrix\n",
    "        updated_belief_state = belief_state_after_transition\n",
    "        for s in csrl.states():\n",
    "            updated_belief_state[s] = updated_belief_state[s]*csrl.belief_observation_probs[s][obsv_state[0], obsv_state[1]]\n",
    "        belief_state = updated_belief_state/sum(sum(sum(sum(updated_belief_state))))\n",
    "\n",
    "        ################# The training process\n",
    "        \n",
    "        # Update the frontier set + update reward setup accordingly\n",
    "        reshaped_reward = csrl.Tf(state, next_state, reshaped_reward)\n",
    "        ###print('frontier set: [' + str(csrl.track)[1:-1] + ']')\n",
    "        \n",
    "        # calculate the reward from the next belief state and find gamm\n",
    "        reward = np.sum(np.reshape(belief_state,(1,prod_b_state_size))*reshaped_reward)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        accumulated_rewards_per_episode = accumulated_rewards_per_episode + reward\n",
    "        print('reward: '+str(reward))\n",
    "    \n",
    "    Path.append(subpath)\n",
    "    \n",
    "    print('accumulated_rewards_per_episode: '+str(accumulated_rewards_per_episode))\n",
    "    accumulated_rewards.append(accumulated_rewards_per_episode)\n",
    "    exploration_rate.append(agent.epsilon)\n",
    "\n",
    "    if len(accumulated_rewards)>=num_episode_for_reward:\n",
    "        accumulated_rewards_hundred_steps.append(np.average(accumulated_rewards))\n",
    "        accumulated_rewards = []\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "t1 = np.arange(0, EPISODES, 1)\n",
    "t2 = np.arange(0, len(accumulated_rewards_hundred_steps)*num_episode_for_reward, num_episode_for_reward)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "display(plt.plot(t1, exploration_rate))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "display(plt.plot(t2, accumulated_rewards_hundred_steps))\n",
    "#matplotlib.pyplot.scatter(len(accumulated_rewards_hundred_steps)*10, accumulated_rewards_hundred_steps, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a00d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "size_x = 10\n",
    "size_y = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a4e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJDCAYAAADJvlo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn3klEQVR4nO3deZBlV2Hn+d9572VWVlZVSrVoTQlkCdCGoZEEBsumMfsYxtjQTOOtabdtTUfPuD1NTziwIybsmIiZoSN6NPZs7VHbBvd4ads00azGJrCN22OMQRIIrSwqkFQqVFKVqkq15fLemT8yZWhQSfnynVxe6vOJqKjKrLznnqNXWfXVvffdW2qtAQBgdJ2NngAAwFYhrAAAGhFWAACNCCsAgEaEFQBAI8IKAKCRZwyrUspvlVIOlVLu/JbP7SmlfKKU8uXln3ev7TQBADa/lRyxel+SN37b596d5JO11ucn+eTyxwAAz2plJTcILaVcluQjtdYXLn98X5JX1VoPllIuSvIXtdYr13SmAACb3Gqvsbqg1nowSZZ/Pr/dlAAAxlNvrXdQSrkpyU1J0ul0rh8MBmu9SwCAFh6rtZ43zAarDatHSikXfcupwENn+8Ja6y1JbkmSUko9cPzAKne5+c3OzMb6xtNWXltifePO+sbX7Mxs3vXxd230NNbMzW+8eauv7+vDbrPaU4EfSvLO5V+/M8kHVzkOAMCWsZLbLfx+kk8nubKU8lAp5aeTvCfJ60opX07yuuWPAQCe1Z7xVGCt9UfP8luvaTwXAICx5s7rAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEZKrXX9dlbK+u0MAGA0t9Zabxhmg95azeRsDhw/sN67XDezM7PWN6a28toS6xt31je+Zmdm866Pv2ujp7Fmbn7jzVt+fcNyKhAAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjI4VVKeVflFLuKqXcWUr5/VLKVKuJAQCMm1WHVSllNsk/T3JDrfWFSbpJ3tFqYgAA42bUU4G9JNtLKb0k00keHn1KAADjadVhVWs9kORfJ3kgycEkx2qtf9pqYgAA46bUWle3YSm7k/yHJP8wydEkf5Tk/bXW3/m2r7spyU3LH16/6pkCAKyvW2utNwyzQW+Enb02yf5a66NJUkr5QJLvTfKfhVWt9ZYktyx/TT1w/MAIu9zcZmdms9XXN/eRF230NNbEtjffsWXXliytb6v/2bS+8bWV17eV15Y8O9Y3rFGusXogyctLKdOllJLkNUnuGWE8AICxNso1Vp9J8v4ktyX54vJYtzSaFwDA2BnlVGBqrb+c5JcbzQUAYKy58zoAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCOl1rp+Oytl/XYGADCaW2utNwyzQW+tZnI2B44fWO9drpvZmdktv765j7xoo6exJra9+Y4tu7ZkaX1b/c+m9Y2vrby+rby25NmxvmE5FQgA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0MhIYVVKObeU8v5Syr2llHtKKa9oNTEAgHHTG3H7X0vy8VrrPyilTCaZbjAnAICxtOqwKqXMJHllkn+cJLXW+STzbaYFADB+RjkVeHmSR5O8t5RyeynlN0opOxrNCwBg7JRa6+o2LOWGJH+T5MZa62dKKb+W5Hit9X/4tq+7KclNyx9eP8pkAQDW0a211huG2WCUsLowyd/UWi9b/vj7k7y71vqmp9mmHjh+YFX7GwezM7OxvvG0ldeWLK3vXe9+10ZPY83c/J6bt/z6tvqfz626vq28tuRZsb6hw2rVpwJrrd9I8mAp5crlT70myd2rHQ8AYNyN+q7An0vyu8vvCLw/yU+NPiUAgPE0UljVWj+fZKhDZAAAW5U7rwMANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANFJqreu3s1LWb2cAAKO5tdZ6wzAb9NZqJmdz4PiB9d7lupmdmbW+MbWV15Ysre9d737XRk9jzdz8npu3/Pq2+p/Prbq+rby25NmxvmE5FQgA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEaEFQBAI8IKAKCRkcOqlNItpdxeSvlIiwkBAIyrFkesfj7JPQ3GAQAYayOFVSnlkiRvSvIbbaYDADC+Rj1i9atJfiHJYPSpAACMt1JrXd2Gpbw5yQ/WWv9ZKeVVSf77Wuubn+Lrbkpy0/KH169yngAA6+3WWusNw2wwSlj9L0l+MslikqkkM0k+UGv9iafZph44fmBV+xsHszOzsb7xtJXXlljfuJudmc3cR1600dNYM9vefMeWXd+2N9+x5f9sbvH1DR1Wqz4VWGv9xVrrJbXWy5K8I8mfPV1UAQBsde5jBQDQSK/FILXWv0jyFy3GAgAYV03CCnhqdVDzxNeeyJG7j+SxLzyW4/uPp3+6n0F/kO62bradsy37XrIve67Zk91X787kzORGTxmAEQgraGywMMiDn3gwd//m3Xns9sdSOiVJ0p/rJyUpZenjWmtSk/0f2p/OZCeDuUGm9k3l8h+5PFf+5JXZ9dxdG7kMAFZBWEEjJx46kfv+3X2573fuy2B+kP58P93J7t+FVW/703+7dSY7mXt8Lnf/27tzz2/ek30v2ZdrfvaaXPr6S9PpuhwSYBwIKxjRYGGQO3/9znzhV7+Q2q8pnZJOr5Pe1HDfXqWUlF5JektHsw597lAe+8JjOeeKc/LK//OVOfcF567NAgBoxv8GwwiO3HUkH3r9h/KFm7+QJOlOdtPpjf5tVUpJb6qX0ik5eu/RfPiNH87nb/58BgsecgCwmQkrWKW7/p+78tH/8qM59tVjKb2yJqfrSinpTnVTSskX/48v5oOv/WBOPnyy+X4AaENYwZBqrfns//jZ3Pae25KSpSNLyxekr5XSXTpN+MTXnshHfvAjOfaVY2u6PwBWR1jBEGqt+eyvfDb3vvfelO7aHKU6m1JKutu6mXt8Lh/7kY/l+P7j67ZvAFZGWMEQ7vy/78x9/+6+pSNInbU9SnU23W3dLBxfyB+/9Y9z5vCZDZkDAE9NWMEKHb7zcD7/v34+pbNxUfWkJ49c/fUv/HVW+yB1ANoTVrAC/bl+PvVPP5XB4iClu7FR9aTORCcH/vxA9n9o/0ZPBYBlwgpW4LZ/dVtOHDiR7rbu6gYYDJKFheTMmZRTp5Z+nD6dzM8ni4vJKo46lVKSmnz6Fz6dU4+cWt28AGhKWMEzOHHgRO59773pdDvDv/uvv7gUUSdPpZyZS3kyompNBoOU+fmU02dSTp5M5uaGDqzORCeLpxdz+7+6fbh5AbAmhBU8g3vfe2/qoA53XVWtKWfOpJw6vRRL3c7Sj04nKeWbPzrf/HyZX0g5eWrpCNYQupPd3P/B+zN3dG7IlQHQmrCCp7F4ZjH3/b/3DXddVa1Lp/kWFpNudymgVqLbWXpI8+nTS6cNV6h0lk4JfvkPvrzyOQKwJoQVPI2vffhrGSwOVv6YmiejajBYCqVhlZJ0uylnzgx35Komd/36XRn0PfIGYCMJK3gaX/nDr6QuDHHd08JC0h8sneIbRWc5rurKQqkz0cnCEws5cueR0fYLwEiEFZxFrTWHv3g4nYkVfpsMBilz86s7UvXtnjx7ODe/4k3qoAorgA0mrOAsTj58MoP5Ie5btbDwzSBqodNJWVj5rRgGC4M88plHGk4AgGEJKziLw3ccHuqi9bKwMPopwKeywmutOr1ODn3uUPv9A7BiwgrO4thXjmXx9AovIB8MkrV4skxJ0u+v7Et7JScePJE68IgbgI0irOAs5p+YX3ksDdbo3Xilk7LCd/o9efPS/vzKQgyA9oQVnEX/dH/4O623VpJhDoWVbslg3i0XADaKsIKz6E51U9fk/N4Qhtx97deVv4sRgOb8DQxnMbFrYuVfvBYXrSfLj8NZ2YOfa62pta7+QdEAjExYwVmcc8U56W3vreyLO6XtrRaeVGvqSsOqX7Pj4h3DPdMQgKaEFZzF3hfuHeIddiV1YmJtLmJfYVgNFgY5//rz2+8fgBUTVnAWO5+zM6VTVh5XExMrvpnnigwGyURvxacZS6/kgldc0G7/AAxNWMFZlFKy55o9GSys8ChUp5M6Obn0rMBRLfdZnZxc8SadXid7X7h39H0DsGrCCp7GFW+7Yqi7r2dycukI06inBAf91G3bVny0arA4SHdbN3u/W1gBbCRhBU/j8rdentIpGaz0KFQpqdunklJWF1c1SX85qiZW/q7EWmuu+Zlr3GoBYIP5WxiexsTOiTzvHz5v5acDk6VTgtPTSxed9/srv+5qMEjqYCnMhjgFWAc1JSUv+PEXrHyOAKwJYQXP4Jqfviadbme4Z/CVkrp9e+r27Usf9wdLP2r95k0/a12KqeXfq71e6o7ppDfE/bOy9AibS99wabaft32o7QBoT1jBM5i5fCaX/4PLV3468Fv1eqk7dqROb0/dtnz9VeryUayyFFNT21J37kimppIy3LfkYHGQ7mQ31//i9cPPDYDmhBWswMt++WWZ2juV/twqH3Dc7SaTk0tHsXbsWP4xvRRTExNL12QNqS6fYnzpr7w0u567a3XzAqApYQUrMLFzIq/6N69K6Q5xX6s1Npgf5PwbzndtFcAmIqxghc5/6fm5+p9cndqvf3e0aKP05/qZ2DmR7//fvz9lFUe7AFgbwgqGcP0vXZ/Lfuiy1MWNi6v+XD+97b284Y/ekOkLpzdkDgA8NWEFQyidkhtvvjGXveWyDBYH635asD/XT29HL6//g9dnzzV71nXfADwzYQVD6nQ7+b7/7fty7c9em9qvq7+gfQh1UNNf6GfqvKm86cNvyr4X71vzfQIwPGEFq1BKyfW/dH1e93uvy9R5U+kv9Nfs6FV/rp/ar3nBj74gP/IXP5JzrjhnTfYDwOiEFYzgwldcmLf+5Vtz1TuvSh3ULJ5ZTO2PHli1Lh0JGywOMn3RdN7wh2/Iy//nl2di53A3DwVgffU2egIw7nrTvbzsV16W57/j+bn7lruz/4P7M+gPUvs1nYnOUO/aq/2lU36diU52XbYr1/7X1+aKt12R7rbuGq4AgFaEFTSy+6rdufHmG/PSX3lp9n9of+75jXty/P7j6Ux1UhdqBouDlE5JSpZ+1KUfdVDTneqm9mtKt+Tyt16eq3/q6ux90V63UgAYM8IKGpucmcyVP3FlrvyJK7NwciFH7zuaI3cfyaG/PZQnHngi/TNLp/h6U71M7JrIvuv2Zd9378uea/dkxyU7xBTAGBNWsIYmdkzkvOvOy3nXnZcrf+LKjZ4OAGvMxesAAI0IKwCARoQVAEAjwgoAoJGyng+SLaVszFNrAQCGd2ut9YZhNlj3dwUeOH5gvXe5bmZnZq1vTG3ltSXWN+5mZ2Yz95EXbfQ01sy2N9+xZde37c13bPk/m1t9fcNyKhAAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAa6W30BBjC/Hw6Rx5P5/GjycJC0umkzsxksHdP6o7pjZ7d6E6fTufwkXSOHU/6/aTXy+DcczLYuyfZtm2jZzey8sSJdA4fSTlxIhkMksnJDPbszmDP7qTnWxFgK/C3+RjoPnggE7fent4X705qTUmS1NQkpZSk1ixeMpuFV7wsi8+7PJmY2NgJD6PfT/f+r2XyM59L7/79Semk1kFKkpqS5V+kf9ULMv/S69K/7DlJKRs965Wbm0vv3i9n8tN/m+6hR5OllytJ8uQqaq+Xhb/3oixc96IMLrxgw6YKwOiE1SZWnjiRbX/6Z5n44l2pU1MZXHRB0u1+5xfWms6x45n6gw+knrcvp3/4TRnMXrz+Ex5S59CjmfrwH6f70IEMdu5Mf/bipPMUZ6cHg3S//kCm77oni1c+P2fe+NrUPbvXf8JD6t7/tUx96GPpHD2Wwe5z07909qm/cHExE5+/I5N/+7nMv+z6zP3A9yfbt6/vZAFowjVWm1Tn4Dey49d/MxP3fSn9S2czuOC8p46qJCkl9dxzMnjupcn8XHb829/OxGdvW98JD6l3973Zcct70znyePrPuXQplJ4qqpKk08lg3970n3tpug88mB2//lvp7v/6+k54GLVm8i/+U6bf97tJp5P+cy9Nndl19q/v9TK46IL0L7k4E7d9PjtueV86h4+s33wBaEZYbUKdRw5l+n2/lzoxkf5FF549OJ5CPffc9C+6MFMf/uNMfO72NZzl6vXuuS/b/+AD6e/dm8G+vSvfsJQMLjg/dWZnpn/n36f79QfXbpIjmPzUX2Xbn/9l+s+5JHXXzpVv2O1mMHtxysJCpt/3uymPH12zOQKwNoTVZjM/n+1/9B9Tt02mnjOzujEmJ9KfvThTH/2TdA5+o+38RlSOPJ6pD3w4/QvPT6ZWd0F63bEjg3PPyfY//EDKyVONZzia7lf3Z9uf/WX6l15y9iOMz2Cwd0+ysJipD3506SJ+AMaGsNpkJv/q0ymHj6TuPnfEgSYy2Lkj2//j5vrHeeqjf5L0usnU1Ejj1J07U+bns+0Tf9ZoZg2cOZPtH/xoBuftW3VUPWlwwXnp7X8gE7ff0WhyAKwHYbWJlFOnM/npv83g4gubjFf37E7n0KFNcz1S5+GD6X11fwbnn9dkvP6FF2Tijrs2zSmz3r1fTnniROrOHU3G6194XrZ96q+SxcUm4wGw9oTVJtL90ldSFvtN72k02Lkzk5/5bLPxRjFx2xdSt022G7DTSUpJ78672405gm3/398s3ZOqlamplBMnN00YA/DMhNUm0vvq/Rk0OtrxpHrOTHr7H9gURz0mvvSVDHa3vU3C4JyZTHzpq03HXI1y4mQ6hw83O1r1pDo5kd4DDzUdE4C1I6w2kd7XH0zd0fYf5nS7yWCwdLf2DVROnFy643jLI1ZJ6o7pdA9+Y8OvI+scPpKU9t9OdeeOdL/miBXAuBBWm0h54kQyuQZ3Te90Us7MtR93CGVuLumMdkH3U+p0ksEgZW6+/dhDKGfOfPOW6g3VicmlPxcAjAVhtZmM06NaNpm60f/p1uy1q/5cAIwRYbWJDM49J5lrf2SpDgYZbPBDmgc7plMH/fZHdRYXU3u9DX9I82DH9Dcf/tdQOTOXwai33gBg3QirTWTxsuem0/q0z+JiMtFLPfectuMOa2oqdffu5MyZpsOWk6eWnsE3xN3p18Jg757UWpuHYzlxMouXX9Z0TADWjrDaRPpXPi85fbrpmJ3DR7J49ZUbHh5JsvDCq9M9crTpmOX4E1m85sqmY67K1FT6z31OytFjbcft9zN4zqVtxwRgzWz8v7b8ncXLL0ump5NWF5rXmnJmLvMvva7NeCNaeNELl969Nxi0GXBxMel2s3j1VW3GG9H8974sneNPNBuvPHEi9by9S0fkABgLwmozmZjI3Ktfme43HmkyXOfQo1l8wfMyuPiiJuONqu7dk/nrXpzOwTbr6x44mPkbX546vb3JeKPqX/5d6c9etHTrhVENBukcPpIzr/0BF68DjBFhtcksvOTFWXz+5emMGFfl5MmkJmfe9IZN9Q/z/GteleyYTjl2fKRxOo8dTv/CCzJ/4/e0mVgL3W7OvOVNKadOj3zUsfPwwSxc9/fSf8HzGk0OgPUgrDabTidn3vLm1JmZdB45tKohyomT6Tx+NKff8bbUc2YaT3A0dXp7Tr3jbSmnz6z6eqTOY4eTbjen3/7DycQa3PdrBIPzz8vpt/1Quo8cWvX1cp0DBzO4+KKcecOrG88OgLUmrDahumtnTv2jH83gvH3pfv3BZH5hZRsOBuk+/I2UU6dy6h/9WPrf9dy1negqDS66MKd+6sdTknQeenjld01fXEz3gYdSp6dz8p0/lrp3z5rOc7UWr706p9/xtnQeP5bONw6t/J2CZ+bS3f/19K+4LKd+7O3J1NTaThSA5to97Zem6q6dOfWPfzwTn70t2z75qaX7Ne05N3V6+jvf4XdmLt0jR5LFfha++5rMvf41zZ9Z19rgwgty4p/+k2z78/+Uyc/elnQ66e/dnWz/tuulak05dTrl8cdTajL3978v89/7smSy7aNxWlu86gU5+c9+JlN//In0vvSV1MnJDPbu/s55DwZLRxiPHkvdti2n3/aWLH73NZviXZwADE9YbWbdbhZe/tIsfve16d17XyY+d3u6Dx9MUlKTpCRlUFN37cz897w0Cy9+YQbn7dvgSQ9h+/bM/eDrM//yl2bizrszcfsdKY89tBQVTx7kqTWDvXsy/7pXZ/Gaq1Jndm3olIdRd5+b0z/29nQOfiMTt38xE3ffk3L6dOrynURLkpSS/oUX5PQPvDKLL7jCUSqAMSesxkDdMZ2F61+ShetfkiwspHP0WLKwkHQ6qTMzm+ZdcatV9+zO/CtvzPwrb0zOnEnn2PGl04O9XgbnzGz4XdVHNbjowsxddGHmfvB133wY9WCQTE4u3W2/59sQYKvwN/q4mZgYr6NSw5qaymALH7WpO3ds+tO0AKyeCzkAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjaw6rEopl5ZS/ryUck8p5a5Sys+3nBgAwLgZ5VmBi0n+Za31tlLKriS3llI+UWu9u9HcAADGyqqPWNVaD9Zab1v+9RNJ7kky22piAADjpsk1VqWUy5K8JMlnWowHADCOSq11tAFK2ZnkU0n+p1rrB57i929KctPyh9ePtDMAgPVza631hmE2GCmsSikTST6S5E9qrTev4Ovru959fNX72+xufs9Mtvr6Dhw/sNHTWBOzM7Nbdm2J9Y076xtfW3ltybNifUOH1SjvCixJfjPJPSuJKgCArW6Ua6xuTPKTSV5dSvn88o8fbDQvAICxs+rbLdRa/ypJaTgXAICx5s7rAACNCCsAgEaEFQBAI8IKAKARYQUA0IiwAgBoRFgBADQirAAAGhFWAACNCCsAgEZW/UgbNk63P59ufyGDTjeLvamNng4AsExYjYFSB9l97OuZfeSO7D729UyfPpqkpKRmvjeVozOX5uD51+TQ3iuFFgBsIGG1ye078uVc++WPZfr00SxMTOXMtpkcPefSv/v9Tn8hMycO5rzDX8qg28uXn/uqfP2S78mg46UFgPXmX99Nqtufz7Vf+lgueeT2nJjel8fPfc5Tft2gO5HT23fn9Pbd6fQXctX9n8jsI3fk9mv/q5yc3rvOswaAZzcXr29C3cW5XHfnH+biQ3fkyDnPyfzkzhVtN+hO5PFzn5ttCyfy8tt/KztPPrrGMwUAvpWw2oSu/urHs+/x+5dO+ZXhX6KT0/sy6HRy/Z2/l97C6TWYIQDwVITVJnP+Y/flOQdvz+PnzI40zuntezI190Su3P/JRjMDAJ6JsNpESh3k6q9+PCem967qSNW3O7brojzn4K1OCQLAOhFWm8iTt1JY6TVVz6h00u/0csnB29uMBwA8LWG1iVzw6L1Z7G1rOubJ6X2ZfeQLTccEAJ6asNpE9hz7Ws60Olq1rN+dzMTimWybO950XADgOwmrTWTXqceyMLG9/cAl2S6sAGDNCatNpNRBk4vWzzo2ALCmhNUmMt/bnk5/ofm4Nclit+21WwDAdxJWm8jRmUuybeFk20HrIKnJqe27244LAHwHYbWJPLbnikzOn2g65tTcEzm+66L0u5NNxwUAvpOw2kS+se/qlFpTBv1mY24/czT7L3lFs/EAgLMTVpvI3LaZPHTBi7PrxCNNxpucP5G5bbvy6N7nNxkPAHh6wmqT+dLlr0m/O5nJ+dGutSqDfnaeejRfuOqHnQYEgHUirDaZ+cmd+fzVb83OU4+lt3B6dYPUQXYffzBfvfT7cnj3FW0nCACclbDahA7vuSKfe+E7suP04UyfOjzUtr2F09lz9IHsv+QV+dLlr12jGQIAT0VYbVKH9l2Vv77uZzM3uSu7j37tGR9J012cy7nHHsrU3PHcfu3bc88Vb0hdo5uNAgBPrbfRE+Dsnth5YT593U/nwkfvznc9+Omce+zBpNYMur0MSjclNd3+QpKShYmpfOmyv58DF74kc9t2bfTUAeBZSVhtcoNOLw9f8KI8fMGLsuPU4ew49Vh2nnwkE4tnUjvdPDF9fk5O782JHedn0PFyAsBG8i/xGDk5vTcnp/fm0L4rN3oqAMBTcBEOAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANCKsAAAaKbXW9dtZKeu3MwCA0dxaa71hmA16azWTs3nXu4+v9y7Xzc3vmdny6ztw/MBGT2NNzM7Mbtm1JdY37qxvfG3ltSXPjvUNy6lAAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGhBUAQCPCCgCgEWEFANCIsAIAaERYAQA0IqwAABoRVgAAjQgrAIBGRgqrUsobSyn3lVK+Ukp5d6tJAQCMo1WHVSmlm+T/SvJfJLkmyY+WUq5pNTEAgHEzyhGrlyX5Sq31/lrrfJJ/n+QtbaYFADB+Rgmr2SQPfsvHDy1/DgDgWanUWle3YSlvT/KGWuvPLH/8k0leVmv9uW/7upuS3LT84QuT3Ln66bLB9iV5bKMnwap47cab1298ee3G25W11l3DbNAbYWcPJbn0Wz6+JMnD3/5FtdZbktySJKWUz9Vabxhhn2wgr9/48tqNN6/f+PLajbdSyueG3WaUU4GfTfL8Usp3lVImk7wjyYdGGA8AYKyt+ohVrXWxlPLfJvmTJN0kv1VrvavZzAAAxswopwJTa/1Yko8Nsckto+yPDef1G19eu/Hm9RtfXrvxNvTrt+qL1wEA+M95pA0AQCPrElYefTO+SimXllL+vJRyTynlrlLKz2/0nBhOKaVbSrm9lPKRjZ4LwymlnFtKeX8p5d7l78FXbPScWLlSyr9Y/nvzzlLK75dSpjZ6TpxdKeW3SimHSil3fsvn9pRSPlFK+fLyz7ufaZw1DyuPvhl7i0n+Za316iQvT/LfeP3Gzs8nuWejJ8Gq/FqSj9dar0ry4ngdx0YpZTbJP09yQ631hVl6k9c7NnZWPIP3JXnjt33u3Uk+WWt9fpJPLn/8tNbjiJVH34yxWuvBWutty79+Ikt/sbvD/pgopVyS5E1JfmOj58JwSikzSV6Z5DeTpNY6X2s9uqGTYli9JNtLKb0k03mKez2yedRa/zLJkW/79FuS/Pbyr387yQ8/0zjrEVYefbNFlFIuS/KSJJ/Z4Kmwcr+a5BeSDDZ4Hgzv8iSPJnnv8qnc3yil7NjoSbEytdYDSf51kgeSHExyrNb6pxs7K1bhglrrwWTpQEOS859pg/UIq/IUn/NWxDFTStmZ5D8k+e9qrcc3ej48s1LKm5McqrXeutFzYVV6Sa5L8m9qrS9JcjIrOA3B5rB8Lc5bknxXkouT7Cil/MTGzor1sB5htaJH37B5lVImshRVv1tr/cBGz4cVuzHJD5VSvpalU/CvLqX8zsZOiSE8lOShWuuTR4jfn6XQYjy8Nsn+WuujtdaFJB9I8r0bPCeG90gp5aIkWf750DNtsB5h5dE3Y6yUUrJ0jcc9tdabN3o+rFyt9RdrrZfUWi/L0vfdn9Va/R/zmKi1fiPJg6WUK5c/9Zokd2/glBjOA0leXkqZXv579DXx5oNx9KEk71z+9TuTfPCZNhjpzusr4dE3Y+/GJD+Z5IullM8vf+6Xlu+6D6ytn0vyu8v/U3p/kp/a4PmwQrXWz5RS3p/ktiy9u/r2uAv7plZK+f0kr0qyr5TyUJJfTvKeJH9YSvnpLMXy259xHHdeBwBow53XAQAaEVYAAI0IKwCARoQVAEAjwgoAoBFhBQDQiLACAGhEWAEANPL/A9M/aUHtMwUEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = Path[0]\n",
    "\n",
    "### plot the path on 'q0'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "        \n",
    "for i in range(len(path)):\n",
    "    if path[i][1]<=0:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        \n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5964e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot the path on 'q1'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "\n",
    "ii=i\n",
    "for i in range(ii, len(path)):\n",
    "    if path[i][1]==1:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6c7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot again the path on 'q0'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "\n",
    "ii=i\n",
    "for i in range(ii, len(path)):\n",
    "    if path[i][1]<=0:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee4946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
