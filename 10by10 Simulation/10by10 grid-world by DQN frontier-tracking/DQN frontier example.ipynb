{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5f1fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<csrl.oaa.oaa at 0x1e53b55fa60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: 0\n",
      "Transition function: [\n",
      "  {(): 0, ('a',): 1, ('b',): 0, ('c',): 2, ('a', 'b'): 0, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2},\n",
      "  {(): 1, ('a',): 1, ('b',): 0, ('c',): 2, ('a', 'b'): 0, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2},\n",
      "  {(): 2, ('a',): 2, ('b',): 2, ('c',): 2, ('a', 'b'): 2, ('a', 'c'): 2, ('b', 'c'): 2, ('a', 'b', 'c'): 2}\n",
      "]\n",
      "Acceptance: [\n",
      "  {(): [None], ('a',): [True], ('b',): [True], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]},\n",
      "  {(): [None], ('a',): [True], ('b',): [True], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]},\n",
      "  {(): [None], ('a',): [None], ('b',): [None], ('c',): [None], ('a', 'b'): [None], ('a', 'c'): [None], ('b', 'c'): [None], ('a', 'b', 'c'): [None]}\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import manually defined automata\n",
    "%matplotlib inline\n",
    "from csrl.pomdp import GridPOMDP\n",
    "from csrl.oaa import oaa\n",
    "from csrl import ControlSynthesis\n",
    "import numpy as np \n",
    "\n",
    "oa=oaa()\n",
    "\n",
    "# LTL Specification\n",
    "#ltl = '(GFa & GFb) & G!c' ### goes to 'a', 'b' recurrently, gallobly ! c\n",
    "\n",
    "# Translate the LTL formula to an LDBA\n",
    "print('Number of Omega-automaton states (including the trap state):',oa.shape[1])\n",
    "display(oa)\n",
    "\n",
    "print('Initial state:',oa.q0)\n",
    "print('Transition function: ['),print(*['  '+str(t) for t in oa.delta],sep=',\\n'),print(']')\n",
    "print('Acceptance: ['),print(*['  '+str(t) for t in oa.acc],sep=',\\n'),print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e69f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNCHA~1\\AppData\\Local\\Temp/ipykernel_836/3991470510.py:29: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ],dtype=np.object)\n"
     ]
    }
   ],
   "source": [
    "# POMDP Description\n",
    "shape = (10,10)\n",
    "# E: Empty, T: Trap, B: Obstacle\n",
    "structure = np.array([\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E']\n",
    "])\n",
    "\n",
    "# Labels of the states\n",
    "label = np.array([\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       ('c',),       ('c',),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       ('c',),       ('c',),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       ('c',),       ('c',),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       ('c',),       ('c',),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()]\n",
    "],dtype=np.object)\n",
    "\n",
    "grid_pomdp = GridPOMDP(shape=shape,structure=structure,label=label) \n",
    "\n",
    "# Construct the product POMDP\n",
    "csrl = ControlSynthesis(grid_pomdp,oa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33501f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "         [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]],\n",
       "\n",
       "        [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "        [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.belief_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c331dd23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]],\n",
       "\n",
       "        [[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]],\n",
       "\n",
       "        [[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]]]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfafe01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc59fe3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 17.39991945028305\n",
      "episode: 5/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 6/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 7/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.95004653930664\n",
      "episode: 8/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 9/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.026213109493255615\n",
      "episode: 10/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 11/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 12/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 13/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 14/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 15/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 19.967758178710938\n",
      "episode: 16/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.820518851280212\n",
      "episode: 17/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 18/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.30042099952697754\n",
      "episode: 19/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.010307967662811\n",
      "episode: 20/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 21/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 22/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 23/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.021842241287231445\n",
      "episode: 24/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 25/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 26/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 27/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 28/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 29/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 30/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.90625\n",
      "episode: 31/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976564407348633\n",
      "episode: 32/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 33/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 34/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 35/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 36/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 37/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5137601494789124\n",
      "episode: 38/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 39/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 40/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 41/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0006771683692932129\n",
      "episode: 42/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.979011535644531\n",
      "episode: 43/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 44/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 45/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 46/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.26405060291290283\n",
      "episode: 47/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1403010487556458\n",
      "episode: 48/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 49/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.965873897075653\n",
      "episode: 50/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 51/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.022615432739257812\n",
      "episode: 52/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 53/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.706099033355713\n",
      "episode: 54/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.288818359375e-05\n",
      "episode: 55/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890626072883606\n",
      "episode: 56/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.028030812740326\n",
      "episode: 57/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 58/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 59/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 60/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656399011612\n",
      "episode: 61/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.008111000061035156\n",
      "episode: 62/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.20866018533706665\n",
      "episode: 63/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 64/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.795557379722595\n",
      "episode: 65/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 66/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00666046142578125\n",
      "episode: 67/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 68/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 69/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 70/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.15773046016693115\n",
      "episode: 71/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 72/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 73/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0078108906745910645\n",
      "episode: 74/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989477574825287\n",
      "episode: 75/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 76/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.605506896972656\n",
      "episode: 77/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.011356353759766\n",
      "episode: 78/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 79/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.034698605537415\n",
      "episode: 80/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 81/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 82/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 83/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 84/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 85/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 86/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.184638142585754\n",
      "episode: 87/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.3113021850585938e-06\n",
      "episode: 88/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 89/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 90/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 91/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.031803131103515625\n",
      "episode: 92/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 93/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 94/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 95/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00700908899307251\n",
      "episode: 96/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 97/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.155050694942474\n",
      "episode: 98/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 99/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 100/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 101/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996346056461334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 102/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.991597712039948\n",
      "episode: 103/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.616104543209076\n",
      "episode: 104/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.121724367141724\n",
      "episode: 105/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0009049177169799805\n",
      "episode: 106/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 107/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 108/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976727724075317\n",
      "episode: 109/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 110/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015851497650146484\n",
      "episode: 111/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 112/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 113/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 114/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00014477968215942383\n",
      "episode: 115/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0005577802658081055\n",
      "episode: 116/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 117/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 118/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 119/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 120/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988949000835419\n",
      "episode: 121/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 122/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 123/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 124/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.2047837376594543\n",
      "episode: 125/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992847800254822\n",
      "episode: 126/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.2557716369628906e-05\n",
      "episode: 127/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976840257644653\n",
      "episode: 128/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 129/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 130/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.093575537204742\n",
      "episode: 131/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 132/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 133/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.2610015869140625\n",
      "episode: 134/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.866983413696289e-05\n",
      "episode: 135/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 136/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0068206787109375\n",
      "episode: 137/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 138/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97048568725586\n",
      "episode: 139/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 17.207996904850006\n",
      "episode: 140/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 141/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 142/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 143/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.285528421401978\n",
      "episode: 144/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 145/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.819775760173798\n",
      "episode: 146/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 147/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 148/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 149/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.33198595046997\n",
      "episode: 150/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.1299729347229\n",
      "episode: 151/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 152/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 153/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.028175175189971924\n",
      "episode: 154/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 155/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 156/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 157/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 158/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0238037109375\n",
      "episode: 159/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 160/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.000587463378906\n",
      "episode: 161/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.23312222957611\n",
      "episode: 162/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 4.76837158203125e-07\n",
      "episode: 163/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 164/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 165/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 166/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 167/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 168/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 169/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.783591330051422\n",
      "episode: 170/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 171/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 172/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.3561277985572815\n",
      "episode: 173/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.900390625\n",
      "episode: 174/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.175729274749756\n",
      "episode: 175/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.965354919433594\n",
      "episode: 176/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9610421657562256\n",
      "episode: 177/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 13.819178521633148\n",
      "episode: 178/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.006930053234100342\n",
      "episode: 179/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 180/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 181/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 182/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.13085007667541504\n",
      "episode: 183/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 184/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 185/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.00897216796875\n",
      "episode: 186/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 187/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.551948428153992\n",
      "episode: 188/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 189/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 190/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 191/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976562738418579\n",
      "episode: 192/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 193/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.3388748168945312\n",
      "episode: 194/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 195/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.982734680175781\n",
      "episode: 196/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 197/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 198/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 199/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 200/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976879596710205\n",
      "episode: 201/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 202/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 203/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.1113624572753906e-05\n",
      "episode: 204/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 205/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 13.705199778079987\n",
      "episode: 206/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.109240233898163\n",
      "episode: 207/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 208/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 209/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 210/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 211/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 212/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 213/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 214/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.463062286376953\n",
      "episode: 215/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.198777556419373\n",
      "episode: 216/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 217/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 218/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 219/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 220/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 221/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 222/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.624485075473785\n",
      "episode: 223/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 224/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 225/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 226/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 227/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 228/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 15.724180221557617\n",
      "episode: 229/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.033731698989868164\n",
      "episode: 230/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 231/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 232/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00443267822265625\n",
      "episode: 233/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.1163503527641296\n",
      "episode: 234/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 235/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 236/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.05771791934967\n",
      "episode: 237/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 238/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0033559799194335938\n",
      "episode: 239/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 240/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.93581622838974\n",
      "episode: 241/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 242/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 243/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988984823226929\n",
      "episode: 244/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 245/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 246/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.003337860107421875\n",
      "episode: 247/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.985257506370544\n",
      "episode: 248/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.011607706546783447\n",
      "episode: 249/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 250/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0017552375793457031\n",
      "episode: 251/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 252/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 253/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 254/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.06389254331588745\n",
      "episode: 255/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 256/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0622103214263916\n",
      "episode: 257/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 258/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 259/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 260/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996800780296326\n",
      "episode: 261/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984266519546509\n",
      "episode: 262/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976880073547363\n",
      "episode: 263/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 264/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 265/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.28706681728363\n",
      "episode: 266/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 267/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 268/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996749877929688\n",
      "episode: 269/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 270/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.469318628311157\n",
      "episode: 271/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 272/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 273/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 274/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0006052851676940918\n",
      "episode: 275/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 276/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 277/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 278/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.99620795249939\n",
      "episode: 279/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 280/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 281/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 282/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 283/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 284/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 285/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 286/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 287/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 288/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.031414031982421875\n",
      "episode: 289/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 290/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 291/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 292/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.328126907348633e-05\n",
      "episode: 293/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 294/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.985748589038849\n",
      "episode: 295/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.675781726837158\n",
      "episode: 296/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 297/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.62409520149231\n",
      "episode: 298/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 299/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.18442153930664\n",
      "episode: 300/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 301/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 302/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0003489851951599121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 303/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.915678977966309\n",
      "episode: 304/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 305/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.468994140625\n",
      "episode: 306/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 307/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.8671875\n",
      "episode: 308/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.99705684185028\n",
      "episode: 309/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 310/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.458558559417725\n",
      "episode: 311/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 312/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 313/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 314/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 315/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 316/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 317/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.27685546875\n",
      "episode: 318/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989300012588501\n",
      "episode: 319/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1324882507324219e-06\n",
      "episode: 320/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 321/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 322/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984760582447052\n",
      "episode: 323/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 324/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 325/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 326/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 327/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 328/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 329/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 330/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 331/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 332/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.004642486572266\n",
      "episode: 333/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 334/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 335/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 336/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.129852294921875\n",
      "episode: 337/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 338/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.991941213607788\n",
      "episode: 339/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007882118225097656\n",
      "episode: 340/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.98899108171463\n",
      "episode: 341/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 342/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 6.924019932746887\n",
      "episode: 343/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 344/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 345/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989263236522675\n",
      "episode: 346/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 347/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 348/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.9852455854415894\n",
      "episode: 349/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 350/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 351/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007804512977600098\n",
      "episode: 352/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 353/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97655701637268\n",
      "episode: 354/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.03364819288253784\n",
      "episode: 355/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 356/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 357/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 358/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0116424560546875\n",
      "episode: 359/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 360/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992072701454163\n",
      "episode: 361/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 362/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 363/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 364/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.350393772125244\n",
      "episode: 365/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 366/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 367/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 368/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007987618446350098\n",
      "episode: 369/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.114269495010376\n",
      "episode: 370/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.89761757850647\n",
      "episode: 371/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 372/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 373/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.811256051063538\n",
      "episode: 374/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.020306706428527832\n",
      "episode: 375/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.012595176696777\n",
      "episode: 376/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 377/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.468356668949127\n",
      "episode: 378/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 379/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 380/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 381/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.029580414295196533\n",
      "episode: 382/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 383/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.9802322387695312e-06\n",
      "episode: 384/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 385/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 386/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.836044609546661\n",
      "episode: 387/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.999077081680298\n",
      "episode: 388/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 389/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0015707015991210938\n",
      "episode: 390/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 391/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976796507835388\n",
      "episode: 392/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976840257644653\n",
      "episode: 393/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.78125149011612\n",
      "episode: 394/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.469820022583008e-05\n",
      "episode: 395/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 396/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 397/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 398/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 399/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 400/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 401/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.024832725524902344\n",
      "episode: 402/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 403/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 404/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0234447717666626\n",
      "episode: 405/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 406/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.4824981689453125\n",
      "episode: 407/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.982498347759247\n",
      "episode: 408/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 409/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 410/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 411/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0003807544708251953\n",
      "episode: 412/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 413/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.001647233963013\n",
      "episode: 414/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 415/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996580481529236\n",
      "episode: 416/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.492447853088379\n",
      "episode: 417/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 418/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.157852530479431\n",
      "episode: 419/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0672616958618164\n",
      "episode: 420/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 421/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.025838851928710938\n",
      "episode: 422/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 423/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.3653181791305542\n",
      "episode: 424/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984545767307281\n",
      "episode: 425/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0008141994476318359\n",
      "episode: 426/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.005925595760345459\n",
      "episode: 427/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 428/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 429/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 22.79491662979126\n",
      "episode: 430/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 431/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 432/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 433/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 434/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 435/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.92979633808136\n",
      "episode: 436/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 437/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 438/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 439/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.523353636264801\n",
      "episode: 440/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 441/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.499934196472168\n",
      "episode: 442/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 443/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 444/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 445/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 446/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.02038741111755371\n",
      "episode: 447/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 448/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 449/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.03686708211898804\n",
      "episode: 450/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 451/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 452/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 453/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.129150390625\n",
      "episode: 454/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 455/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.84912109375\n",
      "episode: 456/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 457/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 458/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 459/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015706121921539307\n",
      "episode: 460/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 461/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 462/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.151236176490784\n",
      "episode: 463/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0746622085571289\n",
      "episode: 464/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.102203369140625\n",
      "episode: 465/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.746106624603271\n",
      "episode: 466/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 467/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976671040058136\n",
      "episode: 468/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 6.08984375\n",
      "episode: 469/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 470/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.34819746017456055\n",
      "episode: 471/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 472/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 473/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 474/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 475/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 476/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 477/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 478/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 479/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.009299457073212\n",
      "episode: 480/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.198505163192749\n",
      "episode: 481/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.164296507835388\n",
      "episode: 482/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 483/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.154750883579254\n",
      "episode: 484/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 485/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 486/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 487/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 488/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 489/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 490/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 491/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 492/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 493/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 494/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.003976345062255859\n",
      "episode: 495/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 496/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 497/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.49078094959259\n",
      "episode: 498/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.171875\n",
      "episode: 499/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007737159729003906\n",
      "episode: 500/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 501/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 502/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 503/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.1507638692855835\n",
      "episode: 504/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.874301910400391e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 505/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 506/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 507/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012424826622009277\n",
      "episode: 508/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 509/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 510/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 511/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 512/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 513/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.12521755695343\n",
      "episode: 514/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 515/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.101323544979095\n",
      "episode: 516/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.757813930511475\n",
      "episode: 517/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 518/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 519/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.738040924072266e-05\n",
      "episode: 520/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 521/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 522/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 523/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 524/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 525/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 526/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5264356136322021\n",
      "episode: 527/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 528/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.002212822437286\n",
      "episode: 529/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.000002205371857\n",
      "episode: 530/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 531/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0046479105949401855\n",
      "episode: 532/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 533/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 534/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 535/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.4330120086669922\n",
      "episode: 536/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 537/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 538/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 539/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 540/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.340363144874573\n",
      "episode: 541/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 542/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 543/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 544/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.461042761802673\n",
      "episode: 545/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 546/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 547/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 548/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 549/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 550/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012040972709655762\n",
      "episode: 551/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 552/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.961813509464264\n",
      "episode: 553/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 554/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 555/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 556/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.0067901611328125e-06\n",
      "episode: 557/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 558/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 559/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976671874523163\n",
      "episode: 560/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 561/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 562/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.499346911907196\n",
      "episode: 563/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.300782799720764\n",
      "episode: 564/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539062e-07\n",
      "episode: 565/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 566/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.980900943279266\n",
      "episode: 567/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 568/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 569/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 570/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 571/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 572/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 573/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 574/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 575/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 576/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 577/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 578/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 579/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.01904296875\n",
      "episode: 580/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.2516975402832031e-06\n",
      "episode: 581/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.02036863565445\n",
      "episode: 582/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 583/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 584/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.018135249614716\n",
      "episode: 585/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 586/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 587/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 588/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.988983273506165\n",
      "episode: 589/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 590/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 591/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 592/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.40614128112793e-05\n",
      "episode: 593/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 594/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 595/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 596/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 597/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.953127264976501\n",
      "episode: 598/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 599/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.27787715196609497\n",
      "episode: 600/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 601/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 602/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976776361465454\n",
      "episode: 603/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 604/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 605/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.001316368579864502\n",
      "episode: 606/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 607/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.7022043466567993\n",
      "episode: 608/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.351331770420074\n",
      "episode: 609/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 610/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 5.257129669189453e-05\n",
      "episode: 611/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 612/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 613/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.715883612632751\n",
      "episode: 614/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.197149276733398\n",
      "episode: 615/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 616/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 617/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 618/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.031784057617188\n",
      "episode: 619/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 620/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.110854029655457\n",
      "episode: 621/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 21.810546875\n",
      "episode: 622/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.484375\n",
      "episode: 623/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 624/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.012595176696777344\n",
      "episode: 625/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.0444393157958984e-05\n",
      "episode: 626/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 627/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976840496063232\n",
      "episode: 628/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 629/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 630/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 631/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.656444549560547\n",
      "episode: 632/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.31876522302627563\n",
      "episode: 633/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 634/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 635/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.106460630893707\n",
      "episode: 636/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989163875579834\n",
      "episode: 637/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976880133152008\n",
      "episode: 638/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 18.75\n",
      "episode: 639/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.10621333122253418\n",
      "episode: 640/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 641/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.15251886844635\n",
      "episode: 642/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 643/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 644/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 13.328760802745819\n",
      "episode: 645/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.324539184570312\n",
      "episode: 646/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 647/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 648/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 649/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.996921956539154\n",
      "episode: 650/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 651/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 652/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 653/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.006178081035614014\n",
      "episode: 654/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 655/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 656/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 657/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 658/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 659/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.99132752418518\n",
      "episode: 660/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 661/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 662/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 663/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 664/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 665/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0003255009651184082\n",
      "episode: 666/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 667/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 668/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0019197463989257812\n",
      "episode: 669/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 17.15917205810547\n",
      "episode: 670/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 671/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 672/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 673/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.977510452270508\n",
      "episode: 674/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 675/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 676/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.978552281856537\n",
      "episode: 677/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 678/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 679/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 680/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 681/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 682/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.984404444694519\n",
      "episode: 683/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 684/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 685/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.900390625\n",
      "episode: 686/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0004286766052246094\n",
      "episode: 687/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0002728700637817383\n",
      "episode: 688/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 689/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 690/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 691/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 692/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 693/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.9200059771537781\n",
      "episode: 694/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.890665471553802\n",
      "episode: 695/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.894330561161041\n",
      "episode: 696/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 697/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 698/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00046443939208984375\n",
      "episode: 699/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 700/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.052032470703125\n",
      "episode: 701/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 702/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 703/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 704/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 705/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 706/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 707/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 708/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.386752605438232\n",
      "episode: 709/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 710/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 711/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 712/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 713/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 714/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 715/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 716/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976978540420532\n",
      "episode: 717/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 718/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 719/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 720/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 721/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 722/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 723/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.1435422897338867\n",
      "episode: 724/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 725/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.12486523389816284\n",
      "episode: 726/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 727/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.777832269668579\n",
      "episode: 728/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 729/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 730/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 731/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 732/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.157132625579834\n",
      "episode: 733/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.990505754947662\n",
      "episode: 734/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 735/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 736/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.088577270507812\n",
      "episode: 737/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.355727970600128\n",
      "episode: 738/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 739/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0002060532569885254\n",
      "episode: 740/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 741/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.546875059604645\n",
      "episode: 742/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.017737805843353\n",
      "episode: 743/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 744/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.19068259000778198\n",
      "episode: 745/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 746/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 747/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 748/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.009803235530853\n",
      "episode: 749/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 750/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 751/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 8.575920462608337\n",
      "episode: 752/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 3.51792174577713\n",
      "episode: 753/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 754/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 755/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 756/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.007663726806640625\n",
      "episode: 757/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 758/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 759/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 760/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 761/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 762/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 763/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 764/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 765/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 766/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 767/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 768/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.186663627624512\n",
      "episode: 769/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.51220703125\n",
      "episode: 770/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 771/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 772/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.305469989776611\n",
      "episode: 773/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 774/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 775/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 776/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 777/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00010848045349121094\n",
      "episode: 778/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0048326849937438965\n",
      "episode: 779/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 780/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 781/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 782/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0007012486457824707\n",
      "episode: 783/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 784/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0002598762512207031\n",
      "episode: 785/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 786/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 787/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.01251220703125\n",
      "episode: 788/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 789/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 790/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 791/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 792/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.813873291015625\n",
      "episode: 793/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 794/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 795/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 796/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 797/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 798/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.000106930732727\n",
      "episode: 799/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 800/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 801/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 12.759827733039856\n",
      "episode: 802/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 803/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.97667384147644\n",
      "episode: 804/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 805/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.922148704528809\n",
      "episode: 806/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.006821155548095703\n",
      "episode: 807/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.555851519107819\n",
      "episode: 808/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 809/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 810/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 811/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.8542962074279785\n",
      "episode: 812/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 813/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 814/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 815/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 816/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.020018696784973145\n",
      "episode: 817/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 818/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.992080330848694\n",
      "episode: 819/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 820/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.95004653930664\n",
      "episode: 821/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 822/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 823/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.308980941772461\n",
      "episode: 824/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.929796397686005\n",
      "episode: 825/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 826/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 827/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 11.78442531824112\n",
      "episode: 828/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.989166498184204\n",
      "episode: 829/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 830/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.134395241737366\n",
      "episode: 831/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.00019407272338867188\n",
      "episode: 832/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.015681922435760498\n",
      "episode: 833/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 834/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 835/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 836/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 837/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.39453125\n",
      "episode: 838/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 839/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.97794246673584\n",
      "episode: 840/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.320179283618927\n",
      "episode: 841/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 842/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 843/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.207000732421875\n",
      "episode: 844/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 845/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 846/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 1.5497207641601562e-06\n",
      "episode: 847/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 848/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.327560424804688\n",
      "episode: 849/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 10.142227530479431\n",
      "episode: 850/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.995857238769531\n",
      "episode: 851/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 852/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 853/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.968856871128082\n",
      "episode: 854/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 855/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 856/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.533219158649445\n",
      "episode: 857/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 7.450580596923828e-06\n",
      "episode: 858/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 859/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 860/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 861/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 862/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 863/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.5674015879631042\n",
      "episode: 864/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.994998574256897\n",
      "episode: 865/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 866/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 867/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.47657823562622\n",
      "episode: 868/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 869/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.971546173095703\n",
      "episode: 870/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 871/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 872/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 873/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 874/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 875/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 876/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.48193359375\n",
      "episode: 877/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 878/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 879/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 880/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 881/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 9.993827104568481\n",
      "episode: 882/6000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-05\n",
      "episode: 883/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.016357779502868652\n",
      "episode: 884/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 885/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 886/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 887/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 888/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 889/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.073066890239716\n",
      "episode: 890/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 891/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.022790610790252686\n",
      "episode: 892/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.8437931537628174\n",
      "episode: 893/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 894/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 895/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.929688930511475\n",
      "episode: 896/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 897/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.028440237045288\n",
      "episode: 898/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 899/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.978403091430664\n",
      "episode: 900/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 901/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 902/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 903/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 904/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 905/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 906/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.030616283416748047\n",
      "episode: 907/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 908/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 909/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 910/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 911/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 912/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 913/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 914/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.311874389648438\n",
      "episode: 915/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00010925531387329102\n",
      "episode: 916/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 917/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.259820461273193\n",
      "episode: 918/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 18.31689453125\n",
      "episode: 919/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 920/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 921/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 922/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 923/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 924/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 925/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0017583966255187988\n",
      "episode: 926/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976671755313873\n",
      "episode: 927/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 928/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.010795593261719\n",
      "episode: 929/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 930/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 931/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 932/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.988289058208466\n",
      "episode: 933/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.18350201845169067\n",
      "episode: 934/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0001093745231628418\n",
      "episode: 935/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 936/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 937/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 938/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.985664367675781e-05\n",
      "episode: 939/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 940/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.02399343252182007\n",
      "episode: 941/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 942/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.996179163455963\n",
      "episode: 943/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 944/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 945/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0042879581451416016\n",
      "episode: 946/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.335705637931824\n",
      "episode: 947/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 948/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976779520511627\n",
      "episode: 949/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.337860107421875e-06\n",
      "episode: 950/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 951/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 952/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00773012638092041\n",
      "episode: 953/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 954/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 955/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.98651385307312\n",
      "episode: 956/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 957/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.2516975402832031e-05\n",
      "episode: 958/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 4.0590763092041016e-05\n",
      "episode: 959/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 960/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 961/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 962/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 963/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 964/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.028075754642486572\n",
      "episode: 965/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 966/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.067516326904297\n",
      "episode: 967/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 968/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 969/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.279594659805298\n",
      "episode: 970/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 971/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.92198395729065\n",
      "episode: 972/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.99090963602066\n",
      "episode: 973/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 974/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007983565330505371\n",
      "episode: 975/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 976/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984821677207947\n",
      "episode: 977/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.370292663574219\n",
      "episode: 978/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.33252859115600586\n",
      "episode: 979/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.001645565032959\n",
      "episode: 980/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 981/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.196502685546875\n",
      "episode: 982/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.012713372707366943\n",
      "episode: 983/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 984/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 985/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.593619108200073\n",
      "episode: 986/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 987/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 988/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.042343139648438\n",
      "episode: 989/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 990/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 991/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 992/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.059741795063019\n",
      "episode: 993/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-06\n",
      "episode: 994/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 19.71875\n",
      "episode: 995/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.914336681365967\n",
      "episode: 996/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 997/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 998/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.060189962387085\n",
      "episode: 999/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1000/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1001/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1002/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1003/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.13966941833496094\n",
      "episode: 1004/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1005/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.83642578125\n",
      "episode: 1006/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1007/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984423696994781\n",
      "episode: 1008/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1009/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1010/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1011/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1012/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1013/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1014/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.006820678710938\n",
      "episode: 1015/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.9767844676971436\n",
      "episode: 1016/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1017/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1018/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1019/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.794929504394531e-06\n",
      "episode: 1020/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1021/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1022/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1023/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1024/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1025/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1026/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1027/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.484377264976501\n",
      "episode: 1028/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1029/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.0763590335845947\n",
      "episode: 1030/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1031/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1032/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00018638372421264648\n",
      "episode: 1033/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 1034/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.997675001621246\n",
      "episode: 1035/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1036/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1037/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1038/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1039/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1040/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 1041/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1042/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1043/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1044/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1045/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.13259732723236\n",
      "episode: 1046/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.13148736953735352\n",
      "episode: 1047/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.055080473423004\n",
      "episode: 1048/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1049/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1050/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1051/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.978134214878082\n",
      "episode: 1052/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0032470226287841797\n",
      "episode: 1053/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.0203638672828674\n",
      "episode: 1054/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1055/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1056/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 1057/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 19.995980739593506\n",
      "episode: 1058/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1059/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97656637430191\n",
      "episode: 1060/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1061/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00779879093170166\n",
      "episode: 1062/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.7001953125\n",
      "episode: 1063/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.7265625\n",
      "episode: 1064/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1065/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1066/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1067/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.476563930511475\n",
      "episode: 1068/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1069/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1070/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1071/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1072/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1073/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1074/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1075/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1076/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1077/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.990797996520996\n",
      "episode: 1078/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.98926454782486\n",
      "episode: 1079/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.992473185062408\n",
      "episode: 1080/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1081/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1082/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.034631729125977\n",
      "episode: 1083/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1084/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.175537109375\n",
      "episode: 1085/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.03497314453125\n",
      "episode: 1086/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1087/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.01706087589264\n",
      "episode: 1088/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1089/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1090/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1091/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 6.820247054100037\n",
      "episode: 1092/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1093/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1094/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 23.316455245018005\n",
      "episode: 1095/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1096/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1097/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1098/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1099/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.129852294921875\n",
      "episode: 1100/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.000107109546661\n",
      "episode: 1101/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.018888235092163086\n",
      "episode: 1102/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007701873779296875\n",
      "episode: 1103/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.341903686523438\n",
      "episode: 1104/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.17187511920929\n",
      "episode: 1105/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1106/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.856257677078247\n",
      "episode: 1107/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1108/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.255083680152893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1109/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1110/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1111/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.009101867675781\n",
      "episode: 1112/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1113/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.11904925107956\n",
      "episode: 1114/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1115/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1116/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1117/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1118/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1119/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0019420385360717773\n",
      "episode: 1120/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1121/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1122/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976953148841858\n",
      "episode: 1123/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1124/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1125/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00015968084335327148\n",
      "episode: 1126/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.18225258588790894\n",
      "episode: 1127/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1128/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.888748466968536\n",
      "episode: 1129/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1130/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00797337293624878\n",
      "episode: 1131/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1132/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1133/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.161446988582611\n",
      "episode: 1134/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 1135/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1136/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1137/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.988845825195312\n",
      "episode: 1138/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1139/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.101886630058289\n",
      "episode: 1140/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.035003066062927\n",
      "episode: 1141/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1142/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1143/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.832967221736908\n",
      "episode: 1144/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1145/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.140631139278412\n",
      "episode: 1146/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1147/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1148/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1149/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1150/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1151/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1152/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1153/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1154/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0019205212593078613\n",
      "episode: 1155/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.000095069408417\n",
      "episode: 1156/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1157/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1158/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1159/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1160/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1161/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1162/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1163/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.687508285045624\n",
      "episode: 1164/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.682209014892578e-06\n",
      "episode: 1165/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1166/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1167/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.34765625\n",
      "episode: 1168/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007764577865600586\n",
      "episode: 1169/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1170/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 1171/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1172/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.08943462371826172\n",
      "episode: 1173/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1174/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1175/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007788121700286865\n",
      "episode: 1176/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1177/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 1178/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.6093254089355469e-06\n",
      "episode: 1179/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.0967254638671875e-05\n",
      "episode: 1180/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.562999725341797e-06\n",
      "episode: 1181/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.978553712368011\n",
      "episode: 1182/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976566314697266\n",
      "episode: 1183/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1184/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1185/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1186/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1187/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.109267771244049\n",
      "episode: 1188/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1189/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1190/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1191/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1192/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1193/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1194/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.928775787353516e-05\n",
      "episode: 1195/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1196/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1197/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.978552281856537\n",
      "episode: 1198/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 1199/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1200/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1201/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.992360055446625\n",
      "episode: 1202/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.03250342607498169\n",
      "episode: 1203/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.021958708763123\n",
      "episode: 1204/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1205/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1206/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1207/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.14123821258544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1208/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1209/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1210/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1211/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1212/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1213/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1214/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 1215/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 1216/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1217/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1218/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1219/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.71103036403656\n",
      "episode: 1220/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1221/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00038123130798339844\n",
      "episode: 1222/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.276968598365784\n",
      "episode: 1223/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1224/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984436810016632\n",
      "episode: 1225/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1226/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00010859966278076172\n",
      "episode: 1227/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1228/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.317142486572266\n",
      "episode: 1229/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1230/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1231/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1232/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 1233/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 18.032318115234375\n",
      "episode: 1234/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.562999725341797e-06\n",
      "episode: 1235/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1236/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.16847991943359375\n",
      "episode: 1237/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1238/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 30.80300724506378\n",
      "episode: 1239/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1240/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.78125\n",
      "episode: 1241/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.344903230667114\n",
      "episode: 1242/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1243/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1244/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1245/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.006583034992218018\n",
      "episode: 1246/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.659248352050781\n",
      "episode: 1247/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1248/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.527358412742615\n",
      "episode: 1249/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.8167441487312317\n",
      "episode: 1250/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1251/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1252/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1253/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1254/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1255/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1256/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 1257/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.467086791992188\n",
      "episode: 1258/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.01242971420288086\n",
      "episode: 1259/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1260/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.313290119171143\n",
      "episode: 1261/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.009376585483551\n",
      "episode: 1262/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1263/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1264/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1265/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1266/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.183436274528503\n",
      "episode: 1267/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1268/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1269/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.03241628408432007\n",
      "episode: 1270/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 12.80058354139328\n",
      "episode: 1271/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1272/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 1273/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.552527666091919\n",
      "episode: 1274/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1275/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007709503173828125\n",
      "episode: 1276/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1277/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1278/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1279/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.0002760887146\n",
      "episode: 1280/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1281/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1282/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1283/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 1284/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1285/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.855974912643433\n",
      "episode: 1286/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.976879596710205\n",
      "episode: 1287/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1288/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 7.957385838031769\n",
      "episode: 1289/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 11.143603920936584\n",
      "episode: 1290/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 1.3887882232666016e-05\n",
      "episode: 1291/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1292/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1293/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.91885530948639\n",
      "episode: 1294/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1295/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1296/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.04092520475387573\n",
      "episode: 1297/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1298/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1299/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1300/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1301/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1302/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1303/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.01714301109314\n",
      "episode: 1304/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.02135235071182251\n",
      "episode: 1305/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1306/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 1307/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1308/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1309/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1310/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.984703063964844\n",
      "episode: 1311/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 3.1937427520751953\n",
      "episode: 1312/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1313/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1314/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1315/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1316/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1317/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1318/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 12.449190139770508\n",
      "episode: 1319/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.97704154253006\n",
      "episode: 1320/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.32088470458984375\n",
      "episode: 1321/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1322/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1323/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.977016687393188\n",
      "episode: 1324/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 9.922092616558075\n",
      "episode: 1325/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.007979393005371094\n",
      "episode: 1326/6000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 0.00828409194946289\n",
      "episode: 1327/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1328/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1329/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 7.996095240116119\n",
      "episode: 1330/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1331/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0004299283027648926\n",
      "episode: 1332/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 1333/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.989150524139404\n",
      "episode: 1334/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.487556457519531\n",
      "episode: 1335/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1336/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1337/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1338/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1339/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.03567886352539\n",
      "episode: 1340/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.649991989135742e-05\n",
      "episode: 1341/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1342/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1343/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1344/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.74755859375\n",
      "episode: 1345/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1346/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1347/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1348/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.276479363441467\n",
      "episode: 1349/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1350/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1351/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1352/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.500343322753906\n",
      "episode: 1353/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 7.185791015625\n",
      "episode: 1354/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1355/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 1356/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1357/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1358/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.2155281901359558\n",
      "episode: 1359/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 5.024095833301544\n",
      "episode: 1360/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1361/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 1362/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1363/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1364/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1365/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1366/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1367/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1368/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.124892771244049\n",
      "episode: 1369/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.976649463176727\n",
      "episode: 1370/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1371/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1372/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.945984542369843\n",
      "episode: 1373/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0001958608627319336\n",
      "episode: 1374/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 13.119990110397339\n",
      "episode: 1375/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.988983392715454\n",
      "episode: 1376/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1377/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.408907651901245\n",
      "episode: 1378/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 4.410743713378906e-06\n",
      "episode: 1379/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.33014690876007\n",
      "episode: 1380/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 12.901159286499023\n",
      "episode: 1381/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.8581658601760864\n",
      "episode: 1382/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1383/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.94531261920929\n",
      "episode: 1384/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 1385/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.988876342773438\n",
      "episode: 1386/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.926981568336487\n",
      "episode: 1387/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.080781280994415\n",
      "episode: 1388/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1389/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1390/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1391/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1392/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1393/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1394/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1395/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.124263763427734\n",
      "episode: 1396/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.012776970863342\n",
      "episode: 1397/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.12485849857330322\n",
      "episode: 1398/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1399/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1400/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1401/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1402/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.4262729287147522\n",
      "episode: 1403/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.284811794757843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1404/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1405/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.000008046627045\n",
      "episode: 1406/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1407/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.03530597686767578\n",
      "episode: 1408/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1409/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.97667384147644\n",
      "episode: 1410/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1411/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.344650268554688e-07\n",
      "episode: 1412/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 1413/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.317154884338379\n",
      "episode: 1414/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.8758277297019958\n",
      "episode: 1415/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.97667372226715\n",
      "episode: 1416/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1417/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1418/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.641843795776367e-05\n",
      "episode: 1419/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1420/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1421/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1422/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1423/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 7.152557373046875e-07\n",
      "episode: 1424/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1425/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.6689300537109375e-06\n",
      "episode: 1426/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.945068359375\n",
      "episode: 1427/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.484375\n",
      "episode: 1428/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1429/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.126853942871094\n",
      "episode: 1430/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 7.142538547515869\n",
      "episode: 1431/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.0003662109375\n",
      "episode: 1432/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1433/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1434/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1435/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1436/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1437/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.167373836040497\n",
      "episode: 1438/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1439/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1440/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1441/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0019197463989257812\n",
      "episode: 1442/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1443/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1444/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.996753752231598\n",
      "episode: 1445/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.253923416137695\n",
      "episode: 1446/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.272125244140625\n",
      "episode: 1447/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1448/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1449/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 1450/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1451/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1452/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 1453/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1454/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1455/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1456/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1457/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1458/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1459/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00010818243026733398\n",
      "episode: 1460/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1461/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 1462/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 19.449069440364838\n",
      "episode: 1463/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.4609375\n",
      "episode: 1464/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1465/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 2.2573757767677307\n",
      "episode: 1466/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1467/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1468/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 12.866323292255402\n",
      "episode: 1469/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1470/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 8.940696716308594e-06\n",
      "episode: 1471/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.013964653015136719\n",
      "episode: 1472/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 5.066394805908203e-06\n",
      "episode: 1473/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.021197497844696045\n",
      "episode: 1474/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1475/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1476/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1477/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1478/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 11.817794382572174\n",
      "episode: 1479/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0316806435585022\n",
      "episode: 1480/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 27.966775715351105\n",
      "episode: 1481/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.4543533325195312e-05\n",
      "episode: 1482/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.302398562431335\n",
      "episode: 1483/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 1484/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.984862983226776\n",
      "episode: 1485/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1486/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.5273444056510925\n",
      "episode: 1487/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1488/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1489/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 6.537094593048096\n",
      "episode: 1490/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 4.921875\n",
      "episode: 1491/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.012929320335388184\n",
      "episode: 1492/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1493/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.12815088033676147\n",
      "episode: 1494/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.00197523832321167\n",
      "episode: 1495/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1496/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1497/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1498/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1499/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1500/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.6954879760742188e-06\n",
      "episode: 1501/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1502/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1503/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1504/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.290895462036133\n",
      "episode: 1505/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.098739624023438\n",
      "episode: 1506/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 3.924591839313507\n",
      "episode: 1507/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1508/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1509/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 6.984811007976532\n",
      "episode: 1510/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1511/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.009976208209991455\n",
      "episode: 1512/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 9.996975839138031\n",
      "episode: 1513/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1514/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1515/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1516/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1517/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1518/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.14987444877624512\n",
      "episode: 1519/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1520/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1521/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.253531098365784\n",
      "episode: 1522/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1523/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1524/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1525/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 11.961242258548737\n",
      "episode: 1526/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0328826904296875\n",
      "episode: 1527/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1528/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1529/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 1.9073486328125e-06\n",
      "episode: 1530/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 10.467751264572144\n",
      "episode: 1531/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.03951382637023926\n",
      "episode: 1532/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.20982575416564941\n",
      "episode: 1533/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1534/6000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1535/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.881987512111664\n",
      "episode: 1536/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1537/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.115796506404877\n",
      "episode: 1538/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1539/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1540/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0019197463989257812\n",
      "episode: 1541/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0031020641326904297\n",
      "episode: 1542/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1543/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.02683258056640625\n",
      "episode: 1544/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1545/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.496079921722412\n",
      "episode: 1546/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1547/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1548/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1549/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1550/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1551/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 12.911361753940582\n",
      "episode: 1552/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1553/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 8.295562744140625\n",
      "episode: 1554/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1555/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 11.989477336406708\n",
      "episode: 1556/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1557/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.329183578491211e-05\n",
      "episode: 1558/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.007495880126953125\n",
      "episode: 1559/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.7110490202903748\n",
      "episode: 1560/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 20.956741333007812\n",
      "episode: 1561/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1562/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.982869863510132\n",
      "episode: 1563/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.828125\n",
      "episode: 1564/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.001514136791229248\n",
      "episode: 1565/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1566/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1567/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1568/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1569/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.304342865943909\n",
      "episode: 1570/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1571/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 6.512470722198486\n",
      "episode: 1572/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.990847051143646\n",
      "episode: 1573/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 12.301304340362549\n",
      "episode: 1574/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.07065999507904053\n",
      "episode: 1575/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.3458290100097656\n",
      "episode: 1576/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1577/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1578/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1579/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1580/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1581/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.515421569347382\n",
      "episode: 1582/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1583/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1584/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1585/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00022280216217041016\n",
      "episode: 1586/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1587/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1588/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.97656637430191\n",
      "episode: 1589/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.013671875\n",
      "episode: 1590/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.971777617931366\n",
      "episode: 1591/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.14973801374435425\n",
      "episode: 1592/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.843859374523163\n",
      "episode: 1593/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 1594/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1595/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1596/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1597/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1598/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1599/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1600/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.000461280345917\n",
      "episode: 1601/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1602/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1603/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1604/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.169563293457031\n",
      "episode: 1605/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1606/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.001358032226562\n",
      "episode: 1607/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00010627508163452148\n",
      "episode: 1608/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 3.2186508178710938e-06\n",
      "episode: 1609/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1610/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.988877832889557\n",
      "episode: 1611/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1612/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1613/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.005156517028809\n",
      "episode: 1614/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 1615/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1616/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0013107061386108398\n",
      "episode: 1617/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1618/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.0299784541130066\n",
      "episode: 1619/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0007146596908569336\n",
      "episode: 1620/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1621/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.875\n",
      "episode: 1622/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1623/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.309361934661865\n",
      "episode: 1624/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.150316417217255\n",
      "episode: 1625/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 2.6127982139587402\n",
      "episode: 1626/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.46899574995040894\n",
      "episode: 1627/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.99718165397644\n",
      "episode: 1628/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.98454350233078\n",
      "episode: 1629/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1630/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1631/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1632/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 8.5947265625\n",
      "episode: 1633/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.007705748081207275\n",
      "episode: 1634/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.97658622264862\n",
      "episode: 1635/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1636/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1637/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.004994750022888184\n",
      "episode: 1638/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00682830810546875\n",
      "episode: 1639/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1640/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1641/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1642/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1643/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1644/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1645/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1646/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.126534223556519\n",
      "episode: 1647/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.010019123554229736\n",
      "episode: 1648/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1649/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 10.101318359375\n",
      "episode: 1650/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.008116364479064941\n",
      "episode: 1651/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 12.749714612960815\n",
      "episode: 1652/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 1.6164610981941223\n",
      "episode: 1653/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1654/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1655/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1656/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1657/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00015604496002197266\n",
      "episode: 1658/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1659/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.00011456012725830078\n",
      "episode: 1660/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 6.781387448310852\n",
      "episode: 1661/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 17.173773527145386\n",
      "episode: 1662/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.429688930511475\n",
      "episode: 1663/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 11.323539793491364\n",
      "episode: 1664/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1665/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1666/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.984270513057709\n",
      "episode: 1667/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1668/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 1669/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1670/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 9.945528030395508\n",
      "episode: 1671/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1672/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1673/6000, steps: 500, e: 0.97\n",
      "accumulated_rewards_per_episode: 0.010733246803283691\n",
      "episode: 1674/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.158379673957825\n",
      "episode: 1675/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1676/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.982760429382324\n",
      "episode: 1677/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1678/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1679/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.9453125\n",
      "episode: 1680/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1681/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1682/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 3.796815872192383e-05\n",
      "episode: 1683/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1684/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.525120675563812\n",
      "episode: 1685/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 7.6974106431007385\n",
      "episode: 1686/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.32862091064453125\n",
      "episode: 1687/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1688/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1689/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1690/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1691/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1692/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.981063842773438\n",
      "episode: 1693/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1694/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1695/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1696/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1697/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976680934429169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1698/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.843969881534576\n",
      "episode: 1699/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.018177509307861328\n",
      "episode: 1700/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1701/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1702/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1703/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.529291331768036\n",
      "episode: 1704/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1705/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1706/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1707/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1708/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.65251737833023\n",
      "episode: 1709/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1710/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1711/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 1.3749140501022339\n",
      "episode: 1712/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1713/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.0628662109375\n",
      "episode: 1714/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00011587142944335938\n",
      "episode: 1715/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1716/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00831449031829834\n",
      "episode: 1717/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1718/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1719/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 8.531288504600525\n",
      "episode: 1720/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1721/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.978553235530853\n",
      "episode: 1722/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.015858948230743408\n",
      "episode: 1723/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.989762306213379\n",
      "episode: 1724/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.9768385887146\n",
      "episode: 1725/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00045120716094970703\n",
      "episode: 1726/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1727/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.297216892242432\n",
      "episode: 1728/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.984268188476562\n",
      "episode: 1729/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1730/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1731/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.369844019412994\n",
      "episode: 1732/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.32351696491241455\n",
      "episode: 1733/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1734/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.00967425107956\n",
      "episode: 1735/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.201945304870605\n",
      "episode: 1736/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1737/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1738/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00040775537490844727\n",
      "episode: 1739/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 11.3115234375\n",
      "episode: 1740/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.16470754146575928\n",
      "episode: 1741/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1742/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1743/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 1744/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976564168930054\n",
      "episode: 1745/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1746/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0019373893737792969\n",
      "episode: 1747/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1748/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.984460830688477\n",
      "episode: 1749/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.16428613662719727\n",
      "episode: 1750/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 1751/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 1752/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1753/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 1754/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1755/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976671993732452\n",
      "episode: 1756/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1757/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.976671576499939\n",
      "episode: 1758/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.446081161499023\n",
      "episode: 1759/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1760/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.9296875\n",
      "episode: 1761/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00026684999465942383\n",
      "episode: 1762/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.00307464599609375\n",
      "episode: 1763/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 6.079673767089844e-06\n",
      "episode: 1764/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1765/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 8.051930129528046\n",
      "episode: 1766/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1767/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.445669651031494\n",
      "episode: 1768/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 17.460888862609863\n",
      "episode: 1769/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1770/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1771/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1772/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1773/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1774/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 9.98451453447342\n",
      "episode: 1775/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.144534409046173\n",
      "episode: 1776/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.13270527124404907\n",
      "episode: 1777/6000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 1778/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1779/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.01593017578125\n",
      "episode: 1780/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1781/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 15.9716796875\n",
      "episode: 1782/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 1783/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.009130001068115234\n",
      "episode: 1784/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.007829368114471436\n",
      "episode: 1785/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1786/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1787/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.006896078586578369\n",
      "episode: 1788/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.994869232177734\n",
      "episode: 1789/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1790/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1791/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.05409449338912964\n",
      "episode: 1792/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1793/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.086181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1794/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1795/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1796/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1797/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1798/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 8.359512090682983\n",
      "episode: 1799/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1800/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1801/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1802/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 2.767578125\n",
      "episode: 1803/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1804/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.06072998046875\n",
      "episode: 1805/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.989149570465088\n",
      "episode: 1806/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1807/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1808/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0005955696105957031\n",
      "episode: 1809/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.00011152029037475586\n",
      "episode: 1810/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.00766146183013916\n",
      "episode: 1811/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.031309127807617\n",
      "episode: 1812/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 2.771615982055664e-05\n",
      "episode: 1813/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1814/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1815/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 13.220777869224548\n",
      "episode: 1816/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 1817/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.00010883808135986328\n",
      "episode: 1818/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 7.165297985076904\n",
      "episode: 1819/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1820/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 2.3245811462402344e-06\n",
      "episode: 1821/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 21.170654356479645\n",
      "episode: 1822/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 12.878844261169434\n",
      "episode: 1823/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1824/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.02019888162612915\n",
      "episode: 1825/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0002760887145996094\n",
      "episode: 1826/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.996902465820312\n",
      "episode: 1827/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1828/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.031125903129577637\n",
      "episode: 1829/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1830/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1831/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.994943380355835\n",
      "episode: 1832/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1833/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1834/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.309493064880371\n",
      "episode: 1835/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.014127373695374\n",
      "episode: 1836/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1837/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 1838/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.683914184570312\n",
      "episode: 1839/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.009699165821075\n",
      "episode: 1840/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1841/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1842/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1843/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.06556087732315063\n",
      "episode: 1844/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.581019043922424\n",
      "episode: 1845/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 18.66737014055252\n",
      "episode: 1846/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1847/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.057504296302795\n",
      "episode: 1848/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.06235635280609131\n",
      "episode: 1849/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.989004790782928\n",
      "episode: 1850/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.961122512817383\n",
      "episode: 1851/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1852/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.996864259243011\n",
      "episode: 1853/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1854/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1855/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1856/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1857/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 1858/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1859/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1860/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.995338201522827\n",
      "episode: 1861/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 10.134674072265625\n",
      "episode: 1862/6000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 9.99706494808197\n",
      "episode: 1863/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.976674258708954\n",
      "episode: 1864/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1865/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 8.554503440856934\n",
      "episode: 1866/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1867/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1868/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1869/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 1.9866324663162231\n",
      "episode: 1870/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.0045725107193\n",
      "episode: 1871/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1872/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.968750059604645\n",
      "episode: 1873/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.47661405801773\n",
      "episode: 1874/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1875/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1876/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1877/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1878/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1879/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.986757755279541\n",
      "episode: 1880/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 7.215660095214844\n",
      "episode: 1881/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 19.142622768878937\n",
      "episode: 1882/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1883/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.999901473522186\n",
      "episode: 1884/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 8.734375\n",
      "episode: 1885/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1886/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1887/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 1888/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1889/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.989506900310516\n",
      "episode: 1890/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1891/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1892/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.743003726005554\n",
      "episode: 1893/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1894/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.03658264875411987\n",
      "episode: 1895/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1896/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1897/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1898/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1899/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.02756500244140625\n",
      "episode: 1900/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1901/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 3.814697265625e-06\n",
      "episode: 1902/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.981056213378906\n",
      "episode: 1903/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.921884894371033\n",
      "episode: 1904/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1905/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.008114218711853027\n",
      "episode: 1906/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 10.017164170742035\n",
      "episode: 1907/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.99161148071289\n",
      "episode: 1908/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1909/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 1910/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1911/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1912/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1913/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1914/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 1915/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1916/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1917/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1918/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1919/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1920/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.006100594997406006\n",
      "episode: 1921/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1922/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 7.152557373046875e-07\n",
      "episode: 1923/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1924/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 1925/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1926/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1927/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 9.898547232151031\n",
      "episode: 1928/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1929/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.13592326641082764\n",
      "episode: 1930/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1931/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1932/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1933/6000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0024127960205078125\n",
      "episode: 1934/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1935/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 7.144808769226074\n",
      "episode: 1936/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1937/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 2.074178636074066\n",
      "episode: 1938/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1939/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.976969003677368\n",
      "episode: 1940/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 1941/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1942/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 3.106109619140625\n",
      "episode: 1943/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1944/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1945/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.011968016624450684\n",
      "episode: 1946/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1947/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.65094792842865\n",
      "episode: 1948/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1949/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1950/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1951/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.00506281852722168\n",
      "episode: 1952/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.419719934463501\n",
      "episode: 1953/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.676513671875\n",
      "episode: 1954/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.113745212554932\n",
      "episode: 1955/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.984435558319092\n",
      "episode: 1956/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1957/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.718442976474762\n",
      "episode: 1958/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1959/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1960/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.006202399730682373\n",
      "episode: 1961/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 1962/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.007094204425811768\n",
      "episode: 1963/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1964/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1965/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1966/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1967/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 11.098640024662018\n",
      "episode: 1968/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 7.215724170207977\n",
      "episode: 1969/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.531122267246246\n",
      "episode: 1970/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1971/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.137536764144897\n",
      "episode: 1972/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1973/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1974/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1975/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1976/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1977/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1978/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1979/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1980/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.324302673339844\n",
      "episode: 1981/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.02209484577179\n",
      "episode: 1982/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1983/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.022826433181762695\n",
      "episode: 1984/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.499734103679657\n",
      "episode: 1985/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1986/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 11.997802734375\n",
      "episode: 1987/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1988/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1989/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1990/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 10.006530821323395\n",
      "episode: 1991/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 5.492431640625\n",
      "episode: 1992/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 9.976584613323212\n",
      "episode: 1993/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1994/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0001049041748046875\n",
      "episode: 1995/6000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1996/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 1997/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.320413708686829\n",
      "episode: 1998/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 1999/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2000/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2001/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2002/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.00866854190826416\n",
      "episode: 2003/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 17.744401931762695\n",
      "episode: 2004/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2005/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.84375\n",
      "episode: 2006/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2007/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2008/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2009/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2010/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2011/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.5497207641601562e-06\n",
      "episode: 2012/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.01269388198852539\n",
      "episode: 2013/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 7.1445313692092896\n",
      "episode: 2014/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.996734738349915\n",
      "episode: 2015/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.984375\n",
      "episode: 2016/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 2017/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2018/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2019/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-07\n",
      "episode: 2020/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2021/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2022/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2023/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 2024/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 2.6345252990722656e-05\n",
      "episode: 2025/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2026/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2027/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2028/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2029/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2030/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.445413649082184\n",
      "episode: 2031/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2032/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2033/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 9.45937728881836\n",
      "episode: 2034/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.00711965560913\n",
      "episode: 2035/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2036/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2037/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2038/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2039/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 8.708997666835785\n",
      "episode: 2040/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 10.774389803409576\n",
      "episode: 2041/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2042/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2043/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2044/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 1.9668264389038086\n",
      "episode: 2045/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2046/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2047/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2048/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2049/6000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 7.159919738769531\n",
      "episode: 2050/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2051/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2052/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.97656399011612\n",
      "episode: 2053/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.008030593395233154\n",
      "episode: 2054/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2055/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2056/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 2057/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 4.175221085548401\n",
      "episode: 2058/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2059/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2060/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2061/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.988984823226929\n",
      "episode: 2062/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0002799034118652344\n",
      "episode: 2063/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.178120136260986\n",
      "episode: 2064/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.983451843261719\n",
      "episode: 2065/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 7.510185241699219e-06\n",
      "episode: 2066/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2067/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2068/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 17.15390717983246\n",
      "episode: 2069/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 13.259506225585938\n",
      "episode: 2070/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2071/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 7.157985806465149\n",
      "episode: 2072/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2073/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.984405279159546\n",
      "episode: 2074/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2075/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2076/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2077/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.007928609848022461\n",
      "episode: 2078/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2079/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2080/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 4.829345703125\n",
      "episode: 2081/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.000006079673767\n",
      "episode: 2082/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.009333789348602295\n",
      "episode: 2083/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2084/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2085/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.148489236831665\n",
      "episode: 2086/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.0091010928154\n",
      "episode: 2087/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2088/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 2089/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.976902306079865\n",
      "episode: 2090/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2091/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.12220823764801\n",
      "episode: 2092/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.968856871128082\n",
      "episode: 2093/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2094/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2095/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 9.988989353179932\n",
      "episode: 2096/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 2097/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2098/6000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2099/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 11.763916015625\n",
      "episode: 2100/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2101/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976570069789886\n",
      "episode: 2102/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 10.014379739761353\n",
      "episode: 2103/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2104/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.9153573513031\n",
      "episode: 2105/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2106/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 6.398612976074219\n",
      "episode: 2107/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.02803337574005127\n",
      "episode: 2108/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2109/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2110/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2111/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.97667795419693\n",
      "episode: 2112/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976565539836884\n",
      "episode: 2113/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 7.894319832324982\n",
      "episode: 2114/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976845383644104\n",
      "episode: 2115/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2116/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2117/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 8.19091796875\n",
      "episode: 2118/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 5.4836273193359375e-06\n",
      "episode: 2119/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 11.16015625\n",
      "episode: 2120/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2121/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2122/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-06\n",
      "episode: 2123/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2124/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2125/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2126/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.991733253002167\n",
      "episode: 2127/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2128/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2129/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2130/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2131/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2132/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2133/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.976949632167816\n",
      "episode: 2134/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0022751688957214355\n",
      "episode: 2135/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 11.552399456501007\n",
      "episode: 2136/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2137/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2138/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2139/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2140/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2141/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0009342432022094727\n",
      "episode: 2142/6000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 11.09909439086914\n",
      "episode: 2143/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0075789690017700195\n",
      "episode: 2144/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 1.0132789611816406e-06\n",
      "episode: 2145/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2146/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 10.885815560817719\n",
      "episode: 2147/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2148/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2149/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2150/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.99129730463028\n",
      "episode: 2151/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2152/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 2153/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0002747178077697754\n",
      "episode: 2154/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2155/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 21.1103515625\n",
      "episode: 2156/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2157/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2158/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2159/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.976572275161743\n",
      "episode: 2160/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2161/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.47722816467285156\n",
      "episode: 2162/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2163/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.01267242431640625\n",
      "episode: 2164/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2165/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.5263686776161194\n",
      "episode: 2166/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2167/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2168/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2169/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 19.97786968946457\n",
      "episode: 2170/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2171/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.988449096679688\n",
      "episode: 2172/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2173/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2174/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.05424904823303223\n",
      "episode: 2175/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2176/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2177/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2178/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.8412542343139648\n",
      "episode: 2179/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2180/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0007149577140808105\n",
      "episode: 2181/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2182/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 2183/6000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2184/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.002410531044006\n",
      "episode: 2185/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.004851162433624\n",
      "episode: 2186/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2187/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.012460827827454\n",
      "episode: 2188/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.008061408996582031\n",
      "episode: 2189/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.997072279453278\n",
      "episode: 2190/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 21.062594056129456\n",
      "episode: 2191/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2192/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2193/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 7.179576873779297\n",
      "episode: 2194/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.5322265625\n",
      "episode: 2195/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2196/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.00016319751739501953\n",
      "episode: 2197/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2198/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.012323081493377686\n",
      "episode: 2199/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2200/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 17.1875\n",
      "episode: 2201/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.034857034683228\n",
      "episode: 2202/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2203/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2204/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2205/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.976917147636414\n",
      "episode: 2206/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2207/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2208/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 9.46875\n",
      "episode: 2209/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 7.157132625579834\n",
      "episode: 2210/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.035651206970215\n",
      "episode: 2211/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2212/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2213/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.3188213109970093\n",
      "episode: 2214/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2215/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 7.51921808719635\n",
      "episode: 2216/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2217/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.022301793098449707\n",
      "episode: 2218/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2219/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2220/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2221/6000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2222/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 2223/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2224/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2225/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.992526412010193\n",
      "episode: 2226/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.976844727993011\n",
      "episode: 2227/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2228/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.10262191295623779\n",
      "episode: 2229/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.968750178813934\n",
      "episode: 2230/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2231/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.998379588127136\n",
      "episode: 2232/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.30545949935913\n",
      "episode: 2233/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2234/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.453125\n",
      "episode: 2235/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2236/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.017355382442474\n",
      "episode: 2237/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2238/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2239/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2240/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2241/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2242/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2243/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2244/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2245/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2246/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2247/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2248/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 11.064760446548462\n",
      "episode: 2249/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2250/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0053923726081848145\n",
      "episode: 2251/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.995773315429688\n",
      "episode: 2252/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2253/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2254/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.04053717851638794\n",
      "episode: 2255/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.32862091064453125\n",
      "episode: 2256/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 9.984797477722168\n",
      "episode: 2257/6000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 10.0\n",
      "episode: 2258/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 13.126935958862305\n",
      "episode: 2259/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2260/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.34224605560302734\n",
      "episode: 2261/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 8.96875\n",
      "episode: 2262/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.843753635883331\n",
      "episode: 2263/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.97683572769165\n",
      "episode: 2264/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.004838764667511\n",
      "episode: 2265/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2266/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.00038444995880126953\n",
      "episode: 2267/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.012621164321899414\n",
      "episode: 2268/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.386108338832855\n",
      "episode: 2269/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 2.7854361534118652\n",
      "episode: 2270/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2271/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.114477753639221\n",
      "episode: 2272/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2273/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 2274/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.957777500152588\n",
      "episode: 2275/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2276/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2277/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2278/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.004383265972137451\n",
      "episode: 2279/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 18.026647567749023\n",
      "episode: 2280/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2281/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.984211146831512\n",
      "episode: 2282/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 6.918240427970886\n",
      "episode: 2283/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.909501075744629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2284/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 2285/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2286/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2287/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2288/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2289/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 10.004943132400513\n",
      "episode: 2290/6000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2291/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2292/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.984241545200348\n",
      "episode: 2293/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2294/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.976778864860535\n",
      "episode: 2295/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 13.039548873901367\n",
      "episode: 2296/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2297/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2298/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2299/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 10.241239786148071\n",
      "episode: 2300/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 12.238783657550812\n",
      "episode: 2301/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2302/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2303/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2304/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 5.960464477539062e-07\n",
      "episode: 2305/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2306/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2307/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2308/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2309/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 2310/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.84402048587799\n",
      "episode: 2311/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2312/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2313/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.5873708128929138\n",
      "episode: 2314/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2315/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2316/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2317/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2318/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2319/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 4.887580871582031e-06\n",
      "episode: 2320/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2321/6000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 9.976903438568115\n",
      "episode: 2322/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 11.841796934604645\n",
      "episode: 2323/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 11.434707641601562\n",
      "episode: 2324/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2325/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2326/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.5528185367584229\n",
      "episode: 2327/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2328/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2329/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.98440420627594\n",
      "episode: 2330/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2331/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2332/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2333/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2334/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.537235260009766\n",
      "episode: 2335/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 2336/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 7.4273422956466675\n",
      "episode: 2337/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.976562738418579\n",
      "episode: 2338/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 8.020384430885315\n",
      "episode: 2339/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2340/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 2341/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.332711398601532\n",
      "episode: 2342/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.996965169906616\n",
      "episode: 2343/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 9.976673305034637\n",
      "episode: 2344/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.5704305171966553\n",
      "episode: 2345/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.020193040370941162\n",
      "episode: 2346/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2347/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2348/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2349/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2350/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2351/6000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 8.785724639892578e-05\n",
      "episode: 2352/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2353/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.992469847202301\n",
      "episode: 2354/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.02491009235382\n",
      "episode: 2355/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 7.873773574829102e-05\n",
      "episode: 2356/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.77558183670044\n",
      "episode: 2357/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.005146980285644531\n",
      "episode: 2358/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2359/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.07717490196228\n",
      "episode: 2360/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2361/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2362/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.007747530937194824\n",
      "episode: 2363/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 8.355438768863678\n",
      "episode: 2364/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 10.457983613014221\n",
      "episode: 2365/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2366/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.985233783721924\n",
      "episode: 2367/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.976675510406494\n",
      "episode: 2368/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.013828277587890625\n",
      "episode: 2369/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2370/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2371/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2372/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2373/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2374/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.002095460891723633\n",
      "episode: 2375/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2376/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 2.110004425048828e-05\n",
      "episode: 2377/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2378/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2379/6000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 1.7285346984863281e-06\n",
      "episode: 2380/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2381/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2382/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2383/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 9.945589542388916\n",
      "episode: 2384/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.47165340185165405\n",
      "episode: 2385/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2386/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.134415030479431\n",
      "episode: 2387/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.101545989513397\n",
      "episode: 2388/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2389/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.06396484375\n",
      "episode: 2390/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2391/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.02646815776824951\n",
      "episode: 2392/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2393/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.015327155590057373\n",
      "episode: 2394/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2395/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 7.2464599609375\n",
      "episode: 2396/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2397/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 19.75853967666626\n",
      "episode: 2398/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2399/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.007840216159820557\n",
      "episode: 2400/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2401/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.011883676052093506\n",
      "episode: 2402/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 1.0332412719726562\n",
      "episode: 2403/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.272401571273804\n",
      "episode: 2404/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 10.756036221981049\n",
      "episode: 2405/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 2.3305416107177734e-05\n",
      "episode: 2406/6000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 0.026702880859375\n",
      "episode: 2407/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2408/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2409/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.996795177459717\n",
      "episode: 2410/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2411/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.16311168670654297\n",
      "episode: 2412/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 8.007990837097168\n",
      "episode: 2413/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2414/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2415/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.986265540122986\n",
      "episode: 2416/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2417/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 16.0453959107399\n",
      "episode: 2418/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.020467162132263184\n",
      "episode: 2419/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.976671040058136\n",
      "episode: 2420/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 11.984715580940247\n",
      "episode: 2421/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.96886295080185\n",
      "episode: 2422/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.004594385623931885\n",
      "episode: 2423/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2424/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2425/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2426/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2427/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.16524016857147217\n",
      "episode: 2428/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 2429/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2430/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2431/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2432/6000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 11.419776916503906\n",
      "episode: 2433/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2434/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2435/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2436/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 10.002412796020508\n",
      "episode: 2437/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2438/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.02658146619796753\n",
      "episode: 2439/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2440/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.976673364639282\n",
      "episode: 2441/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2442/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2443/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2444/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2445/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2446/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 1.0371208190917969e-05\n",
      "episode: 2447/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.984268307685852\n",
      "episode: 2448/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2449/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2450/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.015006303787231445\n",
      "episode: 2451/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.00038361549377441406\n",
      "episode: 2452/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2453/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 2454/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2455/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2456/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2457/6000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 2458/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.03820300102233887\n",
      "episode: 2459/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.09084761142730713\n",
      "episode: 2460/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.00027370452880859375\n",
      "episode: 2461/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2462/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.08025908470153809\n",
      "episode: 2463/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.012422025203704834\n",
      "episode: 2464/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2465/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2466/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 2467/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 5.767061173915863\n",
      "episode: 2468/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.00809013843536377\n",
      "episode: 2469/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.061236202716827\n",
      "episode: 2470/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2471/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2472/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2473/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.984553337097168\n",
      "episode: 2474/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.022034347057343\n",
      "episode: 2475/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.007823169231414795\n",
      "episode: 2476/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2477/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 1.0728836059570312e-06\n",
      "episode: 2478/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 1.9669532775878906e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2479/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2480/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 2481/6000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 9.945585250854492\n",
      "episode: 2482/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 5.185604095458984e-06\n",
      "episode: 2483/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2484/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.976592123508453\n",
      "episode: 2485/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2486/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.12985730171203613\n",
      "episode: 2487/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.00010854005813598633\n",
      "episode: 2488/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.988983392715454\n",
      "episode: 2489/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2490/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.04170715808868408\n",
      "episode: 2491/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.11242556571960449\n",
      "episode: 2492/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 4.649162292480469e-05\n",
      "episode: 2493/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2494/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2495/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 10.043915450572968\n",
      "episode: 2496/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2497/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2498/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0017637014389038086\n",
      "episode: 2499/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 2.980232238769531e-07\n",
      "episode: 2500/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 2.1955108642578125\n",
      "episode: 2501/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2502/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2503/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2504/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2505/6000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 9.98883056640625\n",
      "episode: 2506/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 8.762451171875\n",
      "episode: 2507/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.029167175292969\n",
      "episode: 2508/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 2.580881118774414e-05\n",
      "episode: 2509/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.007594585418701172\n",
      "episode: 2510/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2511/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2512/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2513/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2514/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2515/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2516/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 9.437507569789886\n",
      "episode: 2517/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.29485273361206\n",
      "episode: 2518/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 11.01904296875\n",
      "episode: 2519/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.005073368549347\n",
      "episode: 2520/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.304412841796875\n",
      "episode: 2521/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.005573272705078125\n",
      "episode: 2522/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 10.640640258789062\n",
      "episode: 2523/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2524/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2525/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2526/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2527/6000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2528/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.00013124942779541016\n",
      "episode: 2529/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0012483596801757812\n",
      "episode: 2530/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2531/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2532/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 10.00431489944458\n",
      "episode: 2533/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 18.18017578125\n",
      "episode: 2534/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2535/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2536/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2537/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 1.9073486328125e-06\n",
      "episode: 2538/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2539/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2540/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2541/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2542/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2543/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2544/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0035228729248046875\n",
      "episode: 2545/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2546/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2547/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2548/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 9.036008834838867\n",
      "episode: 2549/6000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 2.771615982055664e-05\n",
      "episode: 2550/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.590839147567749\n",
      "episode: 2551/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 9.988876521587372\n",
      "episode: 2552/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2553/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.3001493811607361\n",
      "episode: 2554/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.142096281051636\n",
      "episode: 2555/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2556/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2557/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2558/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 2559/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2560/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2561/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.004949271678925\n",
      "episode: 2562/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2563/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.010122299194335938\n",
      "episode: 2564/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.149658203125\n",
      "episode: 2565/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0063155293464660645\n",
      "episode: 2566/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.8548420667648315\n",
      "episode: 2567/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 13.430225372314453\n",
      "episode: 2568/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2569/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2570/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2571/6000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2572/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2573/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2574/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 10.105033993721008\n",
      "episode: 2575/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2576/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.002375662326812744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2577/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2578/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2579/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2580/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2581/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2582/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.992108702659607\n",
      "episode: 2583/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.013856709003448486\n",
      "episode: 2584/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.453126311302185\n",
      "episode: 2585/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 5.582782566547394\n",
      "episode: 2586/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 1.2391634583473206\n",
      "episode: 2587/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 11.454040825366974\n",
      "episode: 2588/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2589/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.03560096025466919\n",
      "episode: 2590/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 9.993972420692444\n",
      "episode: 2591/6000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 0.02189767360687256\n",
      "episode: 2592/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2593/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2594/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 9.879364013671875\n",
      "episode: 2595/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2596/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2597/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2598/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.019549012184143066\n",
      "episode: 2599/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2600/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2601/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0005486011505126953\n",
      "episode: 2602/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2603/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2604/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2605/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2606/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2607/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 2.028387427330017\n",
      "episode: 2608/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.001553654670715332\n",
      "episode: 2609/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2610/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 7.630258142948151\n",
      "episode: 2611/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.035882532596588135\n",
      "episode: 2612/6000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 0.6256529688835144\n",
      "episode: 2613/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.01941460371017456\n",
      "episode: 2614/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 2.921825408935547\n",
      "episode: 2615/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.701938807964325\n",
      "episode: 2616/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 8.206459045410156\n",
      "episode: 2617/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2618/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 16.29296875\n",
      "episode: 2619/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.03274655342102051\n",
      "episode: 2620/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2621/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 7.015712857246399\n",
      "episode: 2622/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.02695375680923462\n",
      "episode: 2623/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2624/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2625/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.03893625736236572\n",
      "episode: 2626/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.04520159959793091\n",
      "episode: 2627/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 8.000118374824524\n",
      "episode: 2628/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.976978540420532\n",
      "episode: 2629/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2630/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2631/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.985855102539062\n",
      "episode: 2632/6000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 9.988886773586273\n",
      "episode: 2633/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2634/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2635/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2636/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2637/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2638/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 8.355691611766815\n",
      "episode: 2639/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2640/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.976833820343018\n",
      "episode: 2641/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2642/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2643/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 2644/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2645/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 2646/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2647/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 10.006768584251404\n",
      "episode: 2648/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2649/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 9.996862828731537\n",
      "episode: 2650/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2651/6000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2652/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.00021338462829589844\n",
      "episode: 2653/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 3.3974647521972656e-06\n",
      "episode: 2654/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2655/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2656/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.697716176509857\n",
      "episode: 2657/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 1.430511474609375e-06\n",
      "episode: 2658/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 12.051833391189575\n",
      "episode: 2659/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2660/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 19.972510814666748\n",
      "episode: 2661/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2662/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.978553712368011\n",
      "episode: 2663/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2664/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 2.758451998233795\n",
      "episode: 2665/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.04409158229827881\n",
      "episode: 2666/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 10.014486730098724\n",
      "episode: 2667/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2668/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2669/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 7.861852645874023e-05\n",
      "episode: 2670/6000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2671/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.6158472895622253\n",
      "episode: 2672/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2673/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2674/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2675/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2676/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2677/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 10.127920866012573\n",
      "episode: 2678/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2679/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.02357161045074463\n",
      "episode: 2680/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2681/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2682/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 8.180908203125\n",
      "episode: 2683/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2684/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2685/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.026014745235443115\n",
      "episode: 2686/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2687/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 9.989097118377686\n",
      "episode: 2688/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 4.023439407348633\n",
      "episode: 2689/6000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 8.000060617923737\n",
      "episode: 2690/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2691/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 2.48193359375\n",
      "episode: 2692/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0006931424140930176\n",
      "episode: 2693/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2694/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2695/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2696/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.007810354232788086\n",
      "episode: 2697/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2698/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.00772249698638916\n",
      "episode: 2699/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2700/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.18591594696045\n",
      "episode: 2701/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.976669430732727\n",
      "episode: 2702/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 8.21174532175064\n",
      "episode: 2703/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2704/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2705/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.011355102062225342\n",
      "episode: 2706/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2707/6000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 0.0008046627044677734\n",
      "episode: 2708/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 8.285045623779297e-06\n",
      "episode: 2709/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.96902585029602\n",
      "episode: 2710/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.09501010179519653\n",
      "episode: 2711/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.977035880088806\n",
      "episode: 2712/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2713/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.99685686826706\n",
      "episode: 2714/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2715/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 2716/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2717/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0199928879737854\n",
      "episode: 2718/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2719/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.03198981285095215\n",
      "episode: 2720/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.976573586463928\n",
      "episode: 2721/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 9.984579086303711\n",
      "episode: 2722/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 7.220544099807739\n",
      "episode: 2723/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2724/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2725/6000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2726/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 2727/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2728/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.06396633386611938\n",
      "episode: 2729/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2730/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.015477418899536133\n",
      "episode: 2731/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2732/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 20.31064522266388\n",
      "episode: 2733/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 2734/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 12.85046398639679\n",
      "episode: 2735/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.984541893005371\n",
      "episode: 2736/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.023066163063049316\n",
      "episode: 2737/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2738/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 2739/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2740/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.00044929981231689453\n",
      "episode: 2741/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.015536069869995117\n",
      "episode: 2742/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2743/6000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 9.976619362831116\n",
      "episode: 2744/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.978533744812012\n",
      "episode: 2745/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.009712517261505127\n",
      "episode: 2746/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.007982075214385986\n",
      "episode: 2747/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 10.645575523376465\n",
      "episode: 2748/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2749/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2750/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 2751/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2752/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2753/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2754/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2755/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-07\n",
      "episode: 2756/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2757/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.02490854263305664\n",
      "episode: 2758/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 9.968856990337372\n",
      "episode: 2759/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2760/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 7.220719277858734\n",
      "episode: 2761/6000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 0.15575182437896729\n",
      "episode: 2762/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.999335646629333\n",
      "episode: 2763/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 2764/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2765/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2766/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.979421734809875\n",
      "episode: 2767/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 9.968751549720764\n",
      "episode: 2768/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0019234418869018555\n",
      "episode: 2769/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2770/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.2623980641365051\n",
      "episode: 2771/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2772/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2773/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.14022105932235718\n",
      "episode: 2774/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2775/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2776/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.568981409072876\n",
      "episode: 2777/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2778/6000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 12.779894590377808\n",
      "episode: 2779/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2780/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 2.033571779727936\n",
      "episode: 2781/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2782/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 2783/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2784/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2785/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.988642930984497\n",
      "episode: 2786/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 2.3245811462402344e-06\n",
      "episode: 2787/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2788/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.00992441177368164\n",
      "episode: 2789/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2790/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 10.25370454788208\n",
      "episode: 2791/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2792/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2793/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 9.989263355731964\n",
      "episode: 2794/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 10.001478791236877\n",
      "episode: 2795/6000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.00011336803436279297\n",
      "episode: 2796/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.960943520069122\n",
      "episode: 2797/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.007646143436431885\n",
      "episode: 2798/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2799/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 2800/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2801/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2802/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 2803/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2804/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 10.001358032226562\n",
      "episode: 2805/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2806/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2807/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2808/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2809/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2810/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 9.988813817501068\n",
      "episode: 2811/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2812/6000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 10.324577331542969\n",
      "episode: 2813/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.15764617919921875\n",
      "episode: 2814/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2815/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.976562738418579\n",
      "episode: 2816/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2817/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2818/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2819/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 2.4437904357910156e-06\n",
      "episode: 2820/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.00011110305786132812\n",
      "episode: 2821/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.00012797117233276367\n",
      "episode: 2822/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2823/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.01549994945526123\n",
      "episode: 2824/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.14965969324111938\n",
      "episode: 2825/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.15317702293395996\n",
      "episode: 2826/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2827/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2828/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2829/6000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 9.758499324321747\n",
      "episode: 2830/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2831/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2832/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2833/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2834/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 9.988870203495026\n",
      "episode: 2835/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2836/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2837/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2838/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.4015235900878906\n",
      "episode: 2839/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2840/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2841/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2842/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2843/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2844/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 5.328262567520142\n",
      "episode: 2845/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 2.0317875146865845\n",
      "episode: 2846/6000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 10.114364624023438\n",
      "episode: 2847/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2848/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 10.576787233352661\n",
      "episode: 2849/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2850/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 7.988369345664978\n",
      "episode: 2851/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2852/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 2.056022584438324\n",
      "episode: 2853/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 2854/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.7629350423812866\n",
      "episode: 2855/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2856/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2857/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 2.2530555725097656e-05\n",
      "episode: 2858/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.4909796714782715\n",
      "episode: 2859/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.012509584426879883\n",
      "episode: 2860/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2861/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 10.104747951030731\n",
      "episode: 2862/6000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 2863/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.003554105758666992\n",
      "episode: 2864/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 11.981893837451935\n",
      "episode: 2865/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.8828125\n",
      "episode: 2866/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.00034564733505249023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2867/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.987613320350647\n",
      "episode: 2868/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2869/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2870/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.738265991210938\n",
      "episode: 2871/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2872/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2873/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2874/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.007588863372802734\n",
      "episode: 2875/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.4453125\n",
      "episode: 2876/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 7.228269577026367\n",
      "episode: 2877/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2878/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 9.984557688236237\n",
      "episode: 2879/6000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2880/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2881/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2882/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.007907688617706299\n",
      "episode: 2883/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 7.941428899765015\n",
      "episode: 2884/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 9.976836264133453\n",
      "episode: 2885/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 8.940696716308594e-07\n",
      "episode: 2886/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2887/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2888/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2889/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2890/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2891/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 11.969481885433197\n",
      "episode: 2892/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 11.312035024166107\n",
      "episode: 2893/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 10.476448595523834\n",
      "episode: 2894/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2895/6000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2896/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2897/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.035507261753082275\n",
      "episode: 2898/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 10.022897183895111\n",
      "episode: 2899/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2900/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 20.645079374313354\n",
      "episode: 2901/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2902/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 7.15695321559906\n",
      "episode: 2903/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 19.956281065940857\n",
      "episode: 2904/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.3647139072418213\n",
      "episode: 2905/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.47682237625122\n",
      "episode: 2906/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2907/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 19.942341446876526\n",
      "episode: 2908/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 1.989654541015625\n",
      "episode: 2909/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2910/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.97067105770111\n",
      "episode: 2911/6000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2912/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 3.993511199951172e-05\n",
      "episode: 2913/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2914/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2915/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.7002312541007996\n",
      "episode: 2916/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.484636664390564\n",
      "episode: 2917/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.06655526161193848\n",
      "episode: 2918/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.01623833179473877\n",
      "episode: 2919/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 2.53564453125\n",
      "episode: 2920/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2921/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 10.020884931087494\n",
      "episode: 2922/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 8.007813096046448\n",
      "episode: 2923/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 10.57954752445221\n",
      "episode: 2924/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.999434411525726\n",
      "episode: 2925/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2926/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 2927/6000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 21.791015625\n",
      "episode: 2928/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 10.037139892578125\n",
      "episode: 2929/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.07690119743347168\n",
      "episode: 2930/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2931/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.984264373779297\n",
      "episode: 2932/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2933/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 2934/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.989329814910889\n",
      "episode: 2935/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 5.433053970336914\n",
      "episode: 2936/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2937/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2938/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.844221889972687\n",
      "episode: 2939/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 1.4230270981788635\n",
      "episode: 2940/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 18.876502335071564\n",
      "episode: 2941/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 8.03654283285141\n",
      "episode: 2942/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 8.001799762248993\n",
      "episode: 2943/6000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 9.989253759384155\n",
      "episode: 2944/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2945/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 2946/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0212249755859375\n",
      "episode: 2947/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 11.979485094547272\n",
      "episode: 2948/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2949/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 5.950895130634308\n",
      "episode: 2950/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2951/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2952/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.020515501499176025\n",
      "episode: 2953/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 17.45502418279648\n",
      "episode: 2954/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 2955/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2956/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.796981513500214\n",
      "episode: 2957/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2958/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2959/6000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 9.976573884487152\n",
      "episode: 2960/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2961/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.890625059604645\n",
      "episode: 2962/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2963/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.023683190345764\n",
      "episode: 2964/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.976950824260712\n",
      "episode: 2965/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2966/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.030019581317902\n",
      "episode: 2967/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 9.65653133392334\n",
      "episode: 2968/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.5669177770614624\n",
      "episode: 2969/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2970/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2971/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 7.943716466426849\n",
      "episode: 2972/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 10.127980768680573\n",
      "episode: 2973/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2974/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2975/6000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2976/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-07\n",
      "episode: 2977/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.014667868614196777\n",
      "episode: 2978/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 8.143503606319427\n",
      "episode: 2979/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2980/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2981/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2982/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 4.60274600982666\n",
      "episode: 2983/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2984/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 10.004376888275146\n",
      "episode: 2985/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 1.1324882507324219e-06\n",
      "episode: 2986/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.015659332275390625\n",
      "episode: 2987/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.945314049720764\n",
      "episode: 2988/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.008088827133178711\n",
      "episode: 2989/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2990/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 2991/6000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2992/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2993/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.996573626995087\n",
      "episode: 2994/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.029259562492370605\n",
      "episode: 2995/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2996/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2997/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2998/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 2999/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.015776216983795166\n",
      "episode: 3000/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3001/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3002/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 10.1214599609375\n",
      "episode: 3003/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3004/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 19.994934856891632\n",
      "episode: 3005/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 3006/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 10.337136626243591\n",
      "episode: 3007/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.211284875869751\n",
      "episode: 3008/6000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3009/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3010/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3011/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 10.194580078125\n",
      "episode: 3012/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.491704642772675\n",
      "episode: 3013/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 6.842613220214844e-05\n",
      "episode: 3014/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3015/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 19.63330715894699\n",
      "episode: 3016/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.316009521484375\n",
      "episode: 3017/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 10.304931640625\n",
      "episode: 3018/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 8.000500202178955\n",
      "episode: 3019/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.976836681365967\n",
      "episode: 3020/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.00771254301071167\n",
      "episode: 3021/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 13.082672119140625\n",
      "episode: 3022/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3023/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3024/6000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3025/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.000948488712310791\n",
      "episode: 3026/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3027/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3028/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 2.043696105480194\n",
      "episode: 3029/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.992257297039032\n",
      "episode: 3030/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3031/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.99677848815918\n",
      "episode: 3032/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 18.209966242313385\n",
      "episode: 3033/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.019896626472473145\n",
      "episode: 3034/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.008218169212341309\n",
      "episode: 3035/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.97656899690628\n",
      "episode: 3036/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 0.000894010066986084\n",
      "episode: 3037/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 7.169986724853516\n",
      "episode: 3038/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.546875\n",
      "episode: 3039/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3040/6000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 9.976570010185242\n",
      "episode: 3041/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.088577270507812\n",
      "episode: 3042/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 19.039259910583496\n",
      "episode: 3043/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3044/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 11.943359375\n",
      "episode: 3045/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3046/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.9453125\n",
      "episode: 3047/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.97684097290039\n",
      "episode: 3048/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.476566135883331\n",
      "episode: 3049/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 8.609472513198853\n",
      "episode: 3050/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.006214141845703125\n",
      "episode: 3051/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.278973400592804\n",
      "episode: 3052/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 8.012320637702942\n",
      "episode: 3053/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3054/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3055/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.0155029296875\n",
      "episode: 3056/6000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3057/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 8.132539331912994\n",
      "episode: 3058/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 10.25341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3059/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3060/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3061/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0003548860549926758\n",
      "episode: 3062/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.31787109375\n",
      "episode: 3063/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.663978517055511\n",
      "episode: 3064/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3065/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3066/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 6.476688742637634\n",
      "episode: 3067/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3068/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3069/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.007574141025543213\n",
      "episode: 3070/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3071/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3072/6000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 11.0556640625\n",
      "episode: 3073/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3074/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3075/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.00011295080184936523\n",
      "episode: 3076/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 10.0006702542305\n",
      "episode: 3077/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 3078/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3079/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3080/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3081/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.015413641929626465\n",
      "episode: 3082/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 20.532568335533142\n",
      "episode: 3083/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 9.99655681848526\n",
      "episode: 3084/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.13233178853988647\n",
      "episode: 3085/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.052864253520965576\n",
      "episode: 3086/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.007810354232788086\n",
      "episode: 3087/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 3088/6000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 0.038069188594818115\n",
      "episode: 3089/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3090/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3091/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.890953242778778\n",
      "episode: 3092/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3093/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.625367164611816\n",
      "episode: 3094/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 8.00022178888321\n",
      "episode: 3095/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3096/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3097/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3098/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3099/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 9.995790541172028\n",
      "episode: 3100/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3101/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3102/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3103/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.01290583610534668\n",
      "episode: 3104/6000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 0.0050199031829833984\n",
      "episode: 3105/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.977048635482788\n",
      "episode: 3106/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3107/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 7.996182978153229\n",
      "episode: 3108/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.00019949674606323242\n",
      "episode: 3109/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 10.510717570781708\n",
      "episode: 3110/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3111/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.48288464546203613\n",
      "episode: 3112/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3113/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 20.47580099105835\n",
      "episode: 3114/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 9.929687678813934\n",
      "episode: 3115/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3116/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.020407378673553467\n",
      "episode: 3117/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3118/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 8.015499711036682\n",
      "episode: 3119/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 7.976562559604645\n",
      "episode: 3120/6000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3121/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.04890763759613037\n",
      "episode: 3122/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.33037078380584717\n",
      "episode: 3123/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3124/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3125/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3126/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3127/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.01939910650253296\n",
      "episode: 3128/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 9.945318758487701\n",
      "episode: 3129/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.5593228340148926\n",
      "episode: 3130/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0003998875617980957\n",
      "episode: 3131/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3132/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3133/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 15.335716247558594\n",
      "episode: 3134/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 10.540977537631989\n",
      "episode: 3135/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 10.01406466960907\n",
      "episode: 3136/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 17.958313822746277\n",
      "episode: 3137/6000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 3138/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3139/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.960950374603271\n",
      "episode: 3140/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.019959151744843\n",
      "episode: 3141/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 1.0220683217048645\n",
      "episode: 3142/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.281695187091827\n",
      "episode: 3143/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.02187258005142212\n",
      "episode: 3144/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3145/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3146/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.98440420627594\n",
      "episode: 3147/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.984268605709076\n",
      "episode: 3148/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 7.996093809604645\n",
      "episode: 3149/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.013178825378418\n",
      "episode: 3150/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.001132965087890625\n",
      "episode: 3151/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 10.288595020771027\n",
      "episode: 3152/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 0.00024890899658203125\n",
      "episode: 3153/6000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3154/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 12.760317087173462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3155/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 2.086162567138672e-06\n",
      "episode: 3156/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 4.172325134277344e-07\n",
      "episode: 3157/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.476671040058136\n",
      "episode: 3158/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3159/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.929902791976929\n",
      "episode: 3160/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.953186273574829\n",
      "episode: 3161/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 10.010620892047882\n",
      "episode: 3162/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.023285746574401855\n",
      "episode: 3163/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 7.703198552131653\n",
      "episode: 3164/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.453125\n",
      "episode: 3165/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3166/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 0.2911747694015503\n",
      "episode: 3167/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3168/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.477473199367523\n",
      "episode: 3169/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 1.1920928955078125e-06\n",
      "episode: 3170/6000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 9.984542429447174\n",
      "episode: 3171/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.976880073547363\n",
      "episode: 3172/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.976605296134949\n",
      "episode: 3173/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 3174/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3175/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 3176/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.5229052305221558\n",
      "episode: 3177/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 2.384185791015625e-07\n",
      "episode: 3178/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3179/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 10.02502852678299\n",
      "episode: 3180/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3181/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3182/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3183/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 21.019914209842682\n",
      "episode: 3184/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3185/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.01242828369140625\n",
      "episode: 3186/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.007995784282684326\n",
      "episode: 3187/6000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3188/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.002904355525970459\n",
      "episode: 3189/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3190/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3191/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.00014460086822509766\n",
      "episode: 3192/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3193/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.461202681064606\n",
      "episode: 3194/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.98929238319397\n",
      "episode: 3195/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3196/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3197/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.976786077022552\n",
      "episode: 3198/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3199/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3200/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0009940862655639648\n",
      "episode: 3201/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 10.006796300411224\n",
      "episode: 3202/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.898255586624146\n",
      "episode: 3203/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3204/6000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3205/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.5731899738311768\n",
      "episode: 3206/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 21.423574805259705\n",
      "episode: 3207/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 45.558514177799225\n",
      "episode: 3208/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 10.126222252845764\n",
      "episode: 3209/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.55523681640625\n",
      "episode: 3210/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.2768630385398865\n",
      "episode: 3211/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3212/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.007305264472961426\n",
      "episode: 3213/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 10.007713258266449\n",
      "episode: 3214/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3215/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 2.129150390625\n",
      "episode: 3216/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3217/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.12475639581680298\n",
      "episode: 3218/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3219/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.984264433383942\n",
      "episode: 3220/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 0.007843554019927979\n",
      "episode: 3221/6000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 9.984232902526855\n",
      "episode: 3222/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.4905242919921875\n",
      "episode: 3223/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.001060187816619873\n",
      "episode: 3224/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 7.9452128410339355\n",
      "episode: 3225/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 9.991264343261719\n",
      "episode: 3226/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0008729100227355957\n",
      "episode: 3227/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3228/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3229/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 18.506797969341278\n",
      "episode: 3230/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3231/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3232/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 9.917934596538544\n",
      "episode: 3233/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0035228729248046875\n",
      "episode: 3234/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.4813254475593567\n",
      "episode: 3235/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.007773637771606445\n",
      "episode: 3236/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.012096285820007324\n",
      "episode: 3237/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 20.474269151687622\n",
      "episode: 3238/6000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3239/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3240/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 3241/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3242/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.99243575334549\n",
      "episode: 3243/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3244/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3245/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 1.3113021850585938e-06\n",
      "episode: 3246/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.44049072265625\n",
      "episode: 3247/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3248/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3249/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 1.823902130126953e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3250/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3251/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.976836204528809\n",
      "episode: 3252/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.27685546875\n",
      "episode: 3253/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 1.4901161193847656e-06\n",
      "episode: 3254/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 20.18142718076706\n",
      "episode: 3255/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3256/6000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 9.925299644470215\n",
      "episode: 3257/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.6328125\n",
      "episode: 3258/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3259/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.8359375\n",
      "episode: 3260/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 1.8680357336997986\n",
      "episode: 3261/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.992405891418457\n",
      "episode: 3262/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 10.101320028305054\n",
      "episode: 3263/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.129852294921875\n",
      "episode: 3264/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.484376847743988\n",
      "episode: 3265/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 8.616096556186676\n",
      "episode: 3266/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3267/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3268/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.981636047363281\n",
      "episode: 3269/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 20.51908642053604\n",
      "episode: 3270/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.988983631134033\n",
      "episode: 3271/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 9.976884067058563\n",
      "episode: 3272/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 7.688787758350372\n",
      "episode: 3273/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3274/6000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.1281346082687378\n",
      "episode: 3275/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 10.318251252174377\n",
      "episode: 3276/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.18140578269958496\n",
      "episode: 3277/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 32.30681598186493\n",
      "episode: 3278/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 2.1191139221191406\n",
      "episode: 3279/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.9848672747612\n",
      "episode: 3280/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.40626972913742\n",
      "episode: 3281/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 7.98080974817276\n",
      "episode: 3282/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 7.3112513422966\n",
      "episode: 3283/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3284/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3285/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3286/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 10.052670001983643\n",
      "episode: 3287/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3288/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 8.000006318092346\n",
      "episode: 3289/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3290/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 10.001465082168579\n",
      "episode: 3291/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 0.012420058250427246\n",
      "episode: 3292/6000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 9.976675510406494\n",
      "episode: 3293/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 10.03224778175354\n",
      "episode: 3294/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3295/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 3296/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 7.2706605195999146\n",
      "episode: 3297/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3298/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 7.2995264530181885\n",
      "episode: 3299/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3300/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.976571023464203\n",
      "episode: 3301/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3302/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3303/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3304/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 9.873501479625702\n",
      "episode: 3305/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.029806554317474365\n",
      "episode: 3306/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 11.94140762090683\n",
      "episode: 3307/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3308/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 2.960601806640625\n",
      "episode: 3309/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3310/6000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3311/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.6472853422164917\n",
      "episode: 3312/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 6.556510925292969e-07\n",
      "episode: 3313/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 11.195808410644531\n",
      "episode: 3314/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3315/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.976927101612091\n",
      "episode: 3316/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 1.7881393432617188e-06\n",
      "episode: 3317/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.008495867252349854\n",
      "episode: 3318/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.984618663787842\n",
      "episode: 3319/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.844238638877869\n",
      "episode: 3320/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3321/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 127.59277778863907\n",
      "episode: 3322/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 11.343701004981995\n",
      "episode: 3323/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 10.818368077278137\n",
      "episode: 3324/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.47216796875\n",
      "episode: 3325/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3326/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.887287139892578\n",
      "episode: 3327/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 11.945205748081207\n",
      "episode: 3328/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3329/6000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 3330/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 21.898529946804047\n",
      "episode: 3331/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.976568460464478\n",
      "episode: 3332/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3333/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 10.310855329036713\n",
      "episode: 3334/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 10.000126242637634\n",
      "episode: 3335/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.012717962265014648\n",
      "episode: 3336/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 10.002061486244202\n",
      "episode: 3337/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.7109375\n",
      "episode: 3338/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3339/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.98138439655304\n",
      "episode: 3340/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.71875\n",
      "episode: 3341/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 10.048463463783264\n",
      "episode: 3342/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.99696969985962\n",
      "episode: 3343/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3344/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 5.558962821960449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3345/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.5396919846534729\n",
      "episode: 3346/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.026673316955566406\n",
      "episode: 3347/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 0.0012527108192443848\n",
      "episode: 3348/6000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 9.934240698814392\n",
      "episode: 3349/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.005174756050109863\n",
      "episode: 3350/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3351/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3352/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 8.294825434684753\n",
      "episode: 3353/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3354/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3355/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0007914304733276367\n",
      "episode: 3356/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3357/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3358/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3359/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 8.190367758274078\n",
      "episode: 3360/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.927680909633636\n",
      "episode: 3361/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 18.007240533828735\n",
      "episode: 3362/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.9769327044487\n",
      "episode: 3363/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.493575155735016\n",
      "episode: 3364/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 10.27685546875\n",
      "episode: 3365/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3366/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3367/6000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3368/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3369/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3370/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3371/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.89033156633377\n",
      "episode: 3372/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3373/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 12.770275890827179\n",
      "episode: 3374/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 10.616462111473083\n",
      "episode: 3375/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 10.07804423570633\n",
      "episode: 3376/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 10.027177333831787\n",
      "episode: 3377/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.976569175720215\n",
      "episode: 3378/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.5\n",
      "episode: 3379/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3380/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.007707953453063965\n",
      "episode: 3381/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3382/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3383/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 9.805065631866455\n",
      "episode: 3384/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 10.076347291469574\n",
      "episode: 3385/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 4.172325134277344e-07\n",
      "episode: 3386/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3387/6000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 13.459117889404297\n",
      "episode: 3388/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 10.308749198913574\n",
      "episode: 3389/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 7.179809987545013\n",
      "episode: 3390/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 19.95333021879196\n",
      "episode: 3391/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.02798163890838623\n",
      "episode: 3392/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 8.076846599578857\n",
      "episode: 3393/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 3394/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 3.0994415283203125e-06\n",
      "episode: 3395/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.015397429466247559\n",
      "episode: 3396/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.890627920627594\n",
      "episode: 3397/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3398/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.5367431640625e-07\n",
      "episode: 3399/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 10.046008706092834\n",
      "episode: 3400/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 9.517399787902832\n",
      "episode: 3401/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 7.457633018493652\n",
      "episode: 3402/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3403/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 7.81865131855011\n",
      "episode: 3404/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 8.002779841423035\n",
      "episode: 3405/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 10.008865714073181\n",
      "episode: 3406/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3407/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3408/6000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3409/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3410/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.29236817359924316\n",
      "episode: 3411/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.890629351139069\n",
      "episode: 3412/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3413/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.926085114479065\n",
      "episode: 3414/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 21.491751611232758\n",
      "episode: 3415/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 8.75450849533081\n",
      "episode: 3416/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 10.070068359375\n",
      "episode: 3417/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.953105032444\n",
      "episode: 3418/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.687506318092346\n",
      "episode: 3419/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3420/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3421/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 1.9073486328125e-06\n",
      "episode: 3422/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3423/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 6.006755828857422\n",
      "episode: 3424/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 647.9161807894707\n",
      "episode: 3425/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 9.593969941139221\n",
      "episode: 3426/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 20.772157549858093\n",
      "episode: 3427/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 10.012509047985077\n",
      "episode: 3428/6000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 11.992225885391235\n",
      "episode: 3429/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.996859550476074\n",
      "episode: 3430/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.00019502639770507812\n",
      "episode: 3431/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 8.109935760498047\n",
      "episode: 3432/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.960937738418579\n",
      "episode: 3433/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.90625\n",
      "episode: 3434/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.026545286178588867\n",
      "episode: 3435/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3436/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3437/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.977465152740479\n",
      "episode: 3438/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3439/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3440/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3441/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.5263698697090149\n",
      "episode: 3442/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.956872403621674\n",
      "episode: 3443/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3444/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.973121702671051\n",
      "episode: 3445/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.976570904254913\n",
      "episode: 3446/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 9.710952520370483\n",
      "episode: 3447/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3448/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3449/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3450/6000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 22.4531689286232\n",
      "episode: 3451/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 10.820793271064758\n",
      "episode: 3452/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3453/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 4.4405460357666016e-05\n",
      "episode: 3454/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 2.2530555725097656e-05\n",
      "episode: 3455/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3456/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.9989492893219\n",
      "episode: 3457/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 6.852232217788696\n",
      "episode: 3458/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3459/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 10.001301288604736\n",
      "episode: 3460/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.977271914482117\n",
      "episode: 3461/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3462/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 0.016010820865631104\n",
      "episode: 3463/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3464/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.1640625\n",
      "episode: 3465/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 18.185806274414062\n",
      "episode: 3466/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.8397216796875\n",
      "episode: 3467/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.843760311603546\n",
      "episode: 3468/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 8.018178641796112\n",
      "episode: 3469/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.945399463176727\n",
      "episode: 3470/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.985505104064941\n",
      "episode: 3471/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3472/6000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 10.848681271076202\n",
      "episode: 3473/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3474/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 16.869569957256317\n",
      "episode: 3475/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 12.889345169067383\n",
      "episode: 3476/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3477/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 10.021789371967316\n",
      "episode: 3478/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3479/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.890629291534424\n",
      "episode: 3480/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.94519954919815\n",
      "episode: 3481/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 10.327746152877808\n",
      "episode: 3482/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 8.217111825942993\n",
      "episode: 3483/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3484/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3485/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 11.966144442558289\n",
      "episode: 3486/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.615045189857483\n",
      "episode: 3487/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 19.044029235839844\n",
      "episode: 3488/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3489/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3490/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.469020128250122\n",
      "episode: 3491/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 0.468994140625\n",
      "episode: 3492/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 9.978554666042328\n",
      "episode: 3493/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3494/6000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 10.009611010551453\n",
      "episode: 3495/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.011795520782470703\n",
      "episode: 3496/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3497/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3498/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3499/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3500/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.981502532958984\n",
      "episode: 3501/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3502/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3503/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3504/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.013433933258057\n",
      "episode: 3505/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 3506/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.953136026859283\n",
      "episode: 3507/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3508/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3509/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.84619140625\n",
      "episode: 3510/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 8.377937316894531\n",
      "episode: 3511/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 3512/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3513/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.05310404300689697\n",
      "episode: 3514/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.025818705558777\n",
      "episode: 3515/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3516/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 17.65384179353714\n",
      "episode: 3517/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 9.976616382598877\n",
      "episode: 3518/6000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 10.009552001953125\n",
      "episode: 3519/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3520/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3521/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3522/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3523/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.976564407348633\n",
      "episode: 3524/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.978463172912598\n",
      "episode: 3525/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3526/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.07530468702316284\n",
      "episode: 3527/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3528/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.9769566655159\n",
      "episode: 3529/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.12800908088684082\n",
      "episode: 3530/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 3531/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3532/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 12.009771764278412\n",
      "episode: 3533/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.859641790390015\n",
      "episode: 3534/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.9765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3535/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.976569294929504\n",
      "episode: 3536/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.020255565643310547\n",
      "episode: 3537/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3538/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.97656637430191\n",
      "episode: 3539/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3540/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.97658920288086\n",
      "episode: 3541/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 9.988983452320099\n",
      "episode: 3542/6000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3543/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3544/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3545/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3546/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3547/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.94534718990326\n",
      "episode: 3548/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 7.152557373046875e-07\n",
      "episode: 3549/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3550/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.89062511920929\n",
      "episode: 3551/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3552/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 14.80371105670929\n",
      "episode: 3553/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3554/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.898606836795807\n",
      "episode: 3555/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3556/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.968750059604645\n",
      "episode: 3557/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 12.006591796875\n",
      "episode: 3558/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.977390170097351\n",
      "episode: 3559/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3560/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 16.907203674316406\n",
      "episode: 3561/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 10.008027076721191\n",
      "episode: 3562/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 10.636150300502777\n",
      "episode: 3563/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 3564/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 10.101326048374176\n",
      "episode: 3565/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3566/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 10.012486815452576\n",
      "episode: 3567/6000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 15.435760736465454\n",
      "episode: 3568/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 3569/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3570/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 18.224600076675415\n",
      "episode: 3571/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3572/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3573/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3574/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.015804648399353\n",
      "episode: 3575/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.94553005695343\n",
      "episode: 3576/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3577/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.8046875\n",
      "episode: 3578/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 11.76194441318512\n",
      "episode: 3579/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 11.954107642173767\n",
      "episode: 3580/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0015118718147277832\n",
      "episode: 3581/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.882568359375\n",
      "episode: 3582/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.969970703125\n",
      "episode: 3583/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3584/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.976569175720215\n",
      "episode: 3585/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.87527322769165\n",
      "episode: 3586/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.890820860862732\n",
      "episode: 3587/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 7.232865333557129\n",
      "episode: 3588/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.976564586162567\n",
      "episode: 3589/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3590/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 3591/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.926306247711182\n",
      "episode: 3592/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.976568400859833\n",
      "episode: 3593/6000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3594/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0004298090934753418\n",
      "episode: 3595/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3596/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3597/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 3598/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.98211669921875\n",
      "episode: 3599/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 10.1683349609375\n",
      "episode: 3600/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3601/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3602/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.976562678813934\n",
      "episode: 3603/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 11.961870849132538\n",
      "episode: 3604/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 1.965120255947113\n",
      "episode: 3605/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3606/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3607/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 3608/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3609/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 10.08960509300232\n",
      "episode: 3610/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 10.037489414215088\n",
      "episode: 3611/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 20.322265625\n",
      "episode: 3612/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3613/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 11.83642578125\n",
      "episode: 3614/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 1.430511474609375e-06\n",
      "episode: 3615/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 1.9775390625\n",
      "episode: 3616/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.999847412109375\n",
      "episode: 3617/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.978553712368011\n",
      "episode: 3618/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3619/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3620/6000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 9.993683934211731\n",
      "episode: 3621/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3622/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 8.19091796875\n",
      "episode: 3623/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 3624/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3625/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3626/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 7.41035670042038\n",
      "episode: 3627/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 10.00000011920929\n",
      "episode: 3628/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.976614773273468\n",
      "episode: 3629/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.890625059604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3630/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 10.324539184570312\n",
      "episode: 3631/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.04741322994232178\n",
      "episode: 3632/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.551474571228027\n",
      "episode: 3633/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3634/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3635/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.515625\n",
      "episode: 3636/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3637/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 10.052030086517334\n",
      "episode: 3638/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.330537796020508\n",
      "episode: 3639/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.976568639278412\n",
      "episode: 3640/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.000797271728515625\n",
      "episode: 3641/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.97848230600357\n",
      "episode: 3642/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 7.256137847900391\n",
      "episode: 3643/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 11.95492559671402\n",
      "episode: 3644/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.976830005645752\n",
      "episode: 3645/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 0.11252492666244507\n",
      "episode: 3646/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 2.0526123642921448\n",
      "episode: 3647/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.976562917232513\n",
      "episode: 3648/6000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3649/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 7.445800840854645\n",
      "episode: 3650/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.976658999919891\n",
      "episode: 3651/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.476562559604645\n",
      "episode: 3652/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3653/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3654/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3655/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3656/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 3657/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3658/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 19.827133178710938\n",
      "episode: 3659/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 11.260978698730469\n",
      "episode: 3660/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3661/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 10.001642227172852\n",
      "episode: 3662/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 11.96383672952652\n",
      "episode: 3663/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.51171875\n",
      "episode: 3664/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.976579070091248\n",
      "episode: 3665/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.976562678813934\n",
      "episode: 3666/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4.291534423828125e-06\n",
      "episode: 3667/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3668/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 10.100624084472656\n",
      "episode: 3669/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 10.172441840171814\n",
      "episode: 3670/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3671/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3672/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 10.16982614994049\n",
      "episode: 3673/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 10.343994140625\n",
      "episode: 3674/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 3675/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.528427124023438\n",
      "episode: 3676/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3677/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3678/6000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 0.33251953125\n",
      "episode: 3679/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 7.5674285888671875\n",
      "episode: 3680/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 10.587514996528625\n",
      "episode: 3681/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.977231919765472\n",
      "episode: 3682/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.97673386335373\n",
      "episode: 3683/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 3684/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.1640625\n",
      "episode: 3685/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 8.572858810424805\n",
      "episode: 3686/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3687/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.976680338382721\n",
      "episode: 3688/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3689/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3690/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.976562678813934\n",
      "episode: 3691/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3692/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3693/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 10.05999755859375\n",
      "episode: 3694/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.978357315063477\n",
      "episode: 3695/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 3696/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 3697/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3698/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.904356718063354\n",
      "episode: 3699/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 3700/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 8.535385131835938e-05\n",
      "episode: 3701/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3702/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3703/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.395349740982056\n",
      "episode: 3704/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 10.010467529296875\n",
      "episode: 3705/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3706/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3707/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.97702693939209\n",
      "episode: 3708/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.891670942306519\n",
      "episode: 3709/6000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 9.488235473632812\n",
      "episode: 3710/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3711/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 12.063720703125\n",
      "episode: 3712/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 5.169189453125\n",
      "episode: 3713/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.898819208145142\n",
      "episode: 3714/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.06134033203125\n",
      "episode: 3715/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.253923416137695\n",
      "episode: 3716/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3717/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.7329788208007812\n",
      "episode: 3718/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.007707059383392\n",
      "episode: 3719/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.976841449737549\n",
      "episode: 3720/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.893263578414917\n",
      "episode: 3721/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3722/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.022201538085938\n",
      "episode: 3723/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3724/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.1640625\n",
      "episode: 3725/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.427970886230469\n",
      "episode: 3726/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.268836975097656\n",
      "episode: 3727/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 3728/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3729/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.91406923532486\n",
      "episode: 3730/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3731/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3732/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.14221757650375366\n",
      "episode: 3733/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3734/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3735/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 3736/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.976448059082031\n",
      "episode: 3737/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3738/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 3.6447190642356873\n",
      "episode: 3739/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.149658203125\n",
      "episode: 3740/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3741/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3742/6000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 31.674167096614838\n",
      "episode: 3743/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 8.0234375\n",
      "episode: 3744/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.484375357627869\n",
      "episode: 3745/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.976842403411865\n",
      "episode: 3746/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.953150033950806\n",
      "episode: 3747/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.97848892211914\n",
      "episode: 3748/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 3749/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3750/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 1.806020736694336e-05\n",
      "episode: 3751/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 6.83164781332016\n",
      "episode: 3752/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 6.981542885303497\n",
      "episode: 3753/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 10.471245050430298\n",
      "episode: 3754/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.97657722234726\n",
      "episode: 3755/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 3756/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 10.67706698179245\n",
      "episode: 3757/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.890794038772583\n",
      "episode: 3758/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.036961495876312256\n",
      "episode: 3759/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3760/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3761/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 11.9881831407547\n",
      "episode: 3762/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3763/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 12.032863020896912\n",
      "episode: 3764/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 19.721540093421936\n",
      "episode: 3765/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 13.589852094650269\n",
      "episode: 3766/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.981487274169922\n",
      "episode: 3767/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.976569950580597\n",
      "episode: 3768/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3769/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 8.711023330688477\n",
      "episode: 3770/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 8.728554666042328\n",
      "episode: 3771/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3772/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3773/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.930267930030823\n",
      "episode: 3774/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3775/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.8359375\n",
      "episode: 3776/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 28.013855814933777\n",
      "episode: 3777/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 10.002349853515625\n",
      "episode: 3778/6000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 9.968768775463104\n",
      "episode: 3779/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.978555142879486\n",
      "episode: 3780/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 12.006804466247559\n",
      "episode: 3781/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 10.022689819335938\n",
      "episode: 3782/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3783/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.97656786441803\n",
      "episode: 3784/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.5497875213623047\n",
      "episode: 3785/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3786/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.994026184082031\n",
      "episode: 3787/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.976568400859833\n",
      "episode: 3788/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 20.42711067199707\n",
      "episode: 3789/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.989375412464142\n",
      "episode: 3790/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0001544952392578125\n",
      "episode: 3791/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0011292099952697754\n",
      "episode: 3792/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 8.573828220367432\n",
      "episode: 3793/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 19.959317207336426\n",
      "episode: 3794/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 10.068038940429688\n",
      "episode: 3795/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 8.043757438659668\n",
      "episode: 3796/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3797/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3798/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3799/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 10.74420166015625\n",
      "episode: 3800/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3801/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 13.889593780040741\n",
      "episode: 3802/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 10.061403274536133\n",
      "episode: 3803/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 8.086143493652344\n",
      "episode: 3804/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 19.972213745117188\n",
      "episode: 3805/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 10.0606689453125\n",
      "episode: 3806/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 1.9649402499198914\n",
      "episode: 3807/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3808/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 12.040313124656677\n",
      "episode: 3809/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3810/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.976567685604095\n",
      "episode: 3811/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 12.46685940027237\n",
      "episode: 3812/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0008663535118103027\n",
      "episode: 3813/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3814/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 0.12699323892593384\n",
      "episode: 3815/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.734479248523712\n",
      "episode: 3816/6000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 9.890625\n",
      "episode: 3817/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.28662109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3818/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 17.85608071088791\n",
      "episode: 3819/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 8.036991536617279\n",
      "episode: 3820/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 17.97665899991989\n",
      "episode: 3821/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.968750238418579\n",
      "episode: 3822/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.476562559604645\n",
      "episode: 3823/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.271494150161743\n",
      "episode: 3824/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 11.954689621925354\n",
      "episode: 3825/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.488256454467773\n",
      "episode: 3826/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4.891767382621765\n",
      "episode: 3827/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.023328006267548\n",
      "episode: 3828/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3829/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3830/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3831/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.968750357627869\n",
      "episode: 3832/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 1.3423742651939392\n",
      "episode: 3833/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3834/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.988999724388123\n",
      "episode: 3835/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 3.0994415283203125e-06\n",
      "episode: 3836/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.965675592422485\n",
      "episode: 3837/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.062342286109924316\n",
      "episode: 3838/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976564407348633\n",
      "episode: 3839/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.999008178710938\n",
      "episode: 3840/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 19.965678930282593\n",
      "episode: 3841/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3842/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.002182185649872\n",
      "episode: 3843/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 7.931232452392578\n",
      "episode: 3844/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976563096046448\n",
      "episode: 3845/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.988999724388123\n",
      "episode: 3846/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.986367285251617\n",
      "episode: 3847/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3848/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3849/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976562857627869\n",
      "episode: 3850/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3851/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 21.051611602306366\n",
      "episode: 3852/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 3853/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.254611134529114\n",
      "episode: 3854/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3855/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 3856/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 8.678369283676147\n",
      "episode: 3857/6000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 9.84375149011612\n",
      "episode: 3858/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 6.8984375\n",
      "episode: 3859/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 12.772084593772888\n",
      "episode: 3860/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 7.200101375579834\n",
      "episode: 3861/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 17.98777574300766\n",
      "episode: 3862/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.987373352050781\n",
      "episode: 3863/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 7.298363447189331\n",
      "episode: 3864/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.0982346534729\n",
      "episode: 3865/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3866/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.8681640625\n",
      "episode: 3867/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.671095728874207\n",
      "episode: 3868/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 19.9761962890625\n",
      "episode: 3869/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.983390808105469\n",
      "episode: 3870/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 3871/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 19.953404903411865\n",
      "episode: 3872/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.97656512260437\n",
      "episode: 3873/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.987756729125977\n",
      "episode: 3874/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3875/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3876/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.004357933998108\n",
      "episode: 3877/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.06134033203125\n",
      "episode: 3878/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 15.673258244991302\n",
      "episode: 3879/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 20.001918375492096\n",
      "episode: 3880/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 9.976903200149536\n",
      "episode: 3881/6000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 10.59580111503601\n",
      "episode: 3882/6000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 10.047487139701843\n",
      "episode: 3883/6000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 10.144537150859833\n",
      "episode: 3884/6000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 10.220605731010437\n",
      "episode: 3885/6000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 9.888644337654114\n",
      "episode: 3886/6000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 8.006832122802734\n",
      "episode: 3887/6000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 10.31787109375\n",
      "episode: 3888/6000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 9.976562857627869\n",
      "episode: 3889/6000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 11.623179852962494\n",
      "episode: 3890/6000, steps: 500, e: 0.098\n",
      "accumulated_rewards_per_episode: 20.131210923194885\n",
      "episode: 3891/6000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 3892/6000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3893/6000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 8.155610740184784\n",
      "episode: 3894/6000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 18.972293853759766\n",
      "episode: 3895/6000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 26.459688365459442\n",
      "episode: 3896/6000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 9.97656399011612\n",
      "episode: 3897/6000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 3898/6000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 11.74503231048584\n",
      "episode: 3899/6000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 17.587453424930573\n",
      "episode: 3900/6000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3901/6000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3902/6000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 10.000025272369385\n",
      "episode: 3903/6000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 9.6875\n",
      "episode: 3904/6000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 19.437501668930054\n",
      "episode: 3905/6000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 7.708251953125\n",
      "episode: 3906/6000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 9.547393798828125\n",
      "episode: 3907/6000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 3908/6000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 8.19091796875\n",
      "episode: 3909/6000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 24.040558338165283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 3910/6000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 3911/6000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 12.835788011550903\n",
      "episode: 3912/6000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 18.50065290927887\n",
      "episode: 3913/6000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 7.478005647659302\n",
      "episode: 3914/6000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 20.169339418411255\n",
      "episode: 3915/6000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3916/6000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 0.1828455924987793\n",
      "episode: 3917/6000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 10.053549468517303\n",
      "episode: 3918/6000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 19.95775032043457\n",
      "episode: 3919/6000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 9.97656387090683\n",
      "episode: 3920/6000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 10.10131984949112\n",
      "episode: 3921/6000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 9.976562798023224\n",
      "episode: 3922/6000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 9.882826149463654\n",
      "episode: 3923/6000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 3924/6000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 10.004607915878296\n",
      "episode: 3925/6000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 18.01726108789444\n",
      "episode: 3926/6000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 17.984404742717743\n",
      "episode: 3927/6000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 20.015274107456207\n",
      "episode: 3928/6000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 9.969581604003906\n",
      "episode: 3929/6000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 30.290045142173767\n",
      "episode: 3930/6000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3931/6000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 10.101425468921661\n",
      "episode: 3932/6000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 35.57962906360626\n",
      "episode: 3933/6000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 49.21405470371246\n",
      "episode: 3934/6000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 32.10125756263733\n",
      "episode: 3935/6000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 8.755958557128906\n",
      "episode: 3936/6000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 9.976836442947388\n",
      "episode: 3937/6000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 3938/6000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 10.06072998046875\n",
      "episode: 3939/6000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3940/6000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 3941/6000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 20.833445250988007\n",
      "episode: 3942/6000, steps: 500, e: 0.087\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3943/6000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 36.67214035987854\n",
      "episode: 3944/6000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 17.849674224853516\n",
      "episode: 3945/6000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 12.668045222759247\n",
      "episode: 3946/6000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 9.976604640483856\n",
      "episode: 3947/6000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3948/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 11.538871765136719\n",
      "episode: 3949/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 6.960702419281006\n",
      "episode: 3950/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 30.1802197098732\n",
      "episode: 3951/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 3952/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 7.117345035076141\n",
      "episode: 3953/6000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 39.757475793361664\n",
      "episode: 3954/6000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 10.101455628871918\n",
      "episode: 3955/6000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3956/6000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 10.344084918498993\n",
      "episode: 3957/6000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 5.390640020370483\n",
      "episode: 3958/6000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3959/6000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 19.937594175338745\n",
      "episode: 3960/6000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.890625953674316\n",
      "episode: 3961/6000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.98465895652771\n",
      "episode: 3962/6000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 19.978411853313446\n",
      "episode: 3963/6000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 9.761962890625\n",
      "episode: 3964/6000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 9.976835012435913\n",
      "episode: 3965/6000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 10.000006079673767\n",
      "episode: 3966/6000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 7.160597383975983\n",
      "episode: 3967/6000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3968/6000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 19.95313388109207\n",
      "episode: 3969/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 7.186576843261719\n",
      "episode: 3970/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.976568520069122\n",
      "episode: 3971/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 19.885139644145966\n",
      "episode: 3972/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 3973/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.976698517799377\n",
      "episode: 3974/6000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 9.976588785648346\n",
      "episode: 3975/6000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 9.679693162441254\n",
      "episode: 3976/6000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 19.953248381614685\n",
      "episode: 3977/6000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 9.976670920848846\n",
      "episode: 3978/6000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 19.95312511920929\n",
      "episode: 3979/6000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 3980/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3981/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 0.01939445734024048\n",
      "episode: 3982/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 12.847976684570312\n",
      "episode: 3983/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 0.0019099712371826172\n",
      "episode: 3984/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 2.324828624725342\n",
      "episode: 3985/6000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 20.019688606262207\n",
      "episode: 3986/6000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 13.968978881835938\n",
      "episode: 3987/6000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 20.12788987159729\n",
      "episode: 3988/6000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 20.39420735836029\n",
      "episode: 3989/6000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 7.893117785453796\n",
      "episode: 3990/6000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 9.89147174358368\n",
      "episode: 3991/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3992/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 3993/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 39.144256949424744\n",
      "episode: 3994/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 29.83075487613678\n",
      "episode: 3995/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 32.711856961250305\n",
      "episode: 3996/6000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 12.418383002281189\n",
      "episode: 3997/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 12.753913819789886\n",
      "episode: 3998/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 9.976562559604645\n",
      "episode: 3999/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 20.00799661874771\n",
      "episode: 4000/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4001/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 9.97660481929779\n",
      "episode: 4002/6000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 0.8797281384468079\n",
      "episode: 4003/6000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 0.12488937377929688\n",
      "episode: 4004/6000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 9.97659021615982\n",
      "episode: 4005/6000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 9.936489403247833\n",
      "episode: 4006/6000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 10.1119384765625\n",
      "episode: 4007/6000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4008/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 20.09716886281967\n",
      "episode: 4009/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 9.890822172164917\n",
      "episode: 4010/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 12.609373807907104\n",
      "episode: 4011/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4012/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4013/6000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 20.30328369140625\n",
      "episode: 4014/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 19.976943254470825\n",
      "episode: 4015/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 20.15801250934601\n",
      "episode: 4016/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 9.97683048248291\n",
      "episode: 4017/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 20.243623733520508\n",
      "episode: 4018/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 10.0604248046875\n",
      "episode: 4019/6000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 4020/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 0.4373641014099121\n",
      "episode: 4021/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4022/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 39.95076560974121\n",
      "episode: 4023/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4024/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 20.02716416120529\n",
      "episode: 4025/6000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 9.945850849151611\n",
      "episode: 4026/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 19.954078674316406\n",
      "episode: 4027/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 10.309810042381287\n",
      "episode: 4028/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 10.432646572589874\n",
      "episode: 4029/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 10.30908203125\n",
      "episode: 4030/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 31.217175602912903\n",
      "episode: 4031/6000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 67.87357515096664\n",
      "episode: 4032/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 9.976562738418579\n",
      "episode: 4033/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 4034/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 9.493181228637695\n",
      "episode: 4035/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4036/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 23.373046875\n",
      "episode: 4037/6000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 17.976671874523163\n",
      "episode: 4038/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 12.823022842407227\n",
      "episode: 4039/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 10.027359008789062\n",
      "episode: 4040/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 9.978453636169434\n",
      "episode: 4041/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 22.881720185279846\n",
      "episode: 4042/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 4043/6000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 9.105015277862549\n",
      "episode: 4044/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 4045/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 10.28662109375\n",
      "episode: 4046/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 19.931573033332825\n",
      "episode: 4047/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 23.866118371486664\n",
      "episode: 4048/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 30.124459266662598\n",
      "episode: 4049/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 29.978447914123535\n",
      "episode: 4050/6000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 44.72936421632767\n",
      "episode: 4051/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 0.00767284631729126\n",
      "episode: 4052/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 3.8128181099891663\n",
      "episode: 4053/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 17.318550169467926\n",
      "episode: 4054/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 18.99646121263504\n",
      "episode: 4055/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 26.37103044986725\n",
      "episode: 4056/6000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 3.294638454914093\n",
      "episode: 4057/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 9.981700897216797\n",
      "episode: 4058/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 19.976573824882507\n",
      "episode: 4059/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 22.946299195289612\n",
      "episode: 4060/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 19.924025774002075\n",
      "episode: 4061/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 19.867384672164917\n",
      "episode: 4062/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 10.011581420898438\n",
      "episode: 4063/6000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 18.687507927417755\n",
      "episode: 4064/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 0.0007297992706298828\n",
      "episode: 4065/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 19.955011785030365\n",
      "episode: 4066/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 19.964332580566406\n",
      "episode: 4067/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 19.825005531311035\n",
      "episode: 4068/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 20.34735107421875\n",
      "episode: 4069/6000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 9.88072544336319\n",
      "episode: 4070/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4071/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 19.981201171875\n",
      "episode: 4072/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 19.953166007995605\n",
      "episode: 4073/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 4074/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 12.811058044433594\n",
      "episode: 4075/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 19.882813453674316\n",
      "episode: 4076/6000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 10.00000137090683\n",
      "episode: 4077/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 9.4375\n",
      "episode: 4078/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 19.953131198883057\n",
      "episode: 4079/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 4080/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 19.95339298248291\n",
      "episode: 4081/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 22.744146823883057\n",
      "episode: 4082/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 20.91564118862152\n",
      "episode: 4083/6000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4084/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 19.955010414123535\n",
      "episode: 4085/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 17.203617453575134\n",
      "episode: 4086/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 33.418418526649475\n",
      "episode: 4087/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 29.577810883522034\n",
      "episode: 4088/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 11.044546127319336\n",
      "episode: 4089/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 9.843751430511475\n",
      "episode: 4090/6000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 19.454113960266113\n",
      "episode: 4091/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 17.390790462493896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4092/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 7.260246276855469\n",
      "episode: 4093/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4094/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 19.953068494796753\n",
      "episode: 4095/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 8.242795526981354\n",
      "episode: 4096/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4097/6000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 10.006068110466003\n",
      "episode: 4098/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 10.853823244571686\n",
      "episode: 4099/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 19.965783178806305\n",
      "episode: 4100/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 19.169379711151123\n",
      "episode: 4101/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 4102/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 36.4793746471405\n",
      "episode: 4103/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 19.973590075969696\n",
      "episode: 4104/6000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4105/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 19.953601002693176\n",
      "episode: 4106/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 22.826364398002625\n",
      "episode: 4107/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4108/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4109/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 24.126701295375824\n",
      "episode: 4110/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 80.65564447641373\n",
      "episode: 4111/6000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 135.69627380371094\n",
      "episode: 4112/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4113/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4114/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 4115/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 20.22998046875\n",
      "episode: 4116/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 39.891423523426056\n",
      "episode: 4117/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 28.381118595600128\n",
      "episode: 4118/6000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 20.26318359375\n",
      "episode: 4119/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4120/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 11.975617945194244\n",
      "episode: 4121/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 21.986129760742188\n",
      "episode: 4122/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 3.2067298889160156e-05\n",
      "episode: 4123/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 39.60156261920929\n",
      "episode: 4124/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 9.976568698883057\n",
      "episode: 4125/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 11.595709204673767\n",
      "episode: 4126/6000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 4127/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 19.4140625\n",
      "episode: 4128/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 40.12060546875\n",
      "episode: 4129/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 0.01210719347000122\n",
      "episode: 4130/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 19.9590921998024\n",
      "episode: 4131/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 18.968756079673767\n",
      "episode: 4132/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 19.91406750679016\n",
      "episode: 4133/6000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 20.067812860012054\n",
      "episode: 4134/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 5.6245880126953125\n",
      "episode: 4135/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 8.931603372097015\n",
      "episode: 4136/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 4.1425228118896484e-05\n",
      "episode: 4137/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 20.02227783203125\n",
      "episode: 4138/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 18.43750697374344\n",
      "episode: 4139/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4140/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 66.08094429969788\n",
      "episode: 4141/6000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 41.944013595581055\n",
      "episode: 4142/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 39.89062774181366\n",
      "episode: 4143/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 5.984306335449219e-05\n",
      "episode: 4144/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 9.976565480232239\n",
      "episode: 4145/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4146/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 0.29594337940216064\n",
      "episode: 4147/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 9.98398768901825\n",
      "episode: 4148/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 31.56853359937668\n",
      "episode: 4149/6000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 19.9765625\n",
      "episode: 4150/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 1.935302972793579\n",
      "episode: 4151/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4152/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 0.00014072656631469727\n",
      "episode: 4153/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 0.0009042620658874512\n",
      "episode: 4154/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 19.24244397878647\n",
      "episode: 4155/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4156/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 22.30125594139099\n",
      "episode: 4157/6000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4158/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 644.4557519555092\n",
      "episode: 4159/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 0.4525820016860962\n",
      "episode: 4160/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 56.69118505716324\n",
      "episode: 4161/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 17.289040565490723\n",
      "episode: 4162/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 31.075008630752563\n",
      "episode: 4163/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 19.02241724729538\n",
      "episode: 4164/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4165/6000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 4166/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 9.976618945598602\n",
      "episode: 4167/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 47.11668664216995\n",
      "episode: 4168/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 9.465137481689453\n",
      "episode: 4169/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4170/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 19.414185881614685\n",
      "episode: 4171/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 81.00037038326263\n",
      "episode: 4172/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 13.16348123550415\n",
      "episode: 4173/6000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 19.388671875\n",
      "episode: 4174/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 12.794877767562866\n",
      "episode: 4175/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4176/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4177/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4178/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 10.118408203125\n",
      "episode: 4179/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 9.978975296020508\n",
      "episode: 4180/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 25.78727489709854\n",
      "episode: 4181/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 20.285901188850403\n",
      "episode: 4182/6000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 17.22601318359375\n",
      "episode: 4183/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 17.276853919029236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4184/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 0.005448043346405029\n",
      "episode: 4185/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 12.4453125\n",
      "episode: 4186/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 8.344650268554688e-07\n",
      "episode: 4187/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 37.011291801929474\n",
      "episode: 4188/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 21.917128205299377\n",
      "episode: 4189/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4190/6000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 4191/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 2.7840763330459595\n",
      "episode: 4192/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 39.89065420627594\n",
      "episode: 4193/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 10.0462646484375\n",
      "episode: 4194/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 17.708045959472656\n",
      "episode: 4195/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 20.561477780342102\n",
      "episode: 4196/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 9.841796875\n",
      "episode: 4197/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 39.90652513504028\n",
      "episode: 4198/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 9.976596176624298\n",
      "episode: 4199/6000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 16.83984375\n",
      "episode: 4200/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 4201/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 19.609375\n",
      "episode: 4202/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 9.515666723251343\n",
      "episode: 4203/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 27.322304666042328\n",
      "episode: 4204/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4205/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 10.102093875408173\n",
      "episode: 4206/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 4207/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 4208/6000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 28.202736854553223\n",
      "episode: 4209/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 9.992814898490906\n",
      "episode: 4210/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 40.2682301402092\n",
      "episode: 4211/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 19.9531267285347\n",
      "episode: 4212/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4213/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 22.017343521118164\n",
      "episode: 4214/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 12.712928771972656\n",
      "episode: 4215/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 19.953235685825348\n",
      "episode: 4216/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4217/6000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 4218/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 36.75906103849411\n",
      "episode: 4219/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 9.97656261920929\n",
      "episode: 4220/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 29.581827580928802\n",
      "episode: 4221/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 47.054831802845\n",
      "episode: 4222/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 46.07902866601944\n",
      "episode: 4223/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 29.13144838809967\n",
      "episode: 4224/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 27.910146296024323\n",
      "episode: 4225/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 18.796875\n",
      "episode: 4226/6000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 3.4085496068000793\n",
      "episode: 4227/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 19.593790233135223\n",
      "episode: 4228/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 9.453125\n",
      "episode: 4229/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4230/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 9.976943016052246\n",
      "episode: 4231/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 24.581439971923828\n",
      "episode: 4232/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 10.078369140625\n",
      "episode: 4233/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4234/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4235/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 21.702889025211334\n",
      "episode: 4236/6000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 19.953125059604645\n",
      "episode: 4237/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 20.088289618492126\n",
      "episode: 4238/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4239/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 39.97204953432083\n",
      "episode: 4240/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 20.10699462890625\n",
      "episode: 4241/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 12.47265625\n",
      "episode: 4242/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 21.435424864292145\n",
      "episode: 4243/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 62.81148159503937\n",
      "episode: 4244/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 69.86763888597488\n",
      "episode: 4245/6000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4246/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4247/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 32.76595312356949\n",
      "episode: 4248/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 21.632386803627014\n",
      "episode: 4249/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 19.964080810546875\n",
      "episode: 4250/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 38.03558534383774\n",
      "episode: 4251/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 20.64561575651169\n",
      "episode: 4252/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 55.53019034862518\n",
      "episode: 4253/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 22.75772315263748\n",
      "episode: 4254/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 55.605651676654816\n",
      "episode: 4255/6000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 19.048706114292145\n",
      "episode: 4256/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 29.13287901878357\n",
      "episode: 4257/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 52.58828890323639\n",
      "episode: 4258/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 10.014073848724365\n",
      "episode: 4259/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 82.09305894374847\n",
      "episode: 4260/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 19.953131139278412\n",
      "episode: 4261/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 29.96660614013672\n",
      "episode: 4262/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 55.72258424758911\n",
      "episode: 4263/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 50.27620315551758\n",
      "episode: 4264/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 154.34837424755096\n",
      "episode: 4265/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 10.429931640625\n",
      "episode: 4266/6000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 19.953238010406494\n",
      "episode: 4267/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 52.725470304489136\n",
      "episode: 4268/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4269/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 29.37500011920929\n",
      "episode: 4270/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 81.54301524162292\n",
      "episode: 4271/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 86.84141886234283\n",
      "episode: 4272/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 32.79994344711304\n",
      "episode: 4273/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 29.624459624290466\n",
      "episode: 4274/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 9.926137328147888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4275/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 19.93750137090683\n",
      "episode: 4276/6000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 59.8741814494133\n",
      "episode: 4277/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 115.13329195976257\n",
      "episode: 4278/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 44.04763066768646\n",
      "episode: 4279/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4280/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 28.638013780117035\n",
      "episode: 4281/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 19.44598388671875\n",
      "episode: 4282/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 49.75807428359985\n",
      "episode: 4283/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 39.34809786081314\n",
      "episode: 4284/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 0.0013783574104309082\n",
      "episode: 4285/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 0.124755859375\n",
      "episode: 4286/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 20.406494140625\n",
      "episode: 4287/6000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 39.97207969427109\n",
      "episode: 4288/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 55.54058802127838\n",
      "episode: 4289/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 65.83841246366501\n",
      "episode: 4290/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 49.875006675720215\n",
      "episode: 4291/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 94.73666524887085\n",
      "episode: 4292/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 20.914186000823975\n",
      "episode: 4293/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 65.2350327372551\n",
      "episode: 4294/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4295/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4296/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 19.95319777727127\n",
      "episode: 4297/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 58.803628742694855\n",
      "episode: 4298/6000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 22.747041821479797\n",
      "episode: 4299/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 152.6241192817688\n",
      "episode: 4300/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4301/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4302/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 40.57487350702286\n",
      "episode: 4303/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 123.08565652370453\n",
      "episode: 4304/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 9.979960322380066\n",
      "episode: 4305/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 2.372264862060547e-05\n",
      "episode: 4306/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 120.53511077165604\n",
      "episode: 4307/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 170.56128615140915\n",
      "episode: 4308/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 61.187523782253265\n",
      "episode: 4309/6000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 88.96686452627182\n",
      "episode: 4310/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 145.07104885578156\n",
      "episode: 4311/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 164.05290722846985\n",
      "episode: 4312/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 19.953248381614685\n",
      "episode: 4313/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 874.110805273056\n",
      "episode: 4314/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 66.74291688203812\n",
      "episode: 4315/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 130.9206302165985\n",
      "episode: 4316/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 19.953127801418304\n",
      "episode: 4317/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 5.960464477539063e-08\n",
      "episode: 4318/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 22.526012301445007\n",
      "episode: 4319/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 61.81616461277008\n",
      "episode: 4320/6000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 31.755306243896484\n",
      "episode: 4321/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 7.334269881248474\n",
      "episode: 4322/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 115.8012934923172\n",
      "episode: 4323/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4324/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 20.0628662109375\n",
      "episode: 4325/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 185.04469364881516\n",
      "episode: 4326/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 52.429531276226044\n",
      "episode: 4327/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 228.41589123010635\n",
      "episode: 4328/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 20.077880859375\n",
      "episode: 4329/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 39.790422976017\n",
      "episode: 4330/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 154.3331755399704\n",
      "episode: 4331/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 0.0010827183723449707\n",
      "episode: 4332/6000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4333/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 52.08772850036621\n",
      "episode: 4334/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 120.78137218952179\n",
      "episode: 4335/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 9.976669549942017\n",
      "episode: 4336/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 11.326242327690125\n",
      "episode: 4337/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4338/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 63.82890397310257\n",
      "episode: 4339/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 42.04063582420349\n",
      "episode: 4340/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 52.47199612855911\n",
      "episode: 4341/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 145.52526152133942\n",
      "episode: 4342/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 19.953231930732727\n",
      "episode: 4343/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 72.6259440779686\n",
      "episode: 4344/6000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 49.71147632598877\n",
      "episode: 4345/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 9.97848230600357\n",
      "episode: 4346/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 9.976573824882507\n",
      "episode: 4347/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 22.736435651779175\n",
      "episode: 4348/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4349/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 16.687238693237305\n",
      "episode: 4350/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4351/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 40.02410590648651\n",
      "episode: 4352/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 37.086639523506165\n",
      "episode: 4353/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 22.72476303577423\n",
      "episode: 4354/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 14.804704368114471\n",
      "episode: 4355/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 19.95312762260437\n",
      "episode: 4356/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 87.85340535640717\n",
      "episode: 4357/6000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 39.918670892715454\n",
      "episode: 4358/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 55.38902598619461\n",
      "episode: 4359/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 89.7481689453125\n",
      "episode: 4360/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 49.88299560546875\n",
      "episode: 4361/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 37.90737396478653\n",
      "episode: 4362/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 33.673645973205566\n",
      "episode: 4363/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 52.765817284584045\n",
      "episode: 4364/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 39.90832704305649\n",
      "episode: 4365/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 9.449976682662964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4366/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 29.92982107400894\n",
      "episode: 4367/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 50.27606052160263\n",
      "episode: 4368/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 79.252357006073\n",
      "episode: 4369/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 18.93519353866577\n",
      "episode: 4370/6000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 0.06409937143325806\n",
      "episode: 4371/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 86.64695394039154\n",
      "episode: 4372/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 19.953125059604645\n",
      "episode: 4373/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 9.976669430732727\n",
      "episode: 4374/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4375/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 19.95501136779785\n",
      "episode: 4376/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 79.12499630451202\n",
      "episode: 4377/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 110.03356975317001\n",
      "episode: 4378/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 29.95336800813675\n",
      "episode: 4379/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4380/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 62.38149267435074\n",
      "episode: 4381/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 19.007961750030518\n",
      "episode: 4382/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 92.20072162151337\n",
      "episode: 4383/6000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 17.96484375\n",
      "episode: 4384/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 30.917465209960938\n",
      "episode: 4385/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 18.53125\n",
      "episode: 4386/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 74.71235394477844\n",
      "episode: 4387/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 2.5570392608642578e-05\n",
      "episode: 4388/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 72.7818278670311\n",
      "episode: 4389/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 69.98452979326248\n",
      "episode: 4390/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 2.6289352774620056\n",
      "episode: 4391/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 0.011152923107147217\n",
      "episode: 4392/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4393/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 85.21988689899445\n",
      "episode: 4394/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 112.20576083660126\n",
      "episode: 4395/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 66.31168377399445\n",
      "episode: 4396/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 10.002166748046875\n",
      "episode: 4397/6000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 54.012539744377136\n",
      "episode: 4398/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4399/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4400/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4401/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 19.9732882976532\n",
      "episode: 4402/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 19.35117655992508\n",
      "episode: 4403/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 17.230330228805542\n",
      "episode: 4404/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 86.2647140622139\n",
      "episode: 4405/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 9.984371185302734\n",
      "episode: 4406/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 63.663871228694916\n",
      "episode: 4407/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 80.13799047470093\n",
      "episode: 4408/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 48.460706293582916\n",
      "episode: 4409/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 72.0997804403305\n",
      "episode: 4410/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 29.912756025791168\n",
      "episode: 4411/6000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 9.476664006710052\n",
      "episode: 4412/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 197.09862703084946\n",
      "episode: 4413/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 0.6863343715667725\n",
      "episode: 4414/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4415/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 61.71574550867081\n",
      "episode: 4416/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 21.182198405265808\n",
      "episode: 4417/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 16.199111878871918\n",
      "episode: 4418/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 166.32928276062012\n",
      "episode: 4419/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 39.973290741443634\n",
      "episode: 4420/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 232.7875778079033\n",
      "episode: 4421/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 9.484375059604645\n",
      "episode: 4422/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 60.21741336584091\n",
      "episode: 4423/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 22.09130859375\n",
      "episode: 4424/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 19.95323497056961\n",
      "episode: 4425/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 59.54708981513977\n",
      "episode: 4426/6000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 31.32731133699417\n",
      "episode: 4427/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 29.936223030090332\n",
      "episode: 4428/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 2.104261040687561\n",
      "episode: 4429/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 79.87314313650131\n",
      "episode: 4430/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 74.77652472257614\n",
      "episode: 4431/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 61.80881202220917\n",
      "episode: 4432/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 80.60515016317368\n",
      "episode: 4433/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 100.11139965057373\n",
      "episode: 4434/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 39.89083981513977\n",
      "episode: 4435/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 14.96875\n",
      "episode: 4436/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 10.101325809955597\n",
      "episode: 4437/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 212.23707073926926\n",
      "episode: 4438/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4439/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 64.63835340738297\n",
      "episode: 4440/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 12.750006079673767\n",
      "episode: 4441/6000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 119.8111960887909\n",
      "episode: 4442/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 4443/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 29.929794430732727\n",
      "episode: 4444/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 4445/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 33.203415870666504\n",
      "episode: 4446/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 60.41771066188812\n",
      "episode: 4447/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 55.449569046497345\n",
      "episode: 4448/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 50.136153161525726\n",
      "episode: 4449/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 1.7069759368896484\n",
      "episode: 4450/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 88.72726613283157\n",
      "episode: 4451/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 94.08549803495407\n",
      "episode: 4452/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 20.144538462162018\n",
      "episode: 4453/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 18.98447674512863\n",
      "episode: 4454/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 57.18633019924164\n",
      "episode: 4455/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 61.127102732658386\n",
      "episode: 4456/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 132.72429209947586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4457/6000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 144.35937130451202\n",
      "episode: 4458/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 30.395699083805084\n",
      "episode: 4459/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 19.959945678710938\n",
      "episode: 4460/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 31.606661081314087\n",
      "episode: 4461/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 49.067115008831024\n",
      "episode: 4462/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 52.76130646467209\n",
      "episode: 4463/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4464/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 44.12913954257965\n",
      "episode: 4465/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 69.35557740926743\n",
      "episode: 4466/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 142.45561349391937\n",
      "episode: 4467/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 9.718855619430542\n",
      "episode: 4468/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 128.08371824026108\n",
      "episode: 4469/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 111.7148140668869\n",
      "episode: 4470/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 34.56143218278885\n",
      "episode: 4471/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 49.898362815380096\n",
      "episode: 4472/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 48.01261895895004\n",
      "episode: 4473/6000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 36.08679682016373\n",
      "episode: 4474/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 22.746206045150757\n",
      "episode: 4475/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 79.2425228357315\n",
      "episode: 4476/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4477/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4478/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 19.08250105381012\n",
      "episode: 4479/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 9.976712822914124\n",
      "episode: 4480/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 19.44510853290558\n",
      "episode: 4481/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 62.7900390625\n",
      "episode: 4482/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 29.796878695487976\n",
      "episode: 4483/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 24.556940972805023\n",
      "episode: 4484/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 42.74722546339035\n",
      "episode: 4485/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 158.28049051761627\n",
      "episode: 4486/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 49.883031487464905\n",
      "episode: 4487/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 159.80537474155426\n",
      "episode: 4488/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 56.67380213737488\n",
      "episode: 4489/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 135.2610423564911\n",
      "episode: 4490/6000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 0.048635244369506836\n",
      "episode: 4491/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 95.665418446064\n",
      "episode: 4492/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 20.467008113861084\n",
      "episode: 4493/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 53.61429035663605\n",
      "episode: 4494/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 65.69285583496094\n",
      "episode: 4495/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 1.9079360365867615\n",
      "episode: 4496/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 90.33683788776398\n",
      "episode: 4497/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 100.3208875656128\n",
      "episode: 4498/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 22.04687887430191\n",
      "episode: 4499/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 61.15336734056473\n",
      "episode: 4500/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4501/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 62.80895483493805\n",
      "episode: 4502/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 62.70641732215881\n",
      "episode: 4503/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 19.970531463623047\n",
      "episode: 4504/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 59.95397037267685\n",
      "episode: 4505/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 102.12820202112198\n",
      "episode: 4506/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 39.812653839588165\n",
      "episode: 4507/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 40.27685850858688\n",
      "episode: 4508/6000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 20.038026571273804\n",
      "episode: 4509/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 39.91418468952179\n",
      "episode: 4510/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 118.53630793094635\n",
      "episode: 4511/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 88.32090783119202\n",
      "episode: 4512/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 92.52233535051346\n",
      "episode: 4513/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4514/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 93.04914873838425\n",
      "episode: 4515/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 107.81296736001968\n",
      "episode: 4516/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 160.87681490182877\n",
      "episode: 4517/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 220.88360273838043\n",
      "episode: 4518/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 222.56127309799194\n",
      "episode: 4519/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4520/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 118.05845373868942\n",
      "episode: 4521/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4522/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 61.05908161401749\n",
      "episode: 4523/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 19.875\n",
      "episode: 4524/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 131.10366290807724\n",
      "episode: 4525/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 223.06698548793793\n",
      "episode: 4526/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 82.99667650461197\n",
      "episode: 4527/6000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 99.752317070961\n",
      "episode: 4528/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 171.75506561994553\n",
      "episode: 4529/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 72.63097834587097\n",
      "episode: 4530/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 132.53371834754944\n",
      "episode: 4531/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 109.78421342372894\n",
      "episode: 4532/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 152.7159373164177\n",
      "episode: 4533/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 121.94550466537476\n",
      "episode: 4534/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 33.843880355358124\n",
      "episode: 4535/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 39.8984375\n",
      "episode: 4536/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 55.44971007108688\n",
      "episode: 4537/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 124.12482964992523\n",
      "episode: 4538/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 10.296588897705078\n",
      "episode: 4539/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 134.6584050655365\n",
      "episode: 4540/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 233.2589361667633\n",
      "episode: 4541/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 225.42040634155273\n",
      "episode: 4542/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 192.86763262748718\n",
      "episode: 4543/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 129.6567838191986\n",
      "episode: 4544/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 38.195560455322266\n",
      "episode: 4545/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 130.3867893218994\n",
      "episode: 4546/6000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 22.770826816558838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4547/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 79.98701530694962\n",
      "episode: 4548/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 198.043498814106\n",
      "episode: 4549/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 9.629572987556458\n",
      "episode: 4550/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 37.96759033203125\n",
      "episode: 4551/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 225.5196373462677\n",
      "episode: 4552/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 186.37114948034286\n",
      "episode: 4553/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 29.484375\n",
      "episode: 4554/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 122.71621531248093\n",
      "episode: 4555/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 197.34039384126663\n",
      "episode: 4556/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 186.6758627295494\n",
      "episode: 4557/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 167.7268254160881\n",
      "episode: 4558/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 142.2757786512375\n",
      "episode: 4559/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 137.31289744377136\n",
      "episode: 4560/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 150.230402469635\n",
      "episode: 4561/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 221.41720753908157\n",
      "episode: 4562/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 130.11200261116028\n",
      "episode: 4563/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 208.88772642612457\n",
      "episode: 4564/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 154.95208537578583\n",
      "episode: 4565/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 16.368680357933044\n",
      "episode: 4566/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 200.31323111057281\n",
      "episode: 4567/6000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 256.68264561891556\n",
      "episode: 4568/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 0.021110951900482178\n",
      "episode: 4569/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 211.06954318284988\n",
      "episode: 4570/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 40.03103286027908\n",
      "episode: 4571/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 155.50553315877914\n",
      "episode: 4572/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 71.21517640352249\n",
      "episode: 4573/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 9.596771240234375\n",
      "episode: 4574/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 92.62986481189728\n",
      "episode: 4575/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 205.80625933408737\n",
      "episode: 4576/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 129.32663041353226\n",
      "episode: 4577/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 0.02141481637954712\n",
      "episode: 4578/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 30.318038165569305\n",
      "episode: 4579/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 104.14544773101807\n",
      "episode: 4580/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 111.63650453090668\n",
      "episode: 4581/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 105.49351000785828\n",
      "episode: 4582/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 105.46818041801453\n",
      "episode: 4583/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 117.30565869808197\n",
      "episode: 4584/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4585/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4586/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 78.39002656936646\n",
      "episode: 4587/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 78.3027149438858\n",
      "episode: 4588/6000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 106.78805083036423\n",
      "episode: 4589/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 67.80088758468628\n",
      "episode: 4590/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4591/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 5.661010801792145\n",
      "episode: 4592/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 22.88279491662979\n",
      "episode: 4593/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 241.35200518369675\n",
      "episode: 4594/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 203.7926722764969\n",
      "episode: 4595/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 94.82437115907669\n",
      "episode: 4596/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 89.6497448682785\n",
      "episode: 4597/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 233.3200684785843\n",
      "episode: 4598/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 27.65625\n",
      "episode: 4599/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 231.44419288635254\n",
      "episode: 4600/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 59.4200439453125\n",
      "episode: 4601/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 128.42029291391373\n",
      "episode: 4602/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 242.76486933231354\n",
      "episode: 4603/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 223.0859031677246\n",
      "episode: 4604/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 213.01896113157272\n",
      "episode: 4605/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 19.959049224853516\n",
      "episode: 4606/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 158.47621327638626\n",
      "episode: 4607/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 59.85173541307449\n",
      "episode: 4608/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 4609/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 59.85941696166992\n",
      "episode: 4610/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4611/6000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 58.27796018123627\n",
      "episode: 4612/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4613/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4614/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 60.58818054199219\n",
      "episode: 4615/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 32.93070697784424\n",
      "episode: 4616/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 69.11724478006363\n",
      "episode: 4617/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 54.364121079444885\n",
      "episode: 4618/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 54.44943189620972\n",
      "episode: 4619/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 62.697537541389465\n",
      "episode: 4620/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 3.5762786865234375e-07\n",
      "episode: 4621/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4622/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 80.34567093849182\n",
      "episode: 4623/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 6.933230400085449\n",
      "episode: 4624/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 59.73879933357239\n",
      "episode: 4625/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 158.33999556303024\n",
      "episode: 4626/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 19.953397512435913\n",
      "episode: 4627/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 39.64755177497864\n",
      "episode: 4628/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 186.14413917064667\n",
      "episode: 4629/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 19.983365535736084\n",
      "episode: 4630/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0038533806800842285\n",
      "episode: 4631/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 41.32226824760437\n",
      "episode: 4632/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 220.62471896409988\n",
      "episode: 4633/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4634/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 23.06884765625\n",
      "episode: 4635/6000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 113.18934625387192\n",
      "episode: 4636/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 50.097412109375\n",
      "episode: 4637/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 220.91080951690674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4638/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 130.42902147769928\n",
      "episode: 4639/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 64.33141905069351\n",
      "episode: 4640/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 178.49806141853333\n",
      "episode: 4641/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 126.54958474636078\n",
      "episode: 4642/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 231.43139958381653\n",
      "episode: 4643/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 198.22337573766708\n",
      "episode: 4644/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 167.65637385845184\n",
      "episode: 4645/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 85.12121164798737\n",
      "episode: 4646/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 206.08904886245728\n",
      "episode: 4647/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 161.13843649625778\n",
      "episode: 4648/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 222.80076199769974\n",
      "episode: 4649/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 225.20149725675583\n",
      "episode: 4650/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 217.09326142072678\n",
      "episode: 4651/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 94.08710068464279\n",
      "episode: 4652/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 29.109376847743988\n",
      "episode: 4653/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 93.69161289930344\n",
      "episode: 4654/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 181.16661429405212\n",
      "episode: 4655/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 163.44151103496552\n",
      "episode: 4656/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 219.22749137878418\n",
      "episode: 4657/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 5.848329722881317\n",
      "episode: 4658/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 19.953231930732727\n",
      "episode: 4659/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 19.812500953674316\n",
      "episode: 4660/6000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 50.02061551809311\n",
      "episode: 4661/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 194.754978120327\n",
      "episode: 4662/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.976568579673767\n",
      "episode: 4663/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4664/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 135.57695281505585\n",
      "episode: 4665/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 27.204146683216095\n",
      "episode: 4666/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 94.63765925168991\n",
      "episode: 4667/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 42.37901711463928\n",
      "episode: 4668/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 85.07637584209442\n",
      "episode: 4669/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 20.0\n",
      "episode: 4670/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 20.1639404296875\n",
      "episode: 4671/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4672/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 52.67863464355469\n",
      "episode: 4673/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 65.54856872558594\n",
      "episode: 4674/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 50.009971618652344\n",
      "episode: 4675/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 58.604378283023834\n",
      "episode: 4676/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 122.05173766613007\n",
      "episode: 4677/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 40.59438633918762\n",
      "episode: 4678/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 10.078275918960571\n",
      "episode: 4679/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 58.78822261095047\n",
      "episode: 4680/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4681/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 39.456054866313934\n",
      "episode: 4682/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 62.50435769557953\n",
      "episode: 4683/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.953231930732727\n",
      "episode: 4684/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 222.5083953142166\n",
      "episode: 4685/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 172.21930783987045\n",
      "episode: 4686/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4687/6000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 125.52963531017303\n",
      "episode: 4688/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 145.52710670232773\n",
      "episode: 4689/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 69.92572277784348\n",
      "episode: 4690/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 60.69969183206558\n",
      "episode: 4691/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 237.19594877958298\n",
      "episode: 4692/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 79.800612449646\n",
      "episode: 4693/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 230.79379057884216\n",
      "episode: 4694/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 10.858581721782684\n",
      "episode: 4695/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 139.87324512004852\n",
      "episode: 4696/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 60.256089210510254\n",
      "episode: 4697/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 192.7829111814499\n",
      "episode: 4698/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 142.41669392585754\n",
      "episode: 4699/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 107.23842471837997\n",
      "episode: 4700/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 150.87856948375702\n",
      "episode: 4701/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 201.73928850889206\n",
      "episode: 4702/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 134.5904425382614\n",
      "episode: 4703/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 41.34478884935379\n",
      "episode: 4704/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 91.30623179674149\n",
      "episode: 4705/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 31.8173828125\n",
      "episode: 4706/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 102.52619868516922\n",
      "episode: 4707/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 3.7618408203125\n",
      "episode: 4708/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 243.63140732049942\n",
      "episode: 4709/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 19.95825159549713\n",
      "episode: 4710/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 239.12074226140976\n",
      "episode: 4711/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 102.29482918977737\n",
      "episode: 4712/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 84.92332452535629\n",
      "episode: 4713/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 343.49571669101715\n",
      "episode: 4714/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 123.907506108284\n",
      "episode: 4715/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4716/6000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 42.76557540893555\n",
      "episode: 4717/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 49.900514364242554\n",
      "episode: 4718/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 1928.6420485973358\n",
      "episode: 4719/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 142.026103079319\n",
      "episode: 4720/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 186.1974380016327\n",
      "episode: 4721/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 81.89293265342712\n",
      "episode: 4722/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4723/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 9.706787109375\n",
      "episode: 4724/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 87.17389303445816\n",
      "episode: 4725/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 107.55981856584549\n",
      "episode: 4726/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 128.9305968284607\n",
      "episode: 4727/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4728/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 192.9248633980751\n",
      "episode: 4729/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 10.0611572265625\n",
      "episode: 4730/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 9.89843899011612\n",
      "episode: 4731/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 9.960939943790436\n",
      "episode: 4732/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 15.93505859375\n",
      "episode: 4733/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 29.56296396255493\n",
      "episode: 4734/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 99.76609116792679\n",
      "episode: 4735/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 214.1923744082451\n",
      "episode: 4736/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 84.57328408956528\n",
      "episode: 4737/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 27.995016276836395\n",
      "episode: 4738/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 47.78708839416504\n",
      "episode: 4739/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 92.56766712665558\n",
      "episode: 4740/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 59.2021484375\n",
      "episode: 4741/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 44.707056283950806\n",
      "episode: 4742/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 47.879008769989014\n",
      "episode: 4743/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 132.00221401453018\n",
      "episode: 4744/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 125.42080116271973\n",
      "episode: 4745/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 24.8379168510437\n",
      "episode: 4746/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4747/6000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 114.8419640660286\n",
      "episode: 4748/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.959945738315582\n",
      "episode: 4749/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4750/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 29.880629181861877\n",
      "episode: 4751/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 84.76930838823318\n",
      "episode: 4752/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 104.78220826387405\n",
      "episode: 4753/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 32.92359733581543\n",
      "episode: 4754/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4755/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 169.89349162578583\n",
      "episode: 4756/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 2567.4989057183266\n",
      "episode: 4757/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 50.024658203125\n",
      "episode: 4758/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 79.37190055847168\n",
      "episode: 4759/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.953125059604645\n",
      "episode: 4760/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 84.004101395607\n",
      "episode: 4761/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 251.52242308855057\n",
      "episode: 4762/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 39.820317924022675\n",
      "episode: 4763/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 26.343063056468964\n",
      "episode: 4764/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 72.73808127641678\n",
      "episode: 4765/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 30.0137939453125\n",
      "episode: 4766/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4767/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 52.668210089206696\n",
      "episode: 4768/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 139.8430386185646\n",
      "episode: 4769/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 53.187713861465454\n",
      "episode: 4770/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 78.5882219672203\n",
      "episode: 4771/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.953231930732727\n",
      "episode: 4772/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 12.152344107627869\n",
      "episode: 4773/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 22.78814995288849\n",
      "episode: 4774/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.955687046051025\n",
      "episode: 4775/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 68.10344797372818\n",
      "episode: 4776/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 72.716552734375\n",
      "episode: 4777/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 154.53663581609726\n",
      "episode: 4778/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 173.58126443624496\n",
      "episode: 4779/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 19.962032675743103\n",
      "episode: 4780/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 1.052092969417572\n",
      "episode: 4781/6000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 186.04990112781525\n",
      "episode: 4782/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 1.97705078125\n",
      "episode: 4783/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 31.298647820949554\n",
      "episode: 4784/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 134.01389557123184\n",
      "episode: 4785/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4786/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 62.01046276092529\n",
      "episode: 4787/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 40.86175149679184\n",
      "episode: 4788/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 102.53921222686768\n",
      "episode: 4789/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 232.92021983861923\n",
      "episode: 4790/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 168.19458079338074\n",
      "episode: 4791/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 99.84986686706543\n",
      "episode: 4792/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 10.158246457576752\n",
      "episode: 4793/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4.411340117454529\n",
      "episode: 4794/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 109.66650485992432\n",
      "episode: 4795/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 32.895118713378906\n",
      "episode: 4796/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4797/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 9.679729521274567\n",
      "episode: 4798/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 4799/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 90.18071311712265\n",
      "episode: 4800/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4801/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 61.693359375\n",
      "episode: 4802/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 29.95312589406967\n",
      "episode: 4803/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4804/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4805/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 132.61816787719727\n",
      "episode: 4806/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 100.39194703102112\n",
      "episode: 4807/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 118.11882770061493\n",
      "episode: 4808/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 153.979747235775\n",
      "episode: 4809/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 49.90625524520874\n",
      "episode: 4810/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 32.69535535573959\n",
      "episode: 4811/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4812/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 129.74293166399002\n",
      "episode: 4813/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 80.30486637353897\n",
      "episode: 4814/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 28.77368927001953\n",
      "episode: 4815/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 79.89689081907272\n",
      "episode: 4816/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 41.869140684604645\n",
      "episode: 4817/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 29.929795026779175\n",
      "episode: 4818/6000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 102.5567022562027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4819/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 68.34172773361206\n",
      "episode: 4820/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 19.911208629608154\n",
      "episode: 4821/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 41.88233643770218\n",
      "episode: 4822/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 72.66610080003738\n",
      "episode: 4823/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 19.96058702468872\n",
      "episode: 4824/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 21.81298828125\n",
      "episode: 4825/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 23.876953184604645\n",
      "episode: 4826/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 111.65951615571976\n",
      "episode: 4827/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 69.16556775569916\n",
      "episode: 4828/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 9.976565062999725\n",
      "episode: 4829/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 9.828125894069672\n",
      "episode: 4830/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 69.12800252437592\n",
      "episode: 4831/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 54.77152729034424\n",
      "episode: 4832/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 4833/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 73.00704073905945\n",
      "episode: 4834/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 152.57741749286652\n",
      "episode: 4835/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 134.51486092805862\n",
      "episode: 4836/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 54.351365089416504\n",
      "episode: 4837/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 182.101596057415\n",
      "episode: 4838/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4839/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4840/6000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4841/6000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 91.96237355470657\n",
      "episode: 4842/6000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 4843/6000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 29.10160231590271\n",
      "episode: 4844/6000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4845/6000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 49.597482681274414\n",
      "episode: 4846/6000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 9.979726791381836\n",
      "episode: 4847/6000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4848/6000, steps: 500, e: 0.0098\n",
      "accumulated_rewards_per_episode: 98.2154204249382\n",
      "episode: 4849/6000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 180.68577551841736\n",
      "episode: 4850/6000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 95.57034611701965\n",
      "episode: 4851/6000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 10.106516063213348\n",
      "episode: 4852/6000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 2.6072897911071777\n",
      "episode: 4853/6000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 97.27851921319962\n",
      "episode: 4854/6000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 164.63989758491516\n",
      "episode: 4855/6000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 143.0838395357132\n",
      "episode: 4856/6000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 0.07458025217056274\n",
      "episode: 4857/6000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 95.3608785867691\n",
      "episode: 4858/6000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 70.331787109375\n",
      "episode: 4859/6000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 0.4744837284088135\n",
      "episode: 4860/6000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 20.263225495815277\n",
      "episode: 4861/6000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4862/6000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 48.718750953674316\n",
      "episode: 4863/6000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 54.23614704608917\n",
      "episode: 4864/6000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 39.080007553100586\n",
      "episode: 4865/6000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 66.44545537233353\n",
      "episode: 4866/6000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 49.88469880819321\n",
      "episode: 4867/6000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 121.13462495803833\n",
      "episode: 4868/6000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4869/6000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4870/6000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 144.96595364809036\n",
      "episode: 4871/6000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 93.1710684299469\n",
      "episode: 4872/6000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 106.38995671272278\n",
      "episode: 4873/6000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 119.49458914995193\n",
      "episode: 4874/6000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 121.91263914108276\n",
      "episode: 4875/6000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 0.008870720863342285\n",
      "episode: 4876/6000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 28.559222519397736\n",
      "episode: 4877/6000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 45.3376767039299\n",
      "episode: 4878/6000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 176.36300706863403\n",
      "episode: 4879/6000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 24.21680784225464\n",
      "episode: 4880/6000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 103.8301055431366\n",
      "episode: 4881/6000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 112.66452050209045\n",
      "episode: 4882/6000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 161.6779487133026\n",
      "episode: 4883/6000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 66.6077064871788\n",
      "episode: 4884/6000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 164.08686047792435\n",
      "episode: 4885/6000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 9.97667396068573\n",
      "episode: 4886/6000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 19.152938842773438\n",
      "episode: 4887/6000, steps: 500, e: 0.0089\n",
      "accumulated_rewards_per_episode: 37.014684557914734\n",
      "episode: 4888/6000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 113.45358568429947\n",
      "episode: 4889/6000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 20.28131878376007\n",
      "episode: 4890/6000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4891/6000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 211.54894751310349\n",
      "episode: 4892/6000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 196.58126175403595\n",
      "episode: 4893/6000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 134.3731986284256\n",
      "episode: 4894/6000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 205.83103477954865\n",
      "episode: 4895/6000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 231.2152230143547\n",
      "episode: 4896/6000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 82.61917281150818\n",
      "episode: 4897/6000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 4898/6000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 28.429689943790436\n",
      "episode: 4899/6000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 5.6167832016944885\n",
      "episode: 4900/6000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 197.19338446855545\n",
      "episode: 4901/6000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 52.77283161878586\n",
      "episode: 4902/6000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 92.56841099262238\n",
      "episode: 4903/6000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4904/6000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 202.6916447877884\n",
      "episode: 4905/6000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 4906/6000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4907/6000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 8.007939279079437\n",
      "episode: 4908/6000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 185.07404845952988\n",
      "episode: 4909/6000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 2856.1159445643425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 4910/6000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 150.4123512506485\n",
      "episode: 4911/6000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 106.40972685813904\n",
      "episode: 4912/6000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 190.82510137557983\n",
      "episode: 4913/6000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 100.0976911187172\n",
      "episode: 4914/6000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 42.715123295784\n",
      "episode: 4915/6000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 193.43773621320724\n",
      "episode: 4916/6000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 196.39900988340378\n",
      "episode: 4917/6000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 227.57047832012177\n",
      "episode: 4918/6000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 39.70340555906296\n",
      "episode: 4919/6000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 51.28886163234711\n",
      "episode: 4920/6000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 2.6881790161132812\n",
      "episode: 4921/6000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 202.33989828824997\n",
      "episode: 4922/6000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 78.33638548851013\n",
      "episode: 4923/6000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 214.91554874181747\n",
      "episode: 4924/6000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 219.01485991477966\n",
      "episode: 4925/6000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 234.24282610416412\n",
      "episode: 4926/6000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 923.7772751450539\n",
      "episode: 4927/6000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 157.19371128082275\n",
      "episode: 4928/6000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 32.71289074420929\n",
      "episode: 4929/6000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 137.332826256752\n",
      "episode: 4930/6000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 39.90821838378906\n",
      "episode: 4931/6000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 231.3399116396904\n",
      "episode: 4932/6000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 59.98624050617218\n",
      "episode: 4933/6000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 12.899070739746094\n",
      "episode: 4934/6000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 0.035559654235839844\n",
      "episode: 4935/6000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 234.91957926750183\n",
      "episode: 4936/6000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 81.77587699890137\n",
      "episode: 4937/6000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 39.25993728637695\n",
      "episode: 4938/6000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4939/6000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 4940/6000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 11.768616735935211\n",
      "episode: 4941/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4942/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 19.869337797164917\n",
      "episode: 4943/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 10.0091233253479\n",
      "episode: 4944/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 49.139364540576935\n",
      "episode: 4945/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 184.0205955505371\n",
      "episode: 4946/6000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 195.28332948684692\n",
      "episode: 4947/6000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 190.52967810630798\n",
      "episode: 4948/6000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 22.736328125\n",
      "episode: 4949/6000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 134.315414249897\n",
      "episode: 4950/6000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 228.06964999437332\n",
      "episode: 4951/6000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 234.4191197156906\n",
      "episode: 4952/6000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4953/6000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 240.95783299207687\n",
      "episode: 4954/6000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4955/6000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 221.17868280410767\n",
      "episode: 4956/6000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 120.91356885433197\n",
      "episode: 4957/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 228.2444429397583\n",
      "episode: 4958/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 36.45830535888672\n",
      "episode: 4959/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 20.23025417327881\n",
      "episode: 4960/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 9.976604342460632\n",
      "episode: 4961/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 58.46566081047058\n",
      "episode: 4962/6000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 0.0004413723945617676\n",
      "episode: 4963/6000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4964/6000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 1.955161988735199\n",
      "episode: 4965/6000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 29.929732024669647\n",
      "episode: 4966/6000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 41.106705009937286\n",
      "episode: 4967/6000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 20.406494140625\n",
      "episode: 4968/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 115.0404440164566\n",
      "episode: 4969/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 95.27005088329315\n",
      "episode: 4970/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 4971/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 27.44824868440628\n",
      "episode: 4972/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 66.99707287549973\n",
      "episode: 4973/6000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 19.117187559604645\n",
      "episode: 4974/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 30.100472450256348\n",
      "episode: 4975/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 29.9296875\n",
      "episode: 4976/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 10.187255859375\n",
      "episode: 4977/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 22.738740921020508\n",
      "episode: 4978/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 30.056795597076416\n",
      "episode: 4979/6000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 122.41828608512878\n",
      "episode: 4980/6000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 105.3085458278656\n",
      "episode: 4981/6000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 179.59896755218506\n",
      "episode: 4982/6000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 0.13027328252792358\n",
      "episode: 4983/6000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 28.875104069709778\n",
      "episode: 4984/6000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 49.286340177059174\n",
      "episode: 4985/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 35.50848764181137\n",
      "episode: 4986/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 169.2150130867958\n",
      "episode: 4987/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 40.3470019698143\n",
      "episode: 4988/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 207.64945894479752\n",
      "episode: 4989/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 56.91238898038864\n",
      "episode: 4990/6000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 53.81256145238876\n",
      "episode: 4991/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 24.883026123046875\n",
      "episode: 4992/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 40.94073033332825\n",
      "episode: 4993/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 138.47413963079453\n",
      "episode: 4994/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 47.636128425598145\n",
      "episode: 4995/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 113.68557119369507\n",
      "episode: 4996/6000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 4997/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 187.98334515094757\n",
      "episode: 4998/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 9.3984375\n",
      "episode: 4999/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 18.976806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5000/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 212.02867150306702\n",
      "episode: 5001/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 39.9121749997139\n",
      "episode: 5002/6000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 9.796875\n",
      "episode: 5003/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 3.2857437133789062\n",
      "episode: 5004/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 91.06275337934494\n",
      "episode: 5005/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 59.8650598526001\n",
      "episode: 5006/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 109.83761250972748\n",
      "episode: 5007/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 160.8505533337593\n",
      "episode: 5008/6000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 101.78203761577606\n",
      "episode: 5009/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5010/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 111.64258116483688\n",
      "episode: 5011/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 237.4165554046631\n",
      "episode: 5012/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 238.02615869045258\n",
      "episode: 5013/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 153.77368849515915\n",
      "episode: 5014/6000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 138.4214991927147\n",
      "episode: 5015/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 22.736328125\n",
      "episode: 5016/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 115.82545578479767\n",
      "episode: 5017/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 0.7969061136245728\n",
      "episode: 5018/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 217.40443074703217\n",
      "episode: 5019/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 109.7422742843628\n",
      "episode: 5020/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 224.44167947769165\n",
      "episode: 5021/6000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 391.56207025051117\n",
      "episode: 5022/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 238.82760798931122\n",
      "episode: 5023/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 162.43306022882462\n",
      "episode: 5024/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 151.65983366966248\n",
      "episode: 5025/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 134.79331344366074\n",
      "episode: 5026/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 12.8085298538208\n",
      "episode: 5027/6000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 164.0162397623062\n",
      "episode: 5028/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 249.94085294008255\n",
      "episode: 5029/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 244.63975262641907\n",
      "episode: 5030/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 128.16943591833115\n",
      "episode: 5031/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5032/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 9.304285049438477e-05\n",
      "episode: 5033/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 55.43359375\n",
      "episode: 5034/6000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 111.28739988803864\n",
      "episode: 5035/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 19.953126907348633\n",
      "episode: 5036/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 232.97690922021866\n",
      "episode: 5037/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 142.45512342453003\n",
      "episode: 5038/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 248.06034469604492\n",
      "episode: 5039/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 728.359178006649\n",
      "episode: 5040/6000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 230.55358755588531\n",
      "episode: 5041/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 59.86245918273926\n",
      "episode: 5042/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 161.91405630111694\n",
      "episode: 5043/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 164.4103742837906\n",
      "episode: 5044/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 1.1308873295783997\n",
      "episode: 5045/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 4.70280647277832e-05\n",
      "episode: 5046/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 39.890625\n",
      "episode: 5047/6000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 232.90733802318573\n",
      "episode: 5048/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5049/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 174.7443106174469\n",
      "episode: 5050/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 122.45837157964706\n",
      "episode: 5051/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 135.91258078813553\n",
      "episode: 5052/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 9.96875\n",
      "episode: 5053/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5054/6000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 19.977369785308838\n",
      "episode: 5055/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 95.45903235673904\n",
      "episode: 5056/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 82.51930499076843\n",
      "episode: 5057/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 42.63300997018814\n",
      "episode: 5058/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 19.95503717660904\n",
      "episode: 5059/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 135.2987088561058\n",
      "episode: 5060/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 300.2920958995819\n",
      "episode: 5061/6000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 234.64449435472488\n",
      "episode: 5062/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 159.86117964982986\n",
      "episode: 5063/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 30.061440467834473\n",
      "episode: 5064/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 115.3109599351883\n",
      "episode: 5065/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 1.0048937797546387\n",
      "episode: 5066/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 39.59814453125\n",
      "episode: 5067/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 92.06413942575455\n",
      "episode: 5068/6000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5069/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 217.25269442796707\n",
      "episode: 5070/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 162.49385333061218\n",
      "episode: 5071/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 162.04961556196213\n",
      "episode: 5072/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 230.88071084022522\n",
      "episode: 5073/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 80.09522247314453\n",
      "episode: 5074/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 131.88851195573807\n",
      "episode: 5075/6000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5076/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 55.568360328674316\n",
      "episode: 5077/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 39.91217517852783\n",
      "episode: 5078/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5079/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 110.18744331598282\n",
      "episode: 5080/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5081/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5082/6000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 65.66507416963577\n",
      "episode: 5083/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 89.65982854366302\n",
      "episode: 5084/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 9.97667384147644\n",
      "episode: 5085/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 1.9711411595344543\n",
      "episode: 5086/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 19.95312511920929\n",
      "episode: 5087/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 108.9138617515564\n",
      "episode: 5088/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 107.45412164926529\n",
      "episode: 5089/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5090/6000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 164.6253036260605\n",
      "episode: 5091/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 59.72063225507736\n",
      "episode: 5092/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 193.72802364826202\n",
      "episode: 5093/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 139.75107765197754\n",
      "episode: 5094/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 122.65814453363419\n",
      "episode: 5095/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 140.20996075868607\n",
      "episode: 5096/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 1352.8475435972214\n",
      "episode: 5097/6000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 175.5992732644081\n",
      "episode: 5098/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 38.80210065841675\n",
      "episode: 5099/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 59.71114355325699\n",
      "episode: 5100/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 57.56759589910507\n",
      "episode: 5101/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 141.787901699543\n",
      "episode: 5102/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 217.64585411548615\n",
      "episode: 5103/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 150.41710156202316\n",
      "episode: 5104/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 188.16079729795456\n",
      "episode: 5105/6000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5106/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 183.57680821418762\n",
      "episode: 5107/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 44.37621533870697\n",
      "episode: 5108/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 124.66671991348267\n",
      "episode: 5109/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 43.6905032992363\n",
      "episode: 5110/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 82.04887104034424\n",
      "episode: 5111/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 19.13285630941391\n",
      "episode: 5112/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 144.90546852350235\n",
      "episode: 5113/6000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 212.90103948116302\n",
      "episode: 5114/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 247.98136234283447\n",
      "episode: 5115/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5116/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 143.12494522333145\n",
      "episode: 5117/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 142.83019924163818\n",
      "episode: 5118/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 214.47571218013763\n",
      "episode: 5119/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5120/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 235.007974088192\n",
      "episode: 5121/6000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 141.274711728096\n",
      "episode: 5122/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 222.0441706776619\n",
      "episode: 5123/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 129.03727740049362\n",
      "episode: 5124/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 193.59600764513016\n",
      "episode: 5125/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 184.06121426820755\n",
      "episode: 5126/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 46.604347229003906\n",
      "episode: 5127/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 228.9957811832428\n",
      "episode: 5128/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 123.79305547475815\n",
      "episode: 5129/6000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 227.819517493248\n",
      "episode: 5130/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 126.20666605234146\n",
      "episode: 5131/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 29.929823517799377\n",
      "episode: 5132/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 5133/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 2.783203125\n",
      "episode: 5134/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 107.79493373632431\n",
      "episode: 5135/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 162.24316543340683\n",
      "episode: 5136/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 42.69651198387146\n",
      "episode: 5137/6000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 75.92317944765091\n",
      "episode: 5138/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 49.53910446166992\n",
      "episode: 5139/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 45.75154638290405\n",
      "episode: 5140/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5141/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 145.35512602329254\n",
      "episode: 5142/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 139.7913862466812\n",
      "episode: 5143/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 206.53021013736725\n",
      "episode: 5144/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 69.75717186927795\n",
      "episode: 5145/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 174.832189142704\n",
      "episode: 5146/6000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 161.324309527874\n",
      "episode: 5147/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 56.90482795238495\n",
      "episode: 5148/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5149/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5150/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 19.955010414123535\n",
      "episode: 5151/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 92.21255075931549\n",
      "episode: 5152/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 242.6385315656662\n",
      "episode: 5153/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 203.34376573562622\n",
      "episode: 5154/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 227.96355479955673\n",
      "episode: 5155/6000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 77.35856658220291\n",
      "episode: 5156/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 104.77677977085114\n",
      "episode: 5157/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 150.41552942991257\n",
      "episode: 5158/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5159/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 209.99627667665482\n",
      "episode: 5160/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 196.86059141159058\n",
      "episode: 5161/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 201.46367955207825\n",
      "episode: 5162/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 19.446064174175262\n",
      "episode: 5163/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 63.74544548988342\n",
      "episode: 5164/6000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 206.25098419189453\n",
      "episode: 5165/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 154.77575927972794\n",
      "episode: 5166/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 128.38260424137115\n",
      "episode: 5167/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 227.46313512325287\n",
      "episode: 5168/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 102.94017213582993\n",
      "episode: 5169/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 87.25377571582794\n",
      "episode: 5170/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 79.51475208997726\n",
      "episode: 5171/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 32.204413533210754\n",
      "episode: 5172/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 69.74393045902252\n",
      "episode: 5173/6000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 20.40649676322937\n",
      "episode: 5174/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 85.40756320953369\n",
      "episode: 5175/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 2.710336685180664\n",
      "episode: 5176/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 42.303103029727936\n",
      "episode: 5177/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 197.94055622816086\n",
      "episode: 5178/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 232.43417006731033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5179/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 113.69239640235901\n",
      "episode: 5180/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5181/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 85.07422703504562\n",
      "episode: 5182/6000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 233.9250789284706\n",
      "episode: 5183/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 29.921998381614685\n",
      "episode: 5184/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 245.94070410728455\n",
      "episode: 5185/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 29.929689943790436\n",
      "episode: 5186/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 29.9487823843956\n",
      "episode: 5187/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 159.42740046977997\n",
      "episode: 5188/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 62.642581820487976\n",
      "episode: 5189/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 238.62259721755981\n",
      "episode: 5190/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 184.95554041862488\n",
      "episode: 5191/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 173.6797717809677\n",
      "episode: 5192/6000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 39.931573033332825\n",
      "episode: 5193/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 22.734764099121094\n",
      "episode: 5194/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 47.50186175107956\n",
      "episode: 5195/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 177.26670134067535\n",
      "episode: 5196/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 69.83787935972214\n",
      "episode: 5197/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 1.9990234375\n",
      "episode: 5198/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 22.83751094341278\n",
      "episode: 5199/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 123.13956367969513\n",
      "episode: 5200/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 81.6286113858223\n",
      "episode: 5201/6000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 157.6589813232422\n",
      "episode: 5202/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 76.73969620466232\n",
      "episode: 5203/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 43.54177010059357\n",
      "episode: 5204/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 30.229981422424316\n",
      "episode: 5205/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 114.4609803557396\n",
      "episode: 5206/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 127.0299511551857\n",
      "episode: 5207/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 10.06134033203125\n",
      "episode: 5208/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 113.25004351139069\n",
      "episode: 5209/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5210/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5211/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 171.6829869747162\n",
      "episode: 5212/6000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 152.11507576704025\n",
      "episode: 5213/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 85.97432607412338\n",
      "episode: 5214/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 9.484375059604645\n",
      "episode: 5215/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5216/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 19.31134033203125\n",
      "episode: 5217/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 30.097597062587738\n",
      "episode: 5218/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 0.9434152245521545\n",
      "episode: 5219/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 0.00010126829147338867\n",
      "episode: 5220/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5221/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 71.69938939809799\n",
      "episode: 5222/6000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 102.54950875043869\n",
      "episode: 5223/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 49.87693041563034\n",
      "episode: 5224/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 204.01970326900482\n",
      "episode: 5225/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 223.29545521736145\n",
      "episode: 5226/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 119.30097717046738\n",
      "episode: 5227/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5228/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 49.951628506183624\n",
      "episode: 5229/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 228.5278615951538\n",
      "episode: 5230/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 177.21446204185486\n",
      "episode: 5231/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5232/6000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 151.94672340154648\n",
      "episode: 5233/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 102.65936636924744\n",
      "episode: 5234/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 100.69412875175476\n",
      "episode: 5235/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 77.14586806297302\n",
      "episode: 5236/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 159.08787536621094\n",
      "episode: 5237/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 166.041031062603\n",
      "episode: 5238/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5239/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 125.40057981014252\n",
      "episode: 5240/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 174.87476950883865\n",
      "episode: 5241/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5242/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 29.867236614227295\n",
      "episode: 5243/6000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 29.94531339406967\n",
      "episode: 5244/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5245/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 9.983383178710938\n",
      "episode: 5246/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 40.18495684862137\n",
      "episode: 5247/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 151.5301821231842\n",
      "episode: 5248/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 42.77358162403107\n",
      "episode: 5249/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 22.720810115337372\n",
      "episode: 5250/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 79.82717508077621\n",
      "episode: 5251/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5252/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 72.88156789541245\n",
      "episode: 5253/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 104.22060853242874\n",
      "episode: 5254/6000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 124.14396286010742\n",
      "episode: 5255/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5256/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 9.976565301418304\n",
      "episode: 5257/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 29.929795265197754\n",
      "episode: 5258/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 94.33050417900085\n",
      "episode: 5259/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5260/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 39.85994100570679\n",
      "episode: 5261/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5262/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 9.509195327758789\n",
      "episode: 5263/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 49.53129291534424\n",
      "episode: 5264/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 55.44929105043411\n",
      "episode: 5265/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 107.88189697265625\n",
      "episode: 5266/6000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 42.85801309347153\n",
      "episode: 5267/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 180.41027790308\n",
      "episode: 5268/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5269/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 8.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5270/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 72.10717910528183\n",
      "episode: 5271/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 161.95814859867096\n",
      "episode: 5272/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 169.71325016021729\n",
      "episode: 5273/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 185.23395031690598\n",
      "episode: 5274/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 43.20223045349121\n",
      "episode: 5275/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 88.25104051828384\n",
      "episode: 5276/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 115.13173121213913\n",
      "episode: 5277/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5278/6000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 95.46490556001663\n",
      "episode: 5279/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 119.81349813938141\n",
      "episode: 5280/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 145.3180286884308\n",
      "episode: 5281/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 9.97667384147644\n",
      "episode: 5282/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 9.96097594499588\n",
      "episode: 5283/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5284/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 30.239787995815277\n",
      "episode: 5285/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 85.38671886920929\n",
      "episode: 5286/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 11.954198062419891\n",
      "episode: 5287/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 42.86462950706482\n",
      "episode: 5288/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 52.65820670127869\n",
      "episode: 5289/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5290/6000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 163.8585455417633\n",
      "episode: 5291/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 54.11973291635513\n",
      "episode: 5292/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 180.1764890551567\n",
      "episode: 5293/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 44.37152099609375\n",
      "episode: 5294/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 59.99538516998291\n",
      "episode: 5295/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 7.390629470348358\n",
      "episode: 5296/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 175.2444104552269\n",
      "episode: 5297/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 180.54481881856918\n",
      "episode: 5298/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 135.0650818347931\n",
      "episode: 5299/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 42.80248260498047\n",
      "episode: 5300/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 10.106414794921875\n",
      "episode: 5301/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 92.05669230222702\n",
      "episode: 5302/6000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 59.1470947265625\n",
      "episode: 5303/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 49.022705078125\n",
      "episode: 5304/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 202.01643776893616\n",
      "episode: 5305/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 12.6953125\n",
      "episode: 5306/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 49.84377437829971\n",
      "episode: 5307/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 235.71859681606293\n",
      "episode: 5308/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 69.98115783929825\n",
      "episode: 5309/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5310/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 20.03790283203125\n",
      "episode: 5311/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 104.50447845458984\n",
      "episode: 5312/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 213.12757098674774\n",
      "episode: 5313/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 29.929687559604645\n",
      "episode: 5314/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5315/6000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 144.63723176717758\n",
      "episode: 5316/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 49.512010991573334\n",
      "episode: 5317/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 0.127003014087677\n",
      "episode: 5318/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 49.11966162919998\n",
      "episode: 5319/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 86.60156720876694\n",
      "episode: 5320/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 111.2975572347641\n",
      "episode: 5321/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 49.531251668930054\n",
      "episode: 5322/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 77.28760248422623\n",
      "episode: 5323/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 120.81250166893005\n",
      "episode: 5324/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 68.83039820194244\n",
      "episode: 5325/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 81.86616510152817\n",
      "episode: 5326/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5327/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5328/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 9.976564943790436\n",
      "episode: 5329/6000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 88.96807825565338\n",
      "episode: 5330/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 9.961176872253418\n",
      "episode: 5331/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5332/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 71.32729715108871\n",
      "episode: 5333/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 169.58604633808136\n",
      "episode: 5334/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 143.92103093862534\n",
      "episode: 5335/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 195.48422050476074\n",
      "episode: 5336/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 131.20337170362473\n",
      "episode: 5337/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 189.72068446874619\n",
      "episode: 5338/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 19.898918628692627\n",
      "episode: 5339/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 49.88285541534424\n",
      "episode: 5340/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 155.21898478269577\n",
      "episode: 5341/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 168.6644823551178\n",
      "episode: 5342/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 9.15625262260437\n",
      "episode: 5343/6000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 230.59036779403687\n",
      "episode: 5344/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 29.922849655151367\n",
      "episode: 5345/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 28.401405334472656\n",
      "episode: 5346/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 11.954144179821014\n",
      "episode: 5347/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 7.048259139060974\n",
      "episode: 5348/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 28.406289756298065\n",
      "episode: 5349/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 186.70776492357254\n",
      "episode: 5350/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 132.3283435702324\n",
      "episode: 5351/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 209.29741209745407\n",
      "episode: 5352/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 152.4458373785019\n",
      "episode: 5353/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 32.71299046278\n",
      "episode: 5354/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 47.0212784409523\n",
      "episode: 5355/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 160.2150451540947\n",
      "episode: 5356/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 103.25402414798737\n",
      "episode: 5357/6000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5358/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 205.21203988790512\n",
      "episode: 5359/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 210.1227416396141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5360/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 32.89219778776169\n",
      "episode: 5361/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 98.30710077285767\n",
      "episode: 5362/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 9.51373291015625\n",
      "episode: 5363/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 169.58072263002396\n",
      "episode: 5364/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 9.982486724853516\n",
      "episode: 5365/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 69.87811094522476\n",
      "episode: 5366/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 128.32614904642105\n",
      "episode: 5367/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 138.8566619157791\n",
      "episode: 5368/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 237.80923295021057\n",
      "episode: 5369/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 52.29534959793091\n",
      "episode: 5370/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 39.87626260519028\n",
      "episode: 5371/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 0.43084001541137695\n",
      "episode: 5372/6000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 145.42124181985855\n",
      "episode: 5373/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 227.8150840997696\n",
      "episode: 5374/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 163.8593055009842\n",
      "episode: 5375/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 160.09178709983826\n",
      "episode: 5376/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 160.26980805397034\n",
      "episode: 5377/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 217.07074171304703\n",
      "episode: 5378/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 45.556826531887054\n",
      "episode: 5379/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 28.42968839406967\n",
      "episode: 5380/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 30.01385509967804\n",
      "episode: 5381/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 38.96813678741455\n",
      "episode: 5382/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 9.158218383789062\n",
      "episode: 5383/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 9.796875\n",
      "episode: 5384/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 10.0535888671875\n",
      "episode: 5385/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 32.66605752706528\n",
      "episode: 5386/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 9.978482246398926\n",
      "episode: 5387/6000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5388/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5389/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 10.101318359375\n",
      "episode: 5390/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 49.03962004184723\n",
      "episode: 5391/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 92.70983982086182\n",
      "episode: 5392/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 153.19781172275543\n",
      "episode: 5393/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 126.16991436481476\n",
      "episode: 5394/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 137.76124781370163\n",
      "episode: 5395/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 71.99223071336746\n",
      "episode: 5396/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 29.86610621213913\n",
      "episode: 5397/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 106.17785799503326\n",
      "episode: 5398/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 49.3281272649765\n",
      "episode: 5399/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 161.23412954807281\n",
      "episode: 5400/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 29.953125059604645\n",
      "episode: 5401/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 32.714816987514496\n",
      "episode: 5402/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 9.343187749385834\n",
      "episode: 5403/6000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 177.17613089084625\n",
      "episode: 5404/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5405/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 32.712890625\n",
      "episode: 5406/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5407/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 219.5436179637909\n",
      "episode: 5408/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 97.4237294793129\n",
      "episode: 5409/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 183.2585175037384\n",
      "episode: 5410/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 243.70929157733917\n",
      "episode: 5411/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 249.71087789535522\n",
      "episode: 5412/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 178.82583034038544\n",
      "episode: 5413/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 9.476562857627869\n",
      "episode: 5414/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 20.17974853515625\n",
      "episode: 5415/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 230.4573648571968\n",
      "episode: 5416/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 102.49633878469467\n",
      "episode: 5417/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 77.5468367934227\n",
      "episode: 5418/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 71.80719947814941\n",
      "episode: 5419/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5420/6000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 159.43850755691528\n",
      "episode: 5421/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 46.993020474910736\n",
      "episode: 5422/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 61.36315333843231\n",
      "episode: 5423/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 260.2570525407791\n",
      "episode: 5424/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 49.90648716688156\n",
      "episode: 5425/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 105.94694185256958\n",
      "episode: 5426/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 21.22348016500473\n",
      "episode: 5427/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 72.89603799581528\n",
      "episode: 5428/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 9.960939824581146\n",
      "episode: 5429/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 5430/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 13.126309394836426\n",
      "episode: 5431/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 215.5205124616623\n",
      "episode: 5432/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 176.8238639831543\n",
      "episode: 5433/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 0.10774886608123779\n",
      "episode: 5434/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 231.32642650604248\n",
      "episode: 5435/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 109.55288189649582\n",
      "episode: 5436/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 209.23451441526413\n",
      "episode: 5437/6000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 211.99228370189667\n",
      "episode: 5438/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 113.78457641601562\n",
      "episode: 5439/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 15.543010652065277\n",
      "episode: 5440/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 8.529807806015015\n",
      "episode: 5441/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 29.919986724853516\n",
      "episode: 5442/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 177.2987893819809\n",
      "episode: 5443/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5444/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 0.06415212154388428\n",
      "episode: 5445/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 168.28921496868134\n",
      "episode: 5446/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5447/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 75.76202511787415\n",
      "episode: 5448/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 49.59563547372818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5449/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 287.3978579044342\n",
      "episode: 5450/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 199.08811390399933\n",
      "episode: 5451/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 8.20351529121399\n",
      "episode: 5452/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 169.71326166391373\n",
      "episode: 5453/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 49.06387674808502\n",
      "episode: 5454/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 198.9331077337265\n",
      "episode: 5455/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 151.7815866470337\n",
      "episode: 5456/6000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 167.8944207429886\n",
      "episode: 5457/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 12.09576416015625\n",
      "episode: 5458/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 9.994001626968384\n",
      "episode: 5459/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 42.7862491607666\n",
      "episode: 5460/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 72.34669399261475\n",
      "episode: 5461/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 89.78906559944153\n",
      "episode: 5462/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5463/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 157.1196449995041\n",
      "episode: 5464/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 92.86550581455231\n",
      "episode: 5465/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 89.32700824737549\n",
      "episode: 5466/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5467/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 204.7247480750084\n",
      "episode: 5468/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 189.631287753582\n",
      "episode: 5469/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 44.806947112083435\n",
      "episode: 5470/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 237.3824782371521\n",
      "episode: 5471/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 251.71019971370697\n",
      "episode: 5472/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 29.892513036727905\n",
      "episode: 5473/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 143.63436627388\n",
      "episode: 5474/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 775.053388595581\n",
      "episode: 5475/6000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5476/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 20.120421409606934\n",
      "episode: 5477/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 19.789064168930054\n",
      "episode: 5478/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 20.3969247341156\n",
      "episode: 5479/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 52.71121096611023\n",
      "episode: 5480/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 9.978734731674194\n",
      "episode: 5481/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 137.8797772526741\n",
      "episode: 5482/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 80.65389388799667\n",
      "episode: 5483/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 42.690226554870605\n",
      "episode: 5484/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 9.976685881614685\n",
      "episode: 5485/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 132.6153326034546\n",
      "episode: 5486/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 59.96766608953476\n",
      "episode: 5487/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 99.937775015831\n",
      "episode: 5488/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 10.05279541015625\n",
      "episode: 5489/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5490/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 49.997039794921875\n",
      "episode: 5491/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 210.6481937766075\n",
      "episode: 5492/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 127.3721923828125\n",
      "episode: 5493/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 129.066750228405\n",
      "episode: 5494/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 9.978463172912598\n",
      "episode: 5495/6000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 41.36684775352478\n",
      "episode: 5496/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 156.39538139104843\n",
      "episode: 5497/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 155.9312178492546\n",
      "episode: 5498/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 112.69693946838379\n",
      "episode: 5499/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 9.55706787109375\n",
      "episode: 5500/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 148.36351400613785\n",
      "episode: 5501/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 179.27942061424255\n",
      "episode: 5502/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 59.5273859500885\n",
      "episode: 5503/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 164.8140612244606\n",
      "episode: 5504/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 0.17391276359558105\n",
      "episode: 5505/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 70.76632481813431\n",
      "episode: 5506/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 8.3905029296875\n",
      "episode: 5507/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 39.89054203033447\n",
      "episode: 5508/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 125.83765244483948\n",
      "episode: 5509/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 104.49518418312073\n",
      "episode: 5510/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 112.67736983299255\n",
      "episode: 5511/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 82.98043322563171\n",
      "episode: 5512/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 145.85252195596695\n",
      "episode: 5513/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 50.31991171836853\n",
      "episode: 5514/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 9.976661622524261\n",
      "episode: 5515/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5516/6000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 39.608373939991\n",
      "episode: 5517/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 128.2009426355362\n",
      "episode: 5518/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 95.10998982191086\n",
      "episode: 5519/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 225.58807224035263\n",
      "episode: 5520/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 124.2770499587059\n",
      "episode: 5521/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 39.90817832946777\n",
      "episode: 5522/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 170.99666965007782\n",
      "episode: 5523/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 204.34024983644485\n",
      "episode: 5524/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5525/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 20.077881813049316\n",
      "episode: 5526/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 215.45071798563004\n",
      "episode: 5527/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 42.4316201210022\n",
      "episode: 5528/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 52.15704345703125\n",
      "episode: 5529/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 72.63676255941391\n",
      "episode: 5530/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 135.3786935210228\n",
      "episode: 5531/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 109.83796459436417\n",
      "episode: 5532/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 133.99030750989914\n",
      "episode: 5533/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 92.23564356565475\n",
      "episode: 5534/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 175.52538812160492\n",
      "episode: 5535/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 240.3788143992424\n",
      "episode: 5536/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 42.69736212491989\n",
      "episode: 5537/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 39.67071622610092\n",
      "episode: 5538/6000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 74.90030992031097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5539/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 29.937980711460114\n",
      "episode: 5540/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5541/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.476562559604645\n",
      "episode: 5542/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 82.62036633491516\n",
      "episode: 5543/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 7.519535779953003\n",
      "episode: 5544/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5545/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 254.4067348241806\n",
      "episode: 5546/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 52.53462791442871\n",
      "episode: 5547/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 19.955080032348633\n",
      "episode: 5548/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 217.42738890647888\n",
      "episode: 5549/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 3.2091642022132874\n",
      "episode: 5550/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 99.63680362701416\n",
      "episode: 5551/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 145.7629486322403\n",
      "episode: 5552/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 7.748603820800781e-07\n",
      "episode: 5553/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 42.7227783203125\n",
      "episode: 5554/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 97.78747135400772\n",
      "episode: 5555/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 9.9609375\n",
      "episode: 5556/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 221.15423607826233\n",
      "episode: 5557/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 180.46677565574646\n",
      "episode: 5558/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 60.40545666217804\n",
      "episode: 5559/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 72.59763288497925\n",
      "episode: 5560/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 279.9348112344742\n",
      "episode: 5561/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 40.04836821556091\n",
      "episode: 5562/6000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 59.573976933956146\n",
      "episode: 5563/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 20.0379079580307\n",
      "episode: 5564/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 18.953125\n",
      "episode: 5565/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5566/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 160.33819776773453\n",
      "episode: 5567/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5568/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5569/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 19.140625\n",
      "episode: 5570/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 20.26318359375\n",
      "episode: 5571/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 139.39325857162476\n",
      "episode: 5572/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5573/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 0.000853419303894043\n",
      "episode: 5574/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 201.3018491268158\n",
      "episode: 5575/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 209.26419734954834\n",
      "episode: 5576/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 147.91357344388962\n",
      "episode: 5577/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 1.0263673663139343\n",
      "episode: 5578/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 203.8127755522728\n",
      "episode: 5579/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 226.21060055494308\n",
      "episode: 5580/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 50.02542960643768\n",
      "episode: 5581/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 195.3203679919243\n",
      "episode: 5582/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 59.65283203125\n",
      "episode: 5583/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5584/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 147.19244134426117\n",
      "episode: 5585/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5586/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 20.26318359375\n",
      "episode: 5587/6000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 57.462218284606934\n",
      "episode: 5588/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 72.74646520614624\n",
      "episode: 5589/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 164.82892870903015\n",
      "episode: 5590/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 109.87308824062347\n",
      "episode: 5591/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 223.86542624235153\n",
      "episode: 5592/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 158.93517911434174\n",
      "episode: 5593/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 194.6024763584137\n",
      "episode: 5594/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 179.07806968688965\n",
      "episode: 5595/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 62.137179374694824\n",
      "episode: 5596/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5597/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 110.79590541124344\n",
      "episode: 5598/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 143.63234144449234\n",
      "episode: 5599/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 9.976568579673767\n",
      "episode: 5600/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 129.697301030159\n",
      "episode: 5601/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 125.50725054740906\n",
      "episode: 5602/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 196.51758313179016\n",
      "episode: 5603/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 115.4474425315857\n",
      "episode: 5604/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 195.90637773275375\n",
      "episode: 5605/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 214.8143748641014\n",
      "episode: 5606/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 197.99180006980896\n",
      "episode: 5607/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 171.82395869493484\n",
      "episode: 5608/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 122.4255935549736\n",
      "episode: 5609/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 100.46844375133514\n",
      "episode: 5610/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 132.48560971021652\n",
      "episode: 5611/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5612/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 119.28345882892609\n",
      "episode: 5613/6000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 20.98476666212082\n",
      "episode: 5614/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 87.63136011362076\n",
      "episode: 5615/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 159.6738659143448\n",
      "episode: 5616/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 49.88963317871094\n",
      "episode: 5617/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 60.00192850828171\n",
      "episode: 5618/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 9.9765625\n",
      "episode: 5619/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 68.30742543935776\n",
      "episode: 5620/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 34.3676683306694\n",
      "episode: 5621/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 148.5099511742592\n",
      "episode: 5622/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5623/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 117.38074767589569\n",
      "episode: 5624/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 241.45009845495224\n",
      "episode: 5625/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 155.04743438959122\n",
      "episode: 5626/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 167.7525429725647\n",
      "episode: 5627/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 191.16001796722412\n",
      "episode: 5628/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 125.71581369638443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5629/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 21.597720682621002\n",
      "episode: 5630/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 239.12433236837387\n",
      "episode: 5631/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 226.4784705042839\n",
      "episode: 5632/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 164.81836861371994\n",
      "episode: 5633/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 38.34243965148926\n",
      "episode: 5634/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 222.26197391748428\n",
      "episode: 5635/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 161.45596235990524\n",
      "episode: 5636/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 132.01382142305374\n",
      "episode: 5637/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 176.33454006910324\n",
      "episode: 5638/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 177.9608689546585\n",
      "episode: 5639/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 226.77568662166595\n",
      "episode: 5640/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 206.41495364904404\n",
      "episode: 5641/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 247.60712957382202\n",
      "episode: 5642/6000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 183.8966213464737\n",
      "episode: 5643/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 3.551211714744568\n",
      "episode: 5644/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 48.6640625\n",
      "episode: 5645/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 52.88068866729736\n",
      "episode: 5646/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 143.0838738679886\n",
      "episode: 5647/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.2118397355079651\n",
      "episode: 5648/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.484375\n",
      "episode: 5649/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 37.381575882434845\n",
      "episode: 5650/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5651/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 49.90625607967377\n",
      "episode: 5652/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 117.66976976394653\n",
      "episode: 5653/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 184.22375148534775\n",
      "episode: 5654/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 185.20417004823685\n",
      "episode: 5655/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 79.05112260580063\n",
      "episode: 5656/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 79.38120967149734\n",
      "episode: 5657/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 131.20166015625\n",
      "episode: 5658/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 69.83593845367432\n",
      "episode: 5659/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 118.95699095726013\n",
      "episode: 5660/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 184.23857551813126\n",
      "episode: 5661/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 235.13461989164352\n",
      "episode: 5662/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.976564049720764\n",
      "episode: 5663/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5664/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 131.2743660211563\n",
      "episode: 5665/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 182.15285503864288\n",
      "episode: 5666/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 51.10148096084595\n",
      "episode: 5667/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 18.96875\n",
      "episode: 5668/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 9.4765625\n",
      "episode: 5669/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 223.28263944387436\n",
      "episode: 5670/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5671/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 49.84379303455353\n",
      "episode: 5672/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 142.05777913331985\n",
      "episode: 5673/6000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 185.1833987236023\n",
      "episode: 5674/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 30.74609375\n",
      "episode: 5675/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 179.7794755101204\n",
      "episode: 5676/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 77.87970161437988\n",
      "episode: 5677/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 246.79467582702637\n",
      "episode: 5678/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5679/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 19.992794036865234\n",
      "episode: 5680/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 243.47914969921112\n",
      "episode: 5681/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 177.9572715163231\n",
      "episode: 5682/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 29.040279388427734\n",
      "episode: 5683/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5684/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 132.08640265464783\n",
      "episode: 5685/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 49.950725972652435\n",
      "episode: 5686/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 132.55670857429504\n",
      "episode: 5687/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 9.484375357627869\n",
      "episode: 5688/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 168.12872356176376\n",
      "episode: 5689/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 109.18754464387894\n",
      "episode: 5690/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 97.55121546983719\n",
      "episode: 5691/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 216.52469843626022\n",
      "episode: 5692/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 154.80844008922577\n",
      "episode: 5693/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5694/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 33.11883544921875\n",
      "episode: 5695/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 75.9834417104721\n",
      "episode: 5696/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 9.57220458984375\n",
      "episode: 5697/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 102.52152818441391\n",
      "episode: 5698/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 9.4921875\n",
      "episode: 5699/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 106.83219981193542\n",
      "episode: 5700/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 29.21533203125\n",
      "episode: 5701/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 228.67374205589294\n",
      "episode: 5702/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 51.24695944786072\n",
      "episode: 5703/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 68.41712194681168\n",
      "episode: 5704/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 94.58476251363754\n",
      "episode: 5705/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 110.96157622337341\n",
      "episode: 5706/6000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 9.35164338350296\n",
      "episode: 5707/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 219.77688151597977\n",
      "episode: 5708/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 19.953125\n",
      "episode: 5709/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 203.71239805221558\n",
      "episode: 5710/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 105.33707737922668\n",
      "episode: 5711/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 5712/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 131.7384620308876\n",
      "episode: 5713/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 34.552616119384766\n",
      "episode: 5714/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 246.09112709760666\n",
      "episode: 5715/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 3.013673782348633\n",
      "episode: 5716/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 59.88281399011612\n",
      "episode: 5717/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.042904555797576904\n",
      "episode: 5718/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 191.77556401491165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5719/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 191.72335481643677\n",
      "episode: 5720/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 117.16716009378433\n",
      "episode: 5721/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 103.39295196533203\n",
      "episode: 5722/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 7.5373793840408325\n",
      "episode: 5723/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 129.7579157948494\n",
      "episode: 5724/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 36.32673180103302\n",
      "episode: 5725/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 30.80059015750885\n",
      "episode: 5726/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 245.4593689441681\n",
      "episode: 5727/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 9.280023038387299\n",
      "episode: 5728/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 277.8591536283493\n",
      "episode: 5729/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 245.85816609859467\n",
      "episode: 5730/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 180.9221649169922\n",
      "episode: 5731/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.26362937688827515\n",
      "episode: 5732/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 30.02351003885269\n",
      "episode: 5733/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 192.84231650829315\n",
      "episode: 5734/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 178.98200619220734\n",
      "episode: 5735/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 7.428880989551544\n",
      "episode: 5736/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 214.69823867082596\n",
      "episode: 5737/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 254.20714956521988\n",
      "episode: 5738/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 202.46179658174515\n",
      "episode: 5739/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5740/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 47.877978444099426\n",
      "episode: 5741/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 175.13393115997314\n",
      "episode: 5742/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 30.013917922973633\n",
      "episode: 5743/6000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 98.39904916286469\n",
      "episode: 5744/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 176.8456365466118\n",
      "episode: 5745/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 229.32697176933289\n",
      "episode: 5746/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 215.02654713392258\n",
      "episode: 5747/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 222.2885099053383\n",
      "episode: 5748/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 231.74974137544632\n",
      "episode: 5749/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 85.91824227571487\n",
      "episode: 5750/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 147.91617530584335\n",
      "episode: 5751/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 115.71491765975952\n",
      "episode: 5752/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 185.2726166844368\n",
      "episode: 5753/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 84.44715875387192\n",
      "episode: 5754/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.7211343050003\n",
      "episode: 5755/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 29.859844267368317\n",
      "episode: 5756/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 189.0058451294899\n",
      "episode: 5757/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 95.4246232509613\n",
      "episode: 5758/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 213.66187316179276\n",
      "episode: 5759/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 211.98094481229782\n",
      "episode: 5760/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 151.60101056098938\n",
      "episode: 5761/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 245.1154791712761\n",
      "episode: 5762/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 51.98583984375\n",
      "episode: 5763/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 197.08683460950851\n",
      "episode: 5764/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 239.53085815906525\n",
      "episode: 5765/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 228.99636578559875\n",
      "episode: 5766/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 214.90816116333008\n",
      "episode: 5767/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 203.72128808498383\n",
      "episode: 5768/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 245.8911954164505\n",
      "episode: 5769/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 168.76002156734467\n",
      "episode: 5770/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 236.10035341978073\n",
      "episode: 5771/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 160.377312541008\n",
      "episode: 5772/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 105.46142041683197\n",
      "episode: 5773/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.38360857963562\n",
      "episode: 5774/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 178.0703763961792\n",
      "episode: 5775/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 241.95359605550766\n",
      "episode: 5776/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.987770080566406\n",
      "episode: 5777/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 135.52151042222977\n",
      "episode: 5778/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 125.41420197486877\n",
      "episode: 5779/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5780/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 139.41772466897964\n",
      "episode: 5781/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 229.79831486940384\n",
      "episode: 5782/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5783/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 213.162602186203\n",
      "episode: 5784/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.368933737277985\n",
      "episode: 5785/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 179.650448679924\n",
      "episode: 5786/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 161.8620701432228\n",
      "episode: 5787/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 220.06654000282288\n",
      "episode: 5788/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 231.5126839876175\n",
      "episode: 5789/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5790/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.032272338867188\n",
      "episode: 5791/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5792/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 230.68963253498077\n",
      "episode: 5793/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 233.45232218503952\n",
      "episode: 5794/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.75613468885422\n",
      "episode: 5795/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 78.17390114068985\n",
      "episode: 5796/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 98.50291794538498\n",
      "episode: 5797/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 233.27721291780472\n",
      "episode: 5798/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 147.47203648090363\n",
      "episode: 5799/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 276.6673352718353\n",
      "episode: 5800/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 223.80495327711105\n",
      "episode: 5801/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 63.027099609375\n",
      "episode: 5802/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 72.6191897392273\n",
      "episode: 5803/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 164.2882945537567\n",
      "episode: 5804/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 227.19202607870102\n",
      "episode: 5805/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.9550798535347\n",
      "episode: 5806/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 166.46300435066223\n",
      "episode: 5807/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 247.5226222872734\n",
      "episode: 5808/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 176.81172615289688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5809/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 96.13703429698944\n",
      "episode: 5810/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 219.91658478975296\n",
      "episode: 5811/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5812/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 146.57780414819717\n",
      "episode: 5813/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 149.7491431236267\n",
      "episode: 5814/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 230.21915197372437\n",
      "episode: 5815/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5816/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5817/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 51.498926281929016\n",
      "episode: 5818/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 74.02640265226364\n",
      "episode: 5819/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 134.49167281389236\n",
      "episode: 5820/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 154.41301488876343\n",
      "episode: 5821/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 146.4378172159195\n",
      "episode: 5822/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 91.644879758358\n",
      "episode: 5823/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 144.1211370229721\n",
      "episode: 5824/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.42187535762787\n",
      "episode: 5825/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 215.52047407627106\n",
      "episode: 5826/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 190.41227215528488\n",
      "episode: 5827/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 89.74400556087494\n",
      "episode: 5828/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 174.70491808652878\n",
      "episode: 5829/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 203.50819116830826\n",
      "episode: 5830/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 141.96508640050888\n",
      "episode: 5831/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0005900263786315918\n",
      "episode: 5832/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 230.75482881069183\n",
      "episode: 5833/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 48.95340394973755\n",
      "episode: 5834/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 46.18600910902023\n",
      "episode: 5835/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 126.89257991313934\n",
      "episode: 5836/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 251.76194787025452\n",
      "episode: 5837/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 3.6104738116264343\n",
      "episode: 5838/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 153.17914628982544\n",
      "episode: 5839/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 158.8804926276207\n",
      "episode: 5840/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 203.72022676467896\n",
      "episode: 5841/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 186.86857479810715\n",
      "episode: 5842/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 224.33586698770523\n",
      "episode: 5843/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.46232032775879\n",
      "episode: 5844/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 59.99102783203125\n",
      "episode: 5845/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 33.42142426967621\n",
      "episode: 5846/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 142.55762046575546\n",
      "episode: 5847/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.078125\n",
      "episode: 5848/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 175.79639250040054\n",
      "episode: 5849/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 89.19770348072052\n",
      "episode: 5850/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 151.43739712238312\n",
      "episode: 5851/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 99.79599171876907\n",
      "episode: 5852/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 118.06116336584091\n",
      "episode: 5853/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 88.9219462275505\n",
      "episode: 5854/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 84.99998182058334\n",
      "episode: 5855/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 142.0815151333809\n",
      "episode: 5856/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 238.03972154855728\n",
      "episode: 5857/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5858/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.4453125\n",
      "episode: 5859/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 50.300415992736816\n",
      "episode: 5860/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 242.97656339406967\n",
      "episode: 5861/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 208.53904271125793\n",
      "episode: 5862/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0022698044776916504\n",
      "episode: 5863/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 92.85311108827591\n",
      "episode: 5864/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 140.76471745967865\n",
      "episode: 5865/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.67277824878693\n",
      "episode: 5866/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 227.0434089899063\n",
      "episode: 5867/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 69.92420291900635\n",
      "episode: 5868/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 235.70384937524796\n",
      "episode: 5869/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.08782386779785\n",
      "episode: 5870/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.05474299192429\n",
      "episode: 5871/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 172.24025881290436\n",
      "episode: 5872/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 27.91407060623169\n",
      "episode: 5873/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 155.1896795630455\n",
      "episode: 5874/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 224.00869500637054\n",
      "episode: 5875/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 213.79344087839127\n",
      "episode: 5876/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 28.4296875\n",
      "episode: 5877/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 72.61142462491989\n",
      "episode: 5878/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 94.70312666893005\n",
      "episode: 5879/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 102.88235437870026\n",
      "episode: 5880/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 51.36232751607895\n",
      "episode: 5881/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 83.76371723413467\n",
      "episode: 5882/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.47656261920929\n",
      "episode: 5883/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 155.26388639211655\n",
      "episode: 5884/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 186.0552379488945\n",
      "episode: 5885/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.979179382324219\n",
      "episode: 5886/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.71893310546875\n",
      "episode: 5887/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 31.35833740234375\n",
      "episode: 5888/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 41.91015714406967\n",
      "episode: 5889/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 183.81071043014526\n",
      "episode: 5890/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 136.8866879940033\n",
      "episode: 5891/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 108.62452566623688\n",
      "episode: 5892/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 32.993210315704346\n",
      "episode: 5893/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5894/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 239.91691207885742\n",
      "episode: 5895/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 82.59760385751724\n",
      "episode: 5896/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 35.582271695137024\n",
      "episode: 5897/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.25341796875\n",
      "episode: 5898/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 121.89526534080505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5899/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 92.58200120925903\n",
      "episode: 5900/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.912174224853516\n",
      "episode: 5901/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 27.583959221839905\n",
      "episode: 5902/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 78.16410803794861\n",
      "episode: 5903/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 135.42586773633957\n",
      "episode: 5904/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.51075345277786\n",
      "episode: 5905/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.8525949120521545\n",
      "episode: 5906/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 163.92417532205582\n",
      "episode: 5907/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 178.73866987228394\n",
      "episode: 5908/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5909/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.938444137573242\n",
      "episode: 5910/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 23.82049560546875\n",
      "episode: 5911/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 148.15220940113068\n",
      "episode: 5912/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 235.75187265872955\n",
      "episode: 5913/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 238.30794727802277\n",
      "episode: 5914/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 132.25210201740265\n",
      "episode: 5915/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 189.65808200836182\n",
      "episode: 5916/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 96.16955876350403\n",
      "episode: 5917/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 79.89794832468033\n",
      "episode: 5918/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 43.803581058979034\n",
      "episode: 5919/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 9.1484375\n",
      "episode: 5920/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 96.38903671503067\n",
      "episode: 5921/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 60.543210566043854\n",
      "episode: 5922/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 75.40415054559708\n",
      "episode: 5923/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 49.88381803035736\n",
      "episode: 5924/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 15.591056823730469\n",
      "episode: 5925/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 145.71733683347702\n",
      "episode: 5926/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.66010642051697\n",
      "episode: 5927/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 61.74679654836655\n",
      "episode: 5928/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 121.86295115947723\n",
      "episode: 5929/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 147.12514585256577\n",
      "episode: 5930/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 73.17343592643738\n",
      "episode: 5931/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 144.74752807617188\n",
      "episode: 5932/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 131.61833101511002\n",
      "episode: 5933/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 34.939453125\n",
      "episode: 5934/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 236.98768371343613\n",
      "episode: 5935/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 209.756405711174\n",
      "episode: 5936/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 11.075195372104645\n",
      "episode: 5937/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 52.718508303165436\n",
      "episode: 5938/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 181.90330028533936\n",
      "episode: 5939/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 62.63381862640381\n",
      "episode: 5940/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 41.93937015533447\n",
      "episode: 5941/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 239.14329987764359\n",
      "episode: 5942/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 53.28181153535843\n",
      "episode: 5943/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 159.70316576957703\n",
      "episode: 5944/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 231.26573431491852\n",
      "episode: 5945/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 63.91549873352051\n",
      "episode: 5946/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 187.69329845905304\n",
      "episode: 5947/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 168.0820175409317\n",
      "episode: 5948/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5949/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 10.28809118270874\n",
      "episode: 5950/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 199.48698157072067\n",
      "episode: 5951/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 67.53324288129807\n",
      "episode: 5952/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 156.7921495437622\n",
      "episode: 5953/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 232.24216037988663\n",
      "episode: 5954/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 92.61912906169891\n",
      "episode: 5955/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 121.9294884800911\n",
      "episode: 5956/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 111.75235217809677\n",
      "episode: 5957/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 200.22889316082\n",
      "episode: 5958/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 65.89633452892303\n",
      "episode: 5959/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5960/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.955011785030365\n",
      "episode: 5961/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 233.54071062803268\n",
      "episode: 5962/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 169.03694999217987\n",
      "episode: 5963/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 210.72485381364822\n",
      "episode: 5964/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5965/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 178.12278789281845\n",
      "episode: 5966/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 121.4091609120369\n",
      "episode: 5967/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 94.54529446363449\n",
      "episode: 5968/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0011494755744934082\n",
      "episode: 5969/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 242.62235110998154\n",
      "episode: 5970/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 187.94145107269287\n",
      "episode: 5971/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 145.6020724773407\n",
      "episode: 5972/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 141.1445556282997\n",
      "episode: 5973/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 305.9088201522827\n",
      "episode: 5974/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 130.89245867729187\n",
      "episode: 5975/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 42.77016419172287\n",
      "episode: 5976/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 77.8984375\n",
      "episode: 5977/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 20.20733642578125\n",
      "episode: 5978/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.9453125\n",
      "episode: 5979/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 125.39116275310516\n",
      "episode: 5980/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 8.0234375\n",
      "episode: 5981/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 116.3550825715065\n",
      "episode: 5982/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.002719879150390625\n",
      "episode: 5983/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5984/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 19.9375\n",
      "episode: 5985/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 49.54287666082382\n",
      "episode: 5986/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 51.121962666511536\n",
      "episode: 5987/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 103.12454223632812\n",
      "episode: 5988/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 255.67747956514359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5989/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 39.132373094558716\n",
      "episode: 5990/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 18.094056844711304\n",
      "episode: 5991/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 112.12083822488785\n",
      "episode: 5992/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 118.02721798419952\n",
      "episode: 5993/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "episode: 5994/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 106.948985517025\n",
      "episode: 5995/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 144.6301924586296\n",
      "episode: 5996/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 69.83467477560043\n",
      "episode: 5997/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 185.0469109416008\n",
      "episode: 5998/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 125.54696238040924\n",
      "episode: 5999/6000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 0.0008120536804199219\n",
      "Finished in 36617.3416 second(s)\n"
     ]
    }
   ],
   "source": [
    "exploration_rate, t2, accumulated_rewards = csrl.train_DQN(EPISODES=6000,num_steps=500) #8000, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e61105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "        \n",
    "ax1.set_xlabel('episode(s)') \n",
    "ax1.set_ylabel('epsilon', color = 'red') \n",
    "ax1.plot(t2, exploration_rate, color = 'red') \n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "# Adding Twin Axes\n",
    "ax2 = ax1.twinx() \n",
    "ax2.set_ylabel('accumulated rewards/100 episodes', color = 'blue') \n",
    "ax2.plot(t2, accumulated_rewards, color = 'blue') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue') \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d62dbad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START STATE: (0, 0, 1, 0)\n",
      "(0, 0, 1, 0)\n",
      "state: (0, 0, 1, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START STATE: (0, 0, 7, 9)\n",
      "(0, 0, 7, 9)\n",
      "state: (0, 0, 7, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 6, 9)\n",
      "state: (0, 0, 6, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 5, 9)\n",
      "state: (0, 0, 5, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 6.982266023027107e-08\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.0003803902917223779\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.0003805470200571705\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 8.634599019261303e-06\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.8155156753775044\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.009857822915784064\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.0002729203203243885\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 4)\n",
      "state: (0, 0, 2, 4)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 4)\n",
      "state: (0, 0, 1, 4)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.00019670573629834606\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0119300710188878\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012542815484935974\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012562252858540623\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012562811001367927\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 7.171272958458782\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 8.047483674905884\n",
      "START STATE: (0, 0, 4, 9)\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.00682895305584992\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.0003834927564861049\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 8.705433877285578e-06\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.00027603083192117645\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0002738684950655597\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.00027372723331826215\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0002738628360683115\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 1.138864166282734e-08\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.00026992803714390986\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 8.299179108038574e-06\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 0\n",
      "reward: 2.3223314515268214e-07\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 4)\n",
      "state: (0, 0, 1, 4)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.00019717581894464244\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.3647084747535833\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.023478978644216657\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 7.2263565070594895\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 7.62333824775686\n",
      "START STATE: (0, 0, 0, 4)\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.00019713850773343382\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.011958395511091615\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012572597665086501\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592081283420247\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 7.18829851082769\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 7.225618723795022\n",
      "START STATE: (0, 0, 0, 4)\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.00015110628990144462\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.36367307502264534\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.02346857069717767\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.5491956079726977\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.02503848994286447\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012868649093707085\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012598767851440717\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592789542000413\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592657114652177\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654181185997\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654116204633\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259265411476517\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259265411473328\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732572\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.5386077081198168\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.024800745310044753\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0128633713850382\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259865094700401\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259278695259613\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592657057296997\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259265417991557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.01259265411617649\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114764543\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114733266\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732572\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.012592654114732557\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 7.188299543858834\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 9.053795605472255\n",
      "START STATE: (0, 0, 2, 8)\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 0\n",
      "reward: 9.144903745709593\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 9.144903745709593\n",
      "START STATE: (0, 0, 3, 7)\n",
      "(0, 0, 3, 7)\n",
      "state: (0, 0, 3, 7)\n",
      "action selected: 0\n",
      "reward: 0.12477718360071298\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.026326070843054987\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 2\n",
      "reward: 0.03607556535587454\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.000387876707338717\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 1\n",
      "reward: 8.753488311457558e-06\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 4, 9)\n",
      "state: (0, 0, 4, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 3, 9)\n",
      "state: (0, 0, 3, 9)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 3\n",
      "reward: 0.011830372702789499\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0002809975844205114\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0002738673409403974\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.0002738629057491674\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 3, 8)\n",
      "state: (0, 0, 3, 8)\n",
      "action selected: 0\n",
      "reward: 0.00027386290309408176\n",
      "(0, 0, 2, 8)\n",
      "state: (0, 0, 2, 8)\n",
      "action selected: 1\n",
      "reward: 9.114466697079654e-06\n",
      "(0, 0, 2, 9)\n",
      "state: (0, 0, 2, 9)\n",
      "action selected: 0\n",
      "reward: 9.945521563759076\n",
      "(0, 0, 1, 9)\n",
      "state: (0, 0, 1, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 8)\n",
      "state: (0, 0, 1, 8)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 10.146039091658059\n",
      "START STATE: (0, 0, 0, 2)\n",
      "(0, 0, 0, 2)\n",
      "state: (0, 0, 0, 2)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 2)\n",
      "state: (0, 0, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 2)\n",
      "state: (0, 0, 0, 2)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 0)\n",
      "state: (0, 0, 0, 0)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 1)\n",
      "state: (0, 0, 0, 1)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 2)\n",
      "state: (0, 0, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 2)\n",
      "state: (0, 0, 0, 2)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 3)\n",
      "state: (0, 0, 0, 3)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 4)\n",
      "state: (0, 0, 0, 4)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START STATE: (0, 0, 3, 7)\n",
      "(0, 0, 3, 7)\n",
      "state: (0, 0, 3, 7)\n",
      "action selected: 0\n",
      "reward: 0.12477718360071298\n",
      "(0, 0, 2, 7)\n",
      "state: (0, 0, 2, 7)\n",
      "action selected: 0\n",
      "reward: 0.00509687412030938\n",
      "(0, 0, 1, 7)\n",
      "state: (0, 0, 1, 7)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 2, 6)\n",
      "state: (0, 0, 2, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 1, 6)\n",
      "state: (0, 0, 1, 6)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 1, 5)\n",
      "state: (0, 0, 1, 5)\n",
      "action selected: 1\n",
      "reward: 0.0\n",
      "(0, 0, 2, 5)\n",
      "state: (0, 0, 2, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.12987405772102237\n",
      "START STATE: (0, 0, 0, 8)\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 9)\n",
      "state: (0, 0, 0, 9)\n",
      "action selected: 3\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 8)\n",
      "state: (0, 0, 0, 8)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 7)\n",
      "state: (0, 0, 0, 7)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 2\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 6)\n",
      "state: (0, 0, 0, 6)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "(0, 0, 0, 5)\n",
      "state: (0, 0, 0, 5)\n",
      "action selected: 0\n",
      "reward: 0.0\n",
      "accumulated_rewards_per_episode: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8593f4190>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e857a2d880>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######### verify the dqn_cnn policy\n",
    "'''\n",
    "Parameters\n",
    "----------\n",
    "start : (r,c) = POMDP state\n",
    "    The start state of the product POMDPs.\n",
    "\n",
    "EPISODES : int\n",
    "    The number of episodes.\n",
    "\n",
    "num_steps : int \n",
    "    The episode length.\n",
    "\n",
    "'''\n",
    "\n",
    "from dqn_cnn import DQNAgent\n",
    "EPISODES=10\n",
    "num_steps=100\n",
    "\n",
    "Path = []\n",
    "\n",
    "gamma=0.99999\n",
    "gammaB=0.9\n",
    "\n",
    "# the defined belief_state size and action size\n",
    "belief_state_size = np.shape(csrl.belief_state)\n",
    "#action_size = np.shape(csrl.A)\n",
    "\n",
    "# find the size of belief_state for np.reshape\n",
    "prod_b_state_size = 1\n",
    "for i in range(len(belief_state_size)):\n",
    "    prod_b_state_size = prod_b_state_size * belief_state_size[i]\n",
    "# find the size of action for np.reshape\n",
    "\n",
    "# action size\n",
    "#prod_action_size = csrl.shape[4]\n",
    "prod_action_size = 4\n",
    "\n",
    "agent = DQNAgent(prod_b_state_size, csrl.shape[2], csrl.shape[3], csrl.shape[1], prod_action_size, gamma, gammaB)\n",
    "agent.load(\"./save/DQN_CNN_10_frontier.h5\")\n",
    "agent.epsilon = 0\n",
    "done = False\n",
    "num_episode_for_reward = 100 # print the accumulated reward per num of episode\n",
    "# initialize the list for plot\n",
    "accumulated_rewards=[]\n",
    "exploration_rate=[]\n",
    "accumulated_rewards_hundred_steps = []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    accumulated_rewards_per_episode=0\n",
    "    done = False\n",
    "    subpath = []\n",
    "\n",
    "    pomdp_state = csrl.pomdp.random_state()\n",
    "    while csrl.pomdp.label[pomdp_state[0],pomdp_state[1]] == ('c',) or csrl.pomdp.structure[(pomdp_state[0],pomdp_state[1])]=='B':\n",
    "        #print('state in c and B, state is regenerated')\n",
    "        pomdp_state = csrl.pomdp.random_state()\n",
    "    #pomdp_state = (9, 7)\n",
    "\n",
    "    state = (csrl.shape[0]-1,csrl.oa.q0)+(pomdp_state) # select the start product state\n",
    "    print('START STATE: '+str(state))\n",
    "    belief_state = csrl.belief_state # initialize the belief state\n",
    "    \n",
    "    csrl.track = [0,1] #self.initial_track # initialize frontier set = [0,1]\n",
    "    ###print('begin new episode, self.track is reset')\n",
    "    ###print('frontier reset as: [' + str(self.track)[1:-1] + ']')\n",
    "    reshaped_reward = csrl.reshaped_reward_init\n",
    "    ###print('begin new episode, reward is reset to initial reward')\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        print(state)\n",
    "        subpath.append(state)\n",
    "        # reshape the belief state as the input to acquire the action\n",
    "        input_b_state = np.reshape(belief_state,(1, csrl.shape[2], csrl.shape[3], csrl.shape[1]))\n",
    "        print('state: '+str(state))\n",
    "        #print('input_b_state: '+str(input_b_state))\n",
    "\n",
    "        # verify the existence of action and select the action from the belief_state\n",
    "        action_probs = agent.act_trained(input_b_state)\n",
    "        action_probs = np.reshape(action_probs,(prod_action_size,1))\n",
    "        #print('action_probs: '+str(action_probs))\n",
    "\n",
    "        i = 0\n",
    "        possible_actions = []\n",
    "        for i in range(len(csrl.A[state])):\n",
    "            possible_actions.append(action_probs[csrl.A[state][i]])\n",
    "        action = csrl.A[state][np.argmax(possible_actions)]\n",
    "        #print('possible_actions :'+str(possible_actions))\n",
    "        print('action selected: '+str(action))\n",
    "\n",
    "        ################## The agnet on POMDP simualtion\n",
    "\n",
    "        # agent moves to the next state\n",
    "        states, probs = csrl.transition_probs[state][action]\n",
    "        next_state = states[np.random.choice(len(states),p=probs)]\n",
    "        # find the observation states' list and the corresponding probabilities\n",
    "        obsv_states, obsv_probs = csrl.pomdp.get_observation_prob(next_state[-2:])\n",
    "        # observe the next state\n",
    "        obsv_state = csrl.pomdp.generate_obsv_state(obsv_states, obsv_probs)\n",
    "\n",
    "        ################## The belief_state update with the loops\n",
    "\n",
    "        # temproraily store the current belief state\n",
    "        current_belief_state = belief_state\n",
    "\n",
    "        # multiply the transition probability matrix\n",
    "        belief_state_after_transition = []\n",
    "        for s in csrl.states():\n",
    "            belief_state_after_transition.append(belief_state[s]*csrl.belief_transition_probs[s][action])\n",
    "        belief_state_after_transition = sum(belief_state_after_transition)\n",
    "        # update the belief state with the observation probability matrix\n",
    "        updated_belief_state = belief_state_after_transition\n",
    "        for s in csrl.states():\n",
    "            updated_belief_state[s] = updated_belief_state[s]*csrl.belief_observation_probs[s][obsv_state[0], obsv_state[1]]\n",
    "        belief_state = updated_belief_state/sum(sum(sum(sum(updated_belief_state))))\n",
    "\n",
    "        ################# The training process\n",
    "        \n",
    "        # Update the frontier set + update reward setup accordingly\n",
    "        reshaped_reward = csrl.Tf(state, next_state, reshaped_reward)\n",
    "        ###print('frontier set: [' + str(csrl.track)[1:-1] + ']')\n",
    "        \n",
    "        # calculate the reward from the next belief state and find gamm\n",
    "        reward = np.sum(np.reshape(belief_state,(1,prod_b_state_size))*reshaped_reward)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        accumulated_rewards_per_episode = accumulated_rewards_per_episode + reward\n",
    "        print('reward: '+str(reward))\n",
    "    \n",
    "    Path.append(subpath)\n",
    "    \n",
    "    print('accumulated_rewards_per_episode: '+str(accumulated_rewards_per_episode))\n",
    "    accumulated_rewards.append(accumulated_rewards_per_episode)\n",
    "    exploration_rate.append(agent.epsilon)\n",
    "\n",
    "    if len(accumulated_rewards)>=num_episode_for_reward:\n",
    "        accumulated_rewards_hundred_steps.append(np.average(accumulated_rewards))\n",
    "        accumulated_rewards = []\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "t1 = np.arange(0, EPISODES, 1)\n",
    "t2 = np.arange(0, len(accumulated_rewards_hundred_steps)*num_episode_for_reward, num_episode_for_reward)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "display(plt.plot(t1, exploration_rate))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "display(plt.plot(t2, accumulated_rewards_hundred_steps))\n",
    "#matplotlib.pyplot.scatter(len(accumulated_rewards_hundred_steps)*10, accumulated_rewards_hundred_steps, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a98c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0)]\n",
      "[(0, 0, 7, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 6, 9), (0, 0, 5, 9), (0, 0, 5, 9), (0, 0, 4, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 2, 7), (0, 0, 1, 7), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 2, 4), (0, 0, 1, 4), (0, 0, 0, 4), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 6), (0, 0, 0, 6)]\n",
      "[(0, 0, 4, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 3, 9), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 2, 7), (0, 0, 1, 7), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 2, 6), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 1, 4), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8)]\n",
      "[(0, 0, 0, 4), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8)]\n",
      "[(0, 0, 0, 4), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8)]\n",
      "[(0, 0, 2, 8), (0, 0, 1, 8), (0, 0, 1, 7), (0, 0, 1, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7)]\n",
      "[(0, 0, 3, 7), (0, 0, 2, 7), (0, 0, 2, 8), (0, 0, 2, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 3, 9), (0, 0, 4, 9), (0, 0, 3, 9), (0, 0, 2, 9), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 3, 8), (0, 0, 2, 8), (0, 0, 2, 9), (0, 0, 1, 9), (0, 0, 1, 8), (0, 0, 1, 7), (0, 0, 1, 6), (0, 0, 2, 6), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 2, 6), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8)]\n",
      "[(0, 0, 0, 2), (0, 0, 0, 2), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 2), (0, 0, 0, 1), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 1), (0, 0, 0, 2), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 2), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 3), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5)]\n",
      "[(0, 0, 3, 7), (0, 0, 2, 7), (0, 0, 1, 7), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 2, 6), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 1, 5), (0, 0, 2, 5), (0, 0, 2, 6), (0, 0, 1, 6), (0, 0, 1, 5), (0, 0, 2, 5)]\n",
      "[(0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 9), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 8), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 7), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 6), (0, 0, 0, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(Path[0])\n",
    "print(Path[1])\n",
    "print(Path[2])\n",
    "print(Path[3])\n",
    "print(Path[4])\n",
    "print(Path[5])\n",
    "print(Path[6])\n",
    "print(Path[7])\n",
    "print(Path[8])\n",
    "print(Path[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a00d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "size_x = 10\n",
    "size_y = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10a4e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = Path[0]\n",
    "\n",
    "### plot the path on 'q0'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "        \n",
    "for i in range(len(path)):\n",
    "    if path[i][1]<=0:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        \n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5964e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot the path on 'q1'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "\n",
    "ii=i\n",
    "for i in range(ii, len(path)):\n",
    "    if path[i][1]==1:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e6c7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot again the path on 'q0'.\n",
    "\n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the Blocks\n",
    "b_start_x = b_start_y = 4\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "# plot the Traps, 'c'\n",
    "b_start_x = 2\n",
    "b_start_y = 6\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "b_start_x = 6\n",
    "b_start_y = 2\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='orange', alpha=.8))\n",
    "\n",
    "# plot the 'a's\n",
    "b_start_x = b_start_y = 0\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "\n",
    "# plot the 'b's\n",
    "b_start_x = b_start_y = 8\n",
    "b_size_x = b_size_y = 2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))    \n",
    "\n",
    "ii=i\n",
    "for i in range(ii, len(path)):\n",
    "    if path[i][1]<=0:\n",
    "        state_idx = path[i]\n",
    "        ## convert state index in Julia to 'x,y' coordinates in python\n",
    "        coord_x = path[i][3]\n",
    "        coord_y = size_x-1-path[i][2]\n",
    "        \n",
    "        ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "        if i==0:\n",
    "            # start point\n",
    "            ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee4946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e68d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
